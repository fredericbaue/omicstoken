--- PROJECT STRUCTURE ---
.\app.py
.\auth.py
.\check_config.py
.\db.py
.\demo_checklist.py
.\demo_export.py
.\demo_export_simple.py
.\embeddings.py
.\fix_search.py
.\importers.py
.\ingest_real_data.py
.\list_models.py
.\models.py
.\prepare_cachexia_dataset.py
.\prepare_ibd_dataset.py
.\prepare_peptide_dataset.py
.\search.py
.\summarizer.py
.\test_api_key.py
.\test_embedding_export.py
.\test_fingerprint.py
.\test_gemini.py
.\test_gemini_api.py
.\test_gemini_key.py
.\test_login.py
.\test_models.py
.\test_provided_key.py
.\update_env.py
.\upload_error.html
.\upload_form.html
.\upload_success.html
.\verify_access_control.py
.\verify_auth_flow.py
.\verify_dashboard.py
.\verify_summary.py
.\verify_tumor_flow.py
.\modules\embedder.py
.\modules\tokenizer.py
.\omicstoken_repo\app.py
.\omicstoken_repo\db.py
.\omicstoken_repo\embeddings.py
.\omicstoken_repo\importers.py
.\omicstoken_repo\list_models.py
.\omicstoken_repo\models.py
.\omicstoken_repo\prepare_cachexia_dataset.py
.\omicstoken_repo\prepare_ibd_dataset.py
.\omicstoken_repo\prepare_peptide_dataset.py
.\omicstoken_repo\search.py
.\omicstoken_repo\summarizer.py
.\omicstoken_repo\test_gemini.py
.\omicstoken_repo\upload_error.html
.\omicstoken_repo\upload_form.html
.\omicstoken_repo\upload_success.html
.\omicstoken_repo\verify_summary.py
.\omicstoken_repo\verify_tumor_flow.py
.\omicstoken_repo\scripts\prepare_ibd_dataset.py
.\omicstoken_repo\static\search.html
.\scripts\prepare_ibd_dataset.py
.\static\compare.html
.\static\dashboard.html
.\static\fingerprint.html
.\static\login.html
.\static\runs.html
.\static\search.html
.\static\search_backup.html
.\static\simple_dashboard.html
.\static\style.css
.\static\summary.html
.\static\upload.html


--- FILE CONTENTS ---


====================
FILE: .\app.py
====================
from dotenv import load_dotenv
load_dotenv()

from fastapi.concurrency import run_in_threadpool
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, BackgroundTasks, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi import Request
from pydantic import BaseModel, Field
import uvicorn
import os
import shutil
import pandas as pd
import numpy as np
import random
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

from typing import List, Optional
import logging

import embeddings
from embeddings import peptide_to_vector, EMBEDDING_DIM
import db
import search
import models
import importers
import summarizer
import auth
from auth import current_active_user, User

# --- Configuration ---
DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

app = FastAPI(title="Immuno-Peptidomics MVP")

# CORS (Optional, good for dev)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def on_startup():
    await auth.create_db_and_tables()

# --- Auth Routes ---
app.include_router(
    auth.fastapi_users.get_auth_router(auth.auth_backend),
    prefix="/auth/jwt",
    tags=["auth"],
)
app.include_router(
    auth.fastapi_users.get_register_router(auth.UserRead, auth.UserCreate),
    prefix="/auth",
    tags=["auth"],
)

@app.get("/", include_in_schema=False)
async def root():
    return RedirectResponse(url="/docs", status_code=307)

@app.post("/peptide/embed/{run_id}")
def embed(run_id: str):
    """Vectorize each peptide in a run and persist the vectors."""
    con = db.get_db_connection(DATA_DIR)
    
    # Verify run exists
    run = db.get_run(con, run_id)
    if not run:
        con.close()
        raise HTTPException(404, "run_id not found")

    features = db.get_features_for_run(con, run_id)
    
    count = 0
    total_features = len(features)
    print(f"Embedding {total_features} peptides for run {run_id}...")
    for i, feat in enumerate(features):
        if (i + 1) % 100 == 0:
            print(f"  Processed {i + 1}/{total_features} peptides...")
        # The core of our new engine: converting sequence to vector
        vec = peptide_to_vector(feat.peptide_sequence)

        # If vectorization is successful, calculate properties and insert into DB
        if vec is not None and vec.shape[0] == EMBEDDING_DIM:
            # Vector is valid, proceed with insertion.
            props = calculate_properties(feat.peptide_sequence)
            
            # Populate the new first-class peptide_embeddings table
            db.insert_peptide_embedding(
                con, 
                run_id, 
                run.user_id, 
                feat.feature_id, # Added feature_id
                feat.peptide_sequence, 
                feat.intensity or 0.0,
                props["length"],
                props["charge"],
                props["hydrophobicity"],
                vec
            )
            count += 1
        else:
            # This block is now correctly executed when vectorization fails.
            print(f"Skipping embedding for feature {feat.feature_id} due to invalid sequence or vector.")

    con.commit()
    # After committing, rebuild the global search index
    search.rebuild_faiss_index(con, DATA_DIR)

    con.close()
    return {"run_id": run_id, "peptides_embedded": count}

@app.get("/upload", include_in_schema=False)
def upload_page():
    return RedirectResponse(url="/static/upload.html")


@app.post("/upload", include_in_schema=False)
async def upload_handler(request: Request, background_tasks: BackgroundTasks,
                         file: UploadFile = File(...),
                         run_id: str = Form(""),
                         instrument: str = Form(""),
                         method: str = Form(""),
                         format: str = Form("auto"),
                         user: User = Depends(current_active_user)):
    """
    Handles file uploads, detects format, ingests data, and triggers embedding.
    """
    # --- Ingest Logic ---
    name = file.filename or "upload.csv"
    sep = "\t" if name.endswith(".tsv") or name.endswith(".txt") else ","
    await file.seek(0)
    
    try:
        df = pd.read_csv(file.file, sep=sep)
    except Exception as e:
        raise HTTPException(400, f"Failed to parse CSV: {e}")

    # Use the importers module to parse the dataframe
    try:
        features = importers.parse_upload(df, fmt=format)
    except Exception as e:
        raise HTTPException(400, f"Import failed: {e}")

    # Build meta dict
    meta_dict = {
        "run_id": run_id.strip() or None,
        "instrument": instrument.strip() or None,
        "method": method.strip() or None,
        "original_filename": name
    }
    run_id_final = meta_dict.get("run_id") or f"RUN_{pd.Timestamp.utcnow().strftime('%Y%m%d_%H%M%S')}"

    # Store in SQLite
    con = db.get_db_connection(DATA_DIR)
    db.insert_run(con, run_id_final, meta_dict, user_id=str(user.id))

    for feat in features:
        db.insert_feature(con, run_id_final, feat)
        
    con.commit()
    con.close()
    rows_ingested = len(features)

    # --- Background Tasks ---
    def _background_work(run_id_to_process: str):
        # This function is synchronous and will be run in a threadpool
        try:
            embed_result = embed(run_id=run_id_to_process)
            print(f"Background: Embedded {embed_result['peptides_embedded']} peptides.")
            print(f"Background: Ready for summarization.")
        except Exception as e:
            print(f"[ERROR] Background embedding failed for run {run_id_to_process}: {e}")

    # Use run_in_threadpool to avoid blocking the event loop with synchronous code
    background_tasks.add_task(run_in_threadpool, _background_work, run_id_final)

    # --- Success Response ---
    first_feature_id = features[0].feature_id if features else None
    
    return {
        "status": "success",
        "run_id": run_id_final,
        "rows_ingested": rows_ingested,
        "format": format,
        "first_feature_id": first_feature_id,
        "message": "Upload complete and embedding started in background."
    }

@app.get("/peptide/search/{run_id}/{feature_id}")
def similar(run_id: str, feature_id: str, k: int = 5, user: User = Depends(current_active_user)):
    """Find peptides with similar biophysical properties."""
    con = db.get_db_connection(DATA_DIR)
    try:
        run = db.get_run(con, run_id)
        if run is None or str(run.user_id) != str(user.id):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found",
            )
        return search.search_similar_peptides(con, DATA_DIR, run_id, feature_id, k)
    except HTTPException as e:
        raise e
    finally:
        con.close()

@app.get("/peptide/explain/{run_id}/{feature_id}")
def explain_peptide(run_id: str, feature_id: str, user: User = Depends(current_active_user)):
    """Generate an LLM-powered explanation for a specific peptide."""
    con = db.get_db_connection(DATA_DIR)
    try:
        # Verify run ownership
        run = db.get_run(con, run_id)
        if run is None or str(run.user_id) != str(user.id):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found",
            )
        
        # Get peptide data
        props = db.get_feature_properties(con, run_id, feature_id)
        if not props:
            raise HTTPException(404, "Peptide not found")
        
        sequence, intensity = props
        
        # Calculate biophysical properties
        peptide_props = calculate_properties(sequence)
        
        # Get similar peptides (k=10 neighbors)
        similar_peptides_response = search.search_similar_peptides(con, DATA_DIR, run_id, feature_id, k=10)
        neighbors = similar_peptides_response.neighbors
        
        # Prepare neighbor data for LLM
        neighbors_summary = []
        for n in neighbors[:5]:  # Top 5 for brevity
            neighbors_summary.append({
                "sequence": n.peptide_sequence,
                "similarity_score": round(n.similarity, 3),
                "intensity": n.intensity or 0.0
            })
        
        # Build LLM prompt
        prompt = f"""You are an expert proteomics assistant. A user is looking at a peptide from a mass spectrometry experiment.

Peptide: {sequence}
Length: {peptide_props['length']} amino acids
Intensity: {intensity:,.0f}
Hydrophobicity (GRAVY): {peptide_props['hydrophobicity']}
Charge: {peptide_props['charge']}
Similar peptides in this dataset:
{chr(10).join([f"- {n['sequence']} (similarity: {n['similarity_score']}, intensity: {n.get('intensity', 0):,.0f})" for n in neighbors_summary])}

Explain in 2 short paragraphs what's interesting about this peptide. Mention any obvious biophysical features, whether it looks like a common tryptic peptide (check for K/R cleavage sites), and what the neighbor set suggests (e.g., shared motifs, possible functional or structural similarities). Use accessible scientific language but keep it concise."""

        # Call Gemini API
        try:
            import google.generativeai as genai
            GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
            
            if not GOOGLE_API_KEY:
                raise HTTPException(500, "GOOGLE_API_KEY not configured")
            
            genai.configure(api_key=GOOGLE_API_KEY)
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)
            explanation = response.text
            
        except Exception as e:
            raise HTTPException(500, f"LLM generation failed: {str(e)}")
        
        # Return structured response
        return {
            "sequence": sequence,
            "length": peptide_props['length'],
            "intensity": intensity,
            "hydrophobicity": peptide_props['hydrophobicity'],
            "charge": peptide_props['charge'],
            "neighbors": neighbors_summary,
            "explanation": explanation
        }
        
    finally:
        con.close()

@app.post("/summary/run/{run_id}")
def get_run_summary(run_id: str, user: User = Depends(current_active_user)):
    """
    Generates a text summary of the run using the Summarization Engine.
    """
    con = db.get_db_connection(DATA_DIR)
    try:
        run = db.get_run(con, run_id)
        if run is None or str(run.user_id) != str(user.id):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found",
            )

        summary = summarizer.generate_summary(run_id, con)
        return summary
    finally:
        con.close()

@app.get("/runs")
def list_runs(user: User = Depends(current_active_user)):
    """List all runs for the current user."""
    con = db.get_db_connection(DATA_DIR)
    try:
        return db.get_run_summaries(con, user_id=str(user.id))
    finally:
        con.close()

@app.get("/runs/{run_id}")
def get_run_details(run_id: str, user: User = Depends(current_active_user)):
    """Get detailed information about a specific run."""
    con = db.get_db_connection(DATA_DIR)
    try:
        run = db.get_run(con, run_id)
        
        # If the run doesn't exist or doesn't belong to this user, hide it
        if run is None or str(run.user_id) != str(user.id):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found",
            )
            
        # Get counts
        cur = con.cursor()
        cur.execute("SELECT COUNT(*) FROM features WHERE run_id=?", (run_id,))
        n_features = cur.fetchone()[0]

        cur.execute("SELECT COUNT(*) FROM peptide_embeddings WHERE run_id=?", (run_id,))
        n_embeddings = cur.fetchone()[0]
        
        # Check for first feature for search link
        cur.execute("SELECT feature_id FROM features WHERE run_id=? LIMIT 1", (run_id,))
        row = cur.fetchone()
        first_feature_id = row[0] if row else None
        
        return {
            "run": run,
            "stats": {
                "n_features": n_features,
                "n_embeddings": n_embeddings
            },
            "links": {
                "summary": f"/summary/run/{run_id}",
                "search_example": f"/peptide/search/{run_id}/{first_feature_id}" if first_feature_id else None
            }
        }
    finally:
        con.close()

@app.delete("/runs/{run_id}", status_code=status.HTTP_204_NO_CONTENT)
def delete_run(run_id: str, background_tasks: BackgroundTasks, user: User = Depends(current_active_user)):
    """
    Deletes a run and all its associated data (features, embeddings).
    """
    con = db.get_db_connection(DATA_DIR)
    try:
        # 1. Verify run ownership
        run = db.get_run(con, run_id)
        if run is None or str(run.user_id) != str(user.id):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found or you do not have permission to delete it.",
            )

        # 2. Delete all associated data from tables
        cur = con.cursor()
        cur.execute("DELETE FROM runs WHERE run_id=?", (run_id,))
        cur.execute("DELETE FROM features WHERE run_id=?", (run_id,))
        cur.execute("DELETE FROM peptide_embeddings WHERE run_id=?", (run_id,))
        con.commit()

        # 3. Rebuild the search index in the background
        # This is important to remove the deleted vectors from the search index.
        background_tasks.add_task(search.rebuild_faiss_index, db.get_db_connection(DATA_DIR), DATA_DIR)

        logging.info(f"User {user.email} deleted run {run_id}.")
        # No content is returned on success, per HTTP 204.

    finally:
        con.close()

@app.get("/runs/{run_id}/fingerprint")
def get_run_fingerprint(run_id: str, user: User = Depends(current_active_user)):
    """
    Generates a 'Semantic Fingerprint' for a run, including peptide clustering
    and a 2D projection.
    """
    logging.warning(f"ACCESSING /runs/{run_id}/fingerprint")
    con = db.get_db_connection(DATA_DIR)
    try:
        # 1. Authentication & Authorization
        run = db.get_run(con, run_id)
        if run is None or str(run.user_id) != str(user.id):
            logging.warning(f"Run {run_id} not found or user mismatch.")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found",
            )

        # 2. Fetch peptide embeddings for the run
        peptides = db.get_peptide_embeddings(con, run_id)
        if not peptides:
            logging.warning(f"No peptide embeddings found for run {run_id}.")
            raise HTTPException(404, "No peptide embeddings found for this run.")

        total_peptides = len(peptides)
        
        # 3. Sample if necessary
        sample_size = 1000
        if total_peptides > 2000:
            peptides_to_cluster = random.sample(peptides, sample_size)
        else:
            peptides_to_cluster = peptides
        
        # Prepare data for scikit-learn
        embedding_matrix = np.array([p['embedding'] for p in peptides_to_cluster])
        
        # 4. K-means clustering
        n_clusters = 4 # This could be made dynamic
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
        cluster_labels = kmeans.fit_predict(embedding_matrix)

        # 5. Compute cluster statistics
        clusters_summary = []
        for i in range(n_clusters):
            cluster_indices = np.where(cluster_labels == i)[0]
            if not cluster_indices.any():
                continue

            cluster_peptides = [peptides_to_cluster[j] for j in cluster_indices]
            
            mean_length = np.mean([p['length'] for p in cluster_peptides])
            mean_hydrophobicity = np.mean([p['hydrophobicity'] for p in cluster_peptides])
            mean_intensity = np.mean([p['intensity'] for p in cluster_peptides])

            clusters_summary.append({
                "id": i,
                "size": len(cluster_peptides),
                "mean_length": round(mean_length, 2),
                "mean_hydrophobicity": round(mean_hydrophobicity, 4),
                "mean_intensity": float(mean_intensity)
            })

        # 6. Dimensionality Reduction for plotting
        pca = PCA(n_components=2, random_state=42)
        embedding_2d = pca.fit_transform(embedding_matrix)
        
        embedding_2d_with_labels = [
            {"x": float(point[0]), "y": float(point[1]), "cluster_id": int(label)}
            for point, label in zip(embedding_2d, cluster_labels)
        ]

        # 7. Return JSON response
        return {
            "run_id": run_id,
            "total_peptides": total_peptides,
            "clusters": clusters_summary,
            "embedding_2d": embedding_2d_with_labels,
        }

    finally:
        con.close()

@app.get("/compare/{run_id_1}/{run_id_2}")
def compare_runs(run_id_1: str, run_id_2: str, user: User = Depends(current_active_user)):
    """
    Compare two runs based on distinct peptide sequences.

    Returns:
    - stats: counts + Jaccard index
    - shared_peptides: up to 100 shared peptide sequences
    - unique_run_1 / unique_run_2: up to 100 unique sequences per run

    This implementation is intentionally conservative and JSON-safe.
    """
    con = db.get_db_connection(DATA_DIR)
    try:
        # Access check â€• both runs must exist and belong to the current user
        run1 = db.get_run(con, run_id_1)
        run2 = db.get_run(con, run_id_2)

        if (
            run1 is None or run2 is None
            or str(run1.user_id) != str(user.id)
            or str(run2.user_id) != str(user.id)
        ):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run(s) not found or not owned by current user.",
            )

        cur = con.cursor()

        # Fetch distinct peptide sequences for run 1
        cur.execute(
            "SELECT DISTINCT peptide_sequence FROM features WHERE run_id=?",
            (run_id_1,),
        )
        raw_1 = [row[0] for row in cur.fetchall()]

        # Fetch distinct peptide sequences for run 2
        cur.execute(
            "SELECT DISTINCT peptide_sequence FROM features WHERE run_id=?",
            (run_id_2,),
        )
        raw_2 = [row[0] for row in cur.fetchall()]

        # Normalize everything to JSON-safe strings and drop None
        def normalize_list(raw_list):
            out = []
            for s in raw_list:
                if s is None:
                    continue
                if isinstance(s, bytes):
                    try:
                        out.append(s.decode("utf-8", errors="ignore"))
                    except Exception:
                        continue
                else:
                    out.append(str(s))
            return out

        list_1 = normalize_list(raw_1)
        list_2 = normalize_list(raw_2)

        seqs_1 = set(list_1)
        seqs_2 = set(list_2)

        shared = seqs_1 & seqs_2
        unique_1 = seqs_1 - seqs_2
        unique_2 = seqs_2 - seqs_1

        union = seqs_1 | seqs_2
        jaccard = len(shared) / len(union) if len(union) > 0 else 0.0

        return {
            "run_1": run_id_1,
            "run_2": run_id_2,
            "stats": {
                "total_run_1": len(seqs_1),
                "total_run_2": len(seqs_2),
                "shared_count": len(shared),
                "unique_run_1_count": len(unique_1),
                "unique_run_2_count": len(unique_2),
                "jaccard_index": jaccard,
            },
            "shared_peptides": list(shared)[:100],
            "unique_run_1": list(unique_1)[:100],
            "unique_run_2": list(unique_2)[:100],
        }

    except HTTPException:
        # Re-raise known HTTP exceptions unchanged
        raise
    except Exception as e:
        # Log unexpected errors and surface them as 500
        logging.exception(
            f"Unexpected error while comparing runs {run_id_1} and {run_id_2}: {e}"
        )
        raise HTTPException(
            status_code=500,
            detail=f"Compare runs failed due to an internal error: {e}",
        )
    finally:
        con.close()



@app.get("/export/embeddings/{run_id}")
def export_embeddings(run_id: str, user: User = Depends(current_active_user)):
    """
    Export peptide embeddings for a specific run as JSON.
    Returns a list of peptide embeddings with sequence, intensity, properties, and embedding vectors.
    """
    con = db.get_db_connection(DATA_DIR)
    try:
        run = db.get_run(con, run_id)
        if run is None or str(run.user_id) != str(user.id):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found",
            )
            
        embeddings = db.get_peptide_embeddings(con, run_id)
        return embeddings
    finally:
        con.close()

# --- Biophysics Logic ---
from collections import Counter

HYDROPHOBICITY_SCALE = {
    'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5, 'Q': -3.5, 'E': -3.5,
    'G': -0.4, 'H': -3.2, 'I': 4.5, 'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8,
    'P': -1.6, 'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2
}

def calculate_properties(sequence: str):
    if not sequence:
        return {"hydrophobicity": 0, "molecular_weight": 0, "charge": 0, "length": 0}
    
    # Filter for valid amino acids only for hydrophobicity calculation to avoid errors
    valid_seq = [aa for aa in sequence.upper() if aa in HYDROPHOBICITY_SCALE]
    hydro = sum(HYDROPHOBICITY_SCALE.get(aa, 0) for aa in valid_seq) / len(valid_seq) if valid_seq else 0
    
    mw = len(sequence) * 110
    pos = sum(sequence.upper().count(aa) for aa in ['K', 'R', 'H'])
    neg = sum(sequence.upper().count(aa) for aa in ['D', 'E'])
    return {"hydrophobicity": round(hydro, 2), "molecular_weight": mw, "charge": pos - neg, "length": len(sequence)}

@app.get("/dashboard-data/{run_id}")
def get_dashboard_data(run_id: str, user: User = Depends(current_active_user)):
    """
    Fetches features, calculates biophysical properties, and returns top 500 features.
    """
    con = db.get_db_connection(DATA_DIR)
    try:
        run = db.get_run(con, run_id)
        if run is None or str(run.user_id) != str(user.id):
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Run not found",
            )

        features = db.get_features_for_run(con, run_id)
        if not features:
            raise HTTPException(404, "Run not found or empty")
        
        # Sort by intensity descending
        # Sort by intensity descending (robust to None)
        features.sort(key=lambda x: (x.intensity is None, x.intensity or 0), reverse=True)
        top_features = features[:500]
        
        results = []
        for f in top_features:
            props = calculate_properties(f.peptide_sequence)
            
            # Extract stats from metadata if available
            meta = f.metadata or {}
            fc = meta.get("fold_change")
            qval = meta.get("q_value")
            pval = meta.get("p_value")
            
            results.append({
                "feature_id": f.feature_id,
                "sequence": f.peptide_sequence,
                "intensity": f.intensity,
                "properties": props,
                "stats": {
                    "fold_change": fc,
                    "q_value": qval,
                    "p_value": pval
                }
            })
            
        return {
            "run_id": run_id,
            "total_features": len(features),
            "data": results
        }
    finally:
        con.close()

# Mount static files (must be after all routes)
app.mount("/static", StaticFiles(directory="static", html=True), name="static")

if __name__ == "__main__":
    # This block allows running the app directly with `python app.py`
    # It will start the server on http://127.0.0.1:8080, which matches
    # the desired port for development and testing.
    uvicorn.run("app:app", host="127.0.0.1", port=8080, reload=True)


====================
FILE: .\auth.py
====================
import os
import uuid
from typing import Optional
from fastapi import Depends, Request
from fastapi_users import BaseUserManager, FastAPIUsers, UUIDIDMixin, schemas
from fastapi_users.authentication import (
    AuthenticationBackend,
    BearerTransport,
    JWTStrategy,
)
from fastapi_users.db import SQLAlchemyBaseUserTableUUID, SQLAlchemyUserDatabase
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.declarative import DeclarativeMeta, declarative_base

# --- Configuration ---
SECRET = "SECRET_KEY_FOR_MVP_ONLY_CHANGE_IN_PROD"
DATABASE_URL = "sqlite+aiosqlite:///./data/users.db"

# --- Database Setup ---
Base: DeclarativeMeta = declarative_base()

class User(SQLAlchemyBaseUserTableUUID, Base):
    pass

engine = create_async_engine(DATABASE_URL)
async_session_maker = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

async def get_async_session():
    async with async_session_maker() as session:
        yield session

async def get_user_db(session: AsyncSession = Depends(get_async_session)):
    yield SQLAlchemyUserDatabase(session, User)

# --- User Manager ---
class UserManager(UUIDIDMixin, BaseUserManager[User, uuid.UUID]):
    reset_password_token_secret = SECRET
    verification_token_secret = SECRET

    async def on_after_register(self, user: User, request: Optional[Request] = None):
        print(f"User {user.id} has registered.")

async def get_user_manager(user_db=Depends(get_user_db)):
    yield UserManager(user_db)

# --- Schemas ---
class UserRead(schemas.BaseUser[uuid.UUID]):
    pass

class UserCreate(schemas.BaseUserCreate):
    pass

class UserUpdate(schemas.BaseUserUpdate):
    pass

# --- Authentication Backend ---
bearer_transport = BearerTransport(tokenUrl="auth/jwt/login")

def get_jwt_strategy() -> JWTStrategy:
    return JWTStrategy(secret=SECRET, lifetime_seconds=3600)

auth_backend = AuthenticationBackend(
    name="jwt",
    transport=bearer_transport,
    get_strategy=get_jwt_strategy,
)

fastapi_users = FastAPIUsers[User, uuid.UUID](
    get_user_manager,
    [auth_backend],
)

current_active_user = fastapi_users.current_user(active=True)

# --- Init DB Utility ---
async def create_db_and_tables():
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)


====================
FILE: .\check_config.py
====================
"""
Quick API Configuration Helper
Run this to check your current setup and get instructions
"""
import os
from dotenv import load_dotenv

load_dotenv()

print("=" * 60)
print("ðŸ” GEMINI API CONFIGURATION CHECK")
print("=" * 60)

# Check for old variable
old_key = os.getenv("GEMINI_API_KEY")
if old_key:
    print("âš ï¸  WARNING: Found GEMINI_API_KEY in your .env file")
    print("   This is the OLD variable name and won't work!")
    print()

# Check for new variable
new_key = os.getenv("GOOGLE_API_KEY")
if new_key:
    print(f"âœ… GOOGLE_API_KEY found (starts with: {new_key[:10]}...)")
    print("   Configuration looks correct!")
else:
    print("âŒ GOOGLE_API_KEY not found!")
    print()
    print("ðŸ“ ACTION REQUIRED:")
    print("   1. Open your .env file")
    if old_key:
        print("   2. Change: GEMINI_API_KEY=... ")
        print("      To:     GOOGLE_API_KEY=...")
    else:
        print("   2. Add this line: GOOGLE_API_KEY=your_api_key_here")
    print("   3. Save the file")
    print("   4. Run: python test_gemini_api.py")

print()
print("=" * 60)
print("ðŸ“š QUICK REFERENCE")
print("=" * 60)
print("Environment Variable: GOOGLE_API_KEY")
print("Model Name:          gemini-2.0-flash-exp")
print("Test Command:        python test_gemini_api.py")
print("Start Server:        uvicorn app:app --reload")
print("=" * 60)


====================
FILE: .\db.py
====================
import sqlite3
import os
import json
from typing import List, Dict, Any, Optional, Tuple

import numpy as np
import models

# --- Configuration ---
SCHEMA_VERSION = "immuno-0.1.0"

def get_db_path(data_dir: str) -> str:
    return os.path.join(data_dir, "immuno.sqlite")

def get_db_connection(data_dir: str) -> sqlite3.Connection:
    """Establishes a connection to the SQLite database and ensures tables exist."""
    db_path = get_db_path(data_dir)
    con = sqlite3.connect(db_path)
    con.execute("PRAGMA foreign_keys = ON") # Enable foreign key constraints
    _create_tables(con)
    return con

def _create_tables(con: sqlite3.Connection):
    """Creates database tables if they do not already exist."""
    con.execute("""CREATE TABLE IF NOT EXISTS runs(
        run_id TEXT PRIMARY KEY,
        user_id TEXT,
        instrument TEXT,
        method TEXT,
        polarity TEXT,
        schema_version TEXT,
        meta_json TEXT,
        n_features_to_embed INTEGER,
        n_features_embedded INTEGER
    )""")
    
    con.execute("""CREATE TABLE IF NOT EXISTS features(
        run_id TEXT,
        feature_id TEXT,
        mz REAL,
        rt_sec REAL,
        intensity REAL,
        adduct TEXT,
        polarity TEXT,
        annotation_name TEXT, -- Stores peptide sequence
        annotation_score REAL,
        meta_json TEXT,
        PRIMARY KEY(run_id, feature_id),
        FOREIGN KEY(run_id) REFERENCES runs(run_id) ON DELETE CASCADE
    )""")
    
    # Migration: Attempt to add meta_json column if it doesn't exist
    try:
        con.execute("ALTER TABLE features ADD COLUMN meta_json TEXT")
    except sqlite3.OperationalError:
        pass # Column likely already exists

    con.execute("""CREATE TABLE IF NOT EXISTS embeddings(
        run_id TEXT,
        feature_id TEXT,
        method TEXT,
        polarity TEXT,
        vec_json TEXT,
        PRIMARY KEY(run_id, feature_id),
        FOREIGN KEY(run_id, feature_id) REFERENCES features(run_id, feature_id) ON DELETE CASCADE
    )""")

    con.execute("""CREATE TABLE IF NOT EXISTS peptide_embeddings(
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        run_id TEXT,
        user_id TEXT,
        feature_id TEXT, -- Added feature_id
        sequence TEXT,
        intensity REAL NOT NULL,
        length INTEGER,
        charge INTEGER,
        hydrophobicity REAL,
        embedding TEXT, -- JSON list of floats
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(run_id, feature_id), -- Ensure unique embedding per run and feature
        FOREIGN KEY(run_id) REFERENCES runs(run_id) ON DELETE CASCADE,
        FOREIGN KEY(run_id, feature_id) REFERENCES features(run_id, feature_id) ON DELETE CASCADE
    )""")
    con.commit()

# --- Helper functions for DB operations ---

def insert_run(con: sqlite3.Connection, run_id: str, meta_dict: Dict[str, Any], user_id: Optional[str] = None):
    """Inserts or replaces a run's metadata into the database."""
    con.execute(
        "INSERT OR REPLACE INTO runs(run_id, user_id, instrument, method, polarity, schema_version, meta_json) VALUES(?,?,?,?,?,?,?)",
        (run_id, user_id, meta_dict.get("instrument"), meta_dict.get("method"), meta_dict.get("polarity"), SCHEMA_VERSION, json.dumps(meta_dict)),
    )

def insert_feature(con: sqlite3.Connection, run_id: str, feature_data: models.Feature):
    """Inserts or replaces a feature (peptide) into the database."""
    con.execute(
        """INSERT OR REPLACE INTO features(run_id, feature_id, mz, rt_sec, intensity, adduct, polarity, annotation_name, annotation_score, meta_json)
           VALUES(?,?,?,?,?,?,?,?,?,?)""",
        (
            run_id,
            feature_data.feature_id,
            feature_data.mz,
            feature_data.rt_sec,
            feature_data.intensity,
            feature_data.adduct,
            feature_data.polarity,
            feature_data.peptide_sequence, # Map peptide_sequence to annotation_name DB column
            feature_data.annotation_score,
            json.dumps(feature_data.metadata)
        ),
    )

def insert_embedding(con: sqlite3.Connection, run_id: str, feature_id: str, method: str, polarity: str, vector: List[float]):
    """Inserts or replaces a peptide embedding into the database (Old table)."""
    con.execute(
        """INSERT OR REPLACE INTO embeddings(run_id, feature_id, method, polarity, vec_json)
           VALUES(?,?,?,?,?)""",
        (run_id, feature_id, method, polarity, json.dumps(vector.tolist())),
    )

def insert_peptide_embedding(con: sqlite3.Connection, run_id: str, user_id: str, feature_id: str, sequence: str, intensity: float, 
                             length: int, charge: int, hydrophobicity: float, vector: np.ndarray):
    """Inserts a row into the new peptide_embeddings table."""
    con.execute(
        """INSERT INTO peptide_embeddings(run_id, user_id, feature_id, sequence, intensity, length, charge, hydrophobicity, embedding)
           VALUES(?,?,?,?,?,?,?,?,?)""",
        (run_id, user_id, feature_id, sequence, intensity, length, charge, hydrophobicity, json.dumps(vector.tolist()))
    )

def get_run(con: sqlite3.Connection, run_id: str) -> Optional[models.Run]:
    """Retrieves a run's metadata."""
    cur = con.cursor()
    cur.execute("SELECT run_id, user_id, instrument, method, polarity, schema_version, meta_json FROM runs WHERE run_id=?", (run_id,))
    row = cur.fetchone()
    if row:
        return models.Run(
            run_id=row[0],
            user_id=row[1],
            instrument=row[2],
            method=row[3],
            polarity=row[4],
            schema_version=row[5],
            meta=json.loads(row[6]) if row[6] else {}
        )
    return None

def get_features_for_run(con: sqlite3.Connection, run_id: str) -> List[models.Feature]:
    """Retrieves all features (peptides) for a given run."""
    cur = con.cursor()
    cur.execute("SELECT feature_id, mz, rt_sec, intensity, adduct, polarity, annotation_name, annotation_score, meta_json FROM features WHERE run_id=?", (run_id,))
    results = []
    for row in cur.fetchall():
        meta = json.loads(row[8]) if row[8] else {}
        results.append(models.Feature(
            feature_id=row[0], 
            mz=row[1], 
            rt_sec=row[2], 
            intensity=row[3], 
            adduct=row[4], 
            polarity=row[5], 
            peptide_sequence=row[6], 
            annotation_score=row[7],
            metadata=meta
        ))
    return results

def get_embedding(con: sqlite3.Connection, run_id: str, feature_id: str) -> Optional[List[float]]:
    """Retrieves a specific peptide embedding."""
    cur = con.cursor()
    cur.execute("SELECT vec_json FROM embeddings WHERE run_id=? AND feature_id=?", (run_id, feature_id))
    row = cur.fetchone()
    return json.loads(row[0]) if row else None

def get_feature_properties(con: sqlite3.Connection, run_id: str, feature_id: str) -> Optional[Tuple[str, float]]:
    """Retrieves the peptide sequence and intensity for a given feature."""
    cur = con.cursor()
    cur.execute("SELECT annotation_name, intensity FROM features WHERE run_id=? AND feature_id=? LIMIT 1", (run_id, feature_id))
    row = cur.fetchone()
    return (row[0], row[1]) if row else None

def get_all_embeddings_data(con: sqlite3.Connection) -> List[Tuple[str, str, str]]:
    """Retrieves all embedding data (run_id, feature_id, embedding) from the database."""
    cur = con.cursor()
    cur.execute("SELECT run_id, feature_id, embedding FROM peptide_embeddings")
    return cur.fetchall()

def get_peptide_embeddings(con: sqlite3.Connection, run_id: str) -> List[Dict[str, Any]]:
    """Retrieves all peptide embeddings for a specific run."""
    cur = con.cursor()
    cur.execute("""
        SELECT sequence, intensity, length, charge, hydrophobicity, embedding 
        FROM peptide_embeddings 
        WHERE run_id=?
    """, (run_id,))
    
    results = []
    for row in cur.fetchall():
        results.append({
            "sequence": row[0],
            "intensity": row[1],
            "length": row[2],
            "charge": row[3],
            "hydrophobicity": row[4],
            "embedding": json.loads(row[5]) if row[5] else []
        })
    return results

def get_run_summaries(con: sqlite3.Connection, user_id: Optional[str] = None) -> List[Dict[str, Any]]:
    """Retrievels a summary of all runs with feature and embedding counts. Optionally filtered by user_id."""
    cur = con.cursor()
    
    base_query = """
        SELECT
            r.run_id,
            r.instrument,
            r.method,
            r.polarity,
            r.meta_json,
            (SELECT COUNT(*) FROM features f WHERE f.run_id = r.run_id) as n_features,
            (SELECT COUNT(*) FROM peptide_embeddings pe WHERE pe.run_id = r.run_id) as n_embeddings
        FROM
            runs r
    """
    
    params = []
    if user_id:
        base_query += " WHERE r.user_id = ?"
        params.append(user_id)
        
    cur.execute(base_query, tuple(params))
    
    results = []
    for row in cur.fetchall():
        meta = json.loads(row[4]) if row[4] else {}
        results.append({
            "run_id": row[0],
            "instrument": row[1],
            "method": row[2],
            "polarity": row[3],
            "original_filename": meta.get("original_filename"),
            "n_features": row[5],
            "n_embeddings": row[6]
        })
    return results

====================
FILE: .\demo_checklist.py
====================
"""
Pre-Demo Checklist Script
Verifies all systems are ready for the proteomics demo
"""

import os
import sys
from pathlib import Path

def check_env():
    """Check environment variables"""
    print("ðŸ” Checking environment variables...")
    api_key = os.getenv("GOOGLE_API_KEY")
    if api_key:
        print(f"  âœ… GOOGLE_API_KEY found (starts with: {api_key[:10]}...)")
        return True
    else:
        print("  âŒ GOOGLE_API_KEY not found!")
        print("     Run: python update_env.py")
        return False

def check_demo_data():
    """Check demo datasets exist"""
    print("\nðŸ“ Checking demo datasets...")
    datasets = [
        "data/melanoma_peptides_demo.csv",
        "data/mpnst_peptides_demo.csv",
        "demo_tumor_data.csv",
        "data/Melanoma vs. MPNST.csv"
    ]
    
    all_exist = True
    for dataset in datasets:
        if Path(dataset).exists():
            size = Path(dataset).stat().st_size
            print(f"  âœ… {dataset} ({size:,} bytes)")
        else:
            print(f"  âŒ {dataset} NOT FOUND")
            all_exist = False
    
    return all_exist

def check_static_files():
    """Check UI files exist"""
    print("\nðŸŒ Checking UI files...")
    ui_files = [
        "static/login.html",
        "static/runs.html",
        "static/simple_dashboard.html",
        "static/summary.html",
        "static/search.html",
        "static/compare.html"
    ]
    
    all_exist = True
    for file in ui_files:
        if Path(file).exists():
            print(f"  âœ… {file}")
        else:
            print(f"  âŒ {file} NOT FOUND")
            all_exist = False
    
    return all_exist

def check_modules():
    """Check Python modules are importable"""
    print("\nðŸ Checking Python modules...")
    modules = [
        "fastapi",
        "uvicorn",
        "google.generativeai",
        "faiss",
        "pandas",
        "numpy"
    ]
    
    all_imported = True
    for module in modules:
        try:
            __import__(module)
            print(f"  âœ… {module}")
        except ImportError:
            print(f"  âŒ {module} NOT INSTALLED")
            all_imported = False
    
    return all_imported

def check_database():
    """Check database exists"""
    print("\nðŸ’¾ Checking database...")
    db_path = Path("data/immuno.db")
    if db_path.exists():
        size = db_path.stat().st_size
        print(f"  âœ… Database exists ({size:,} bytes)")
        return True
    else:
        print(f"  âš ï¸  Database not found (will be created on first run)")
        return True  # Not critical

def print_demo_urls():
    """Print important URLs"""
    print("\nðŸ”— Demo URLs:")
    print("  ðŸ“ Login:      http://127.0.0.1:8080/static/login.html")
    print("  ðŸ“¤ Upload:     http://127.0.0.1:8080/upload")
    print("  ðŸ“Š Runs:       http://127.0.0.1:8080/static/runs.html")
    print("  ðŸ“š API Docs:   http://127.0.0.1:8080/docs")

def print_demo_credentials():
    """Print demo credentials"""
    print("\nðŸ”‘ Demo Credentials:")
    print("  Email:    test@example.com")
    print("  Password: password123")
    print("  (Or register new user via UI)")

def main():
    print("=" * 60)
    print("ðŸ§¬ IMMUNO-ENGINE DEMO PRE-FLIGHT CHECKLIST")
    print("=" * 60)
    
    checks = [
        check_env(),
        check_demo_data(),
        check_static_files(),
        check_modules(),
        check_database()
    ]
    
    print("\n" + "=" * 60)
    if all(checks):
        print("âœ… ALL SYSTEMS GO! Ready for demo.")
        print_demo_urls()
        print_demo_credentials()
        print("\nðŸš€ To start the server:")
        print("   uvicorn app:app --reload --port 8080")
    else:
        print("âŒ SOME CHECKS FAILED - Please fix issues above")
        return 1
    
    print("=" * 60)
    return 0

if __name__ == "__main__":
    sys.exit(main())


====================
FILE: .\demo_export.py
====================
"""
Quick demo script to test the export embeddings endpoint.
This simulates what you would do in the browser console.
"""

import requests
import json

BASE_URL = "http://127.0.0.1:8080"

# Step 1: Login to get a token
print("ðŸ” Logging in...")
login_data = {
    "username": "user_a@example.com",
    "password": "password123"
}

res = requests.post(f"{BASE_URL}/auth/jwt/login", data=login_data)
if res.status_code != 200:
    print(f"âŒ Login failed: {res.status_code}")
    exit(1)

token = res.json()["access_token"]
print(f"âœ… Login successful")

# Step 2: Get list of runs
print("\nðŸ“‹ Fetching your runs...")
headers = {"Authorization": f"Bearer {token}"}
res = requests.get(f"{BASE_URL}/runs", headers=headers)

if res.status_code != 200:
    print(f"âŒ Failed to get runs: {res.status_code}")
    exit(1)

runs = res.json()
if not runs:
    print("âš ï¸  No runs found. Upload some data first!")
    exit(0)

print(f"Found {len(runs)} run(s):")
for run in runs[:5]:  # Show first 5
    print(f"  - {run['run_id']} ({run.get('n_embeddings', 0)} embeddings)")

# Step 3: Export embeddings from the first run
run_id = runs[0]['run_id']
print(f"\nðŸ“¤ Exporting embeddings from run: {run_id}")

res = requests.get(f"{BASE_URL}/export/embeddings/{run_id}", headers=headers)

if res.status_code != 200:
    print(f"âŒ Export failed: {res.status_code}")
    print(f"Response: {res.text}")
    exit(1)

embeddings = res.json()
print(f"âœ… Export successful!")
print(f"\nðŸ“Š Results:")
print(f"  Total embeddings: {len(embeddings)}")

if embeddings:
    print(f"\nðŸ”¬ First embedding sample:")
    first = embeddings[0]
    print(f"  Sequence: {first['sequence']}")
    print(f"  Intensity: {first['intensity']}")
    print(f"  Length: {first['length']}")
    print(f"  Charge: {first['charge']}")
    print(f"  Hydrophobicity: {first['hydrophobicity']}")
    print(f"  Embedding dimensions: {len(first['embedding'])}")
    print(f"  First 5 values: {first['embedding'][:5]}")
    
    # Show a few more sequences
    if len(embeddings) > 1:
        print(f"\nðŸ“ All sequences in this run:")
        for i, emb in enumerate(embeddings[:10], 1):
            print(f"  {i}. {emb['sequence']} (intensity: {emb['intensity']})")
        if len(embeddings) > 10:
            print(f"  ... and {len(embeddings) - 10} more")
else:
    print("  âš ï¸  No embeddings found (background task may still be processing)")

print("\nâœ¨ Done!")


====================
FILE: .\demo_export_simple.py
====================
"""
Quick demo to show the export endpoint working with TEST_EXPORT_RUN
"""

import requests
import json

BASE_URL = "http://127.0.0.1:8080"

# Login
login_data = {"username": "user_a@example.com", "password": "password123"}
res = requests.post(f"{BASE_URL}/auth/jwt/login", data=login_data)
token = res.json()["access_token"]
headers = {"Authorization": f"Bearer {token}"}

# Export embeddings from TEST_EXPORT_RUN
run_id = "TEST_EXPORT_RUN"
print(f"ðŸ“¤ Exporting embeddings from: {run_id}\n")

res = requests.get(f"{BASE_URL}/export/embeddings/{run_id}", headers=headers)
embeddings = res.json()

print(f"âœ… Got {len(embeddings)} embeddings\n")
print("=" * 60)

for i, emb in enumerate(embeddings, 1):
    print(f"\nPeptide #{i}:")
    print(f"  Sequence:       {emb['sequence']}")
    print(f"  Intensity:      {emb['intensity']}")
    print(f"  Length:         {emb['length']} amino acids")
    print(f"  Charge:         {emb['charge']}")
    print(f"  Hydrophobicity: {emb['hydrophobicity']}")
    print(f"  Embedding:      {len(emb['embedding'])}-dimensional vector")
    print(f"                  {emb['embedding'][:5]}...")

print("\n" + "=" * 60)
print("\nðŸ’¡ This is what you'd get in the browser console!")
print("\nTo try it yourself, open the browser console at")
print("http://127.0.0.1:8080/static/runs.html and run:")
print(f"""
fetch("http://127.0.0.1:8080/export/embeddings/{run_id}", {{
  headers: {{
    "Authorization": "Bearer " + localStorage.getItem("token")
  }}
}})
.then(r => r.json())
.then(console.log)
""")


====================
FILE: .\embeddings.py
====================
import numpy as np

# --- Configuration ---
# Dimension of the peptide embedding vector.
EMBEDDING_DIM = 16

_AMINO_ALPHABET = "ACDEFGHIKLMNPQRSTVWY"
_AMINO_INDEX = {aa: i for i, aa in enumerate(_AMINO_ALPHABET)}


def peptide_to_vector(sequence: str) -> np.ndarray:
    """
    Very simple, fast, *local* embedder that does NOT require external libraries.

    It turns a peptide into a small numeric vector:
      - length
      - mean position in alphabet
      - fraction of charged residues (D, E, K, R, H)
      - fraction of hydrophobic residues (A, V, I, L, M, F, Y, W)
      - plus a small fixed-length bag-of-amino-acids representation

    Later, this implementation can be replaced with a real ProtTrans-based embedder,
    but for now it's a lightweight, dependency-free embedding that always returns
    an EMBEDDING_DIM-dimensional vector.
    """
    if not sequence or not isinstance(sequence, str):
        return np.zeros((EMBEDDING_DIM,), dtype=np.float32)

    seq = sequence.strip().upper()
    if not seq:
        return np.zeros((EMBEDDING_DIM,), dtype=np.float32)

    length = len(seq)

    charged = set("DEKRH")
    hydrophobic = set("AVILMFWY")

    charged_count = sum(1 for aa in seq if aa in charged)
    hydrophobic_count = sum(1 for aa in seq if aa in hydrophobic)

    charged_frac = charged_count / length
    hydrophobic_frac = hydrophobic_count / length

    indices = [_AMINO_INDEX.get(aa, 0) for aa in seq]
    mean_idx = float(sum(indices)) / length

    bag_dim = EMBEDDING_DIM - 4  # we already used 4 slots above
    bag = np.zeros((bag_dim,), dtype=np.float32)

    for aa in seq:
        idx = _AMINO_INDEX.get(aa)
        if idx is not None and idx < bag_dim:
            bag[idx] += 1.0

    if bag.sum() > 0:
        bag = bag / bag.sum()

    vec = np.concatenate(
        [
            np.array(
                [length, mean_idx, charged_frac, hydrophobic_frac],
                dtype=np.float32,
            ),
            bag.astype(np.float32),
        ]
    )

    if vec.shape[0] != EMBEDDING_DIM:
        vec = np.resize(vec, (EMBEDDING_DIM,)).astype(np.float32)

    return vec

====================
FILE: .\fix_search.py
====================
"""
Quick fix script to update search.html with dropdowns and correct API field names
"""

# Read the current basic search.html
with open('static/search.html', 'r', encoding='utf-8') as f:
    content = f.read()

# Create the new version with dropdowns
new_content = '''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Peptide Search Explorer</title>
    <style>
        body { font-family: sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; }
        .form-group { margin-bottom: 15px; }
        label { display: block; margin-bottom: 5px; font-weight: bold; }
        select { width: 100%; padding: 8px; box-sizing: border-box; }
        button { padding: 10px 20px; background-color: #007bff; color: white; border: none; cursor: pointer; margin-right: 10px; }
        button:hover { background-color: #0056b3; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }
        #results, #explanation { margin-top: 20px; }
        #explanation { padding: 15px; background-color: #f0f7ff; border-radius: 4px; display: none; }
        table { width: 100%; border-collapse: collapse; margin-top: 10px; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        .error { color: red; }
        .peptide-props { background: #e3f2fd; padding: 10px; border-radius: 4px; margin: 10px 0; }
        .explanation-text { line-height: 1.6; white-space: pre-wrap; margin-top: 10px; }
    </style>
</head>
<body>
    <h1>Peptide Search Explorer</h1>
    
    <div class="form-group">
        <label for="runId">Select Run:</label>
        <select id="runId" onchange="loadFeatures()">
            <option value="">Loading runs...</option>
        </select>
    </div>
    
    <div class="form-group">
        <label for="featureId">Select Peptide:</label>
        <select id="featureId" disabled>
            <option value="">First select a run</option>
        </select>
    </div>
    
    <button onclick="search()">ðŸ” Search Similar Peptides</button>
    <button id="explainBtn" onclick="explainPeptide()" disabled>ðŸ§  Explain This Peptide</button>
    
    <div id="explanation"></div>
    <div id="results"></div>

    <script>
        let currentRunId = '';
        let currentFeatureId = '';
        const token = localStorage.getItem('token');

        window.addEventListener('DOMContentLoaded', loadRuns);

        async function loadRuns() {
            const runSelect = document.getElementById('runId');
            try {
                const headers = token ? { 'Authorization': 'Bearer ' + token } : {};
                const response = await fetch('/runs', { headers });
                if (!response.ok) throw new Error('Failed to load runs');
                const runs = await response.json();
                if (runs.length === 0) {
                    runSelect.innerHTML = '<option value="">No runs available</option>';
                    return;
                }
                runSelect.innerHTML = '<option value="">-- Select a run --</option>' +
                    runs.map(run => `<option value="${run.run_id}">${run.run_id} (${run.n_features} features)</option>`).join('');
            } catch (e) {
                runSelect.innerHTML = `<option value="">Error: ${e.message}</option>`;
            }
        }

        async function loadFeatures() {
            const runId = document.getElementById('runId').value;
            const featureSelect = document.getElementById('featureId');
            const explainBtn = document.getElementById('explainBtn');
            featureSelect.disabled = true;
            featureSelect.innerHTML = '<option value="">Loading features...</option>';
            document.getElementById('results').innerHTML = '';
            document.getElementById('explanation').style.display = 'none';
            explainBtn.disabled = true;
            if (!runId) {
                featureSelect.innerHTML = '<option value="">First select a run</option>';
                return;
            }
            try {
                const headers = token ? { 'Authorization': 'Bearer ' + token } : {};
                const response = await fetch(`/dashboard-data/${runId}`, { headers });
                if (!response.ok) throw new Error('Failed to load features');
                const data = await response.json();
                const features = data.data;
                if (features.length === 0) {
                    featureSelect.innerHTML = '<option value="">No features available</option>';
                    return;
                }
                featureSelect.innerHTML = '<option value="">-- Select a peptide --</option>' +
                    features.map(f => `<option value="${f.feature_id}">${f.sequence} (intensity: ${f.intensity.toExponential(2)})</option>`).join('');
                featureSelect.disabled = false;
            } catch (e) {
                featureSelect.innerHTML = `<option value="">Error: ${e.message}</option>`;
            }
        }

        async function search() {
            const runId = document.getElementById('runId').value;
            const featureId = document.getElementById('featureId').value;
            const resultsDiv = document.getElementById('results');
            const explainBtn = document.getElementById('explainBtn');
            if (!runId || !featureId) {
                resultsDiv.innerHTML = '<p class="error">Please select both a run and a peptide.</p>';
                return;
            }
            currentRunId = runId;
            currentFeatureId = featureId;
            resultsDiv.innerHTML = '<p>Searching...</p>';
            document.getElementById('explanation').style.display = 'none';
            try {
                const headers = token ? { 'Authorization': 'Bearer ' + token } : {};
                const response = await fetch(`/peptide/search/${runId}/${featureId}`, { headers });
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.detail || 'Search failed');
                }
                const data = await response.json();
                displayResults(data);
                explainBtn.disabled = false;
            } catch (e) {
                resultsDiv.innerHTML = `<p class="error">Error: ${e.message}</p>`;
                explainBtn.disabled = true;
            }
        }

        function displayResults(data) {
            const resultsDiv = document.getElementById('results');
            let html = `<h3>Results for ${data.query.feature_id}</h3>`;
            if (!data.neighbors || data.neighbors.length === 0) {
                html += '<p>No similar peptides found.</p>';
            } else {
                html += '<table><thead><tr><th>Feature ID</th><th>Sequence</th><th>Similarity</th></tr></thead><tbody>';
                data.neighbors.forEach(item => {
                    html += `<tr><td>${item.feature_id}</td><td>${item.peptide_sequence || 'N/A'}</td><td>${(item.similarity * 100).toFixed(1)}%</td></tr>`;
                });
                html += '</tbody></table>';
            }
            resultsDiv.innerHTML = html;
        }

        async function explainPeptide() {
            if (!currentRunId || !currentFeatureId) {
                alert('Please search for a peptide first');
                return;
            }
            const explainBtn = document.getElementById('explainBtn');
            const explanationDiv = document.getElementById('explanation');
            explainBtn.textContent = 'â³ Generating explanation...';
            explainBtn.disabled = true;
            explanationDiv.style.display = 'none';
            try {
                const headers = token ? { 'Authorization': 'Bearer ' + token } : {};
                const response = await fetch(`/peptide/explain/${currentRunId}/${currentFeatureId}`, { headers });
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.detail || 'Explanation failed');
                }
                const data = await response.json();
                let html = `<h3>AI Explanation</h3><div class="peptide-props"><strong>Peptide:</strong> <code>${data.sequence}</code><br><strong>Length:</strong> ${data.length} AA | <strong>Intensity:</strong> ${data.intensity.toExponential(2)} | <strong>Hydrophobicity:</strong> ${data.hydrophobicity} | <strong>Charge:</strong> ${data.charge > 0 ? '+' + data.charge : data.charge}</div><div class="explanation-text">${data.explanation}</div>`;
                if (data.neighbors && data.neighbors.length > 0) {
                    html += `<details style="margin-top: 15px;"><summary style="cursor: pointer; font-weight: bold;">Similar Peptides Used for Analysis</summary><ul style="margin-top: 10px;">`;
                    data.neighbors.forEach(n => {
                        html += `<li><code>${n.sequence}</code> (similarity: ${n.similarity_score}, intensity: ${n.intensity.toExponential(2)})</li>`;
                    });
                    html += '</ul></details>';
                }
                explanationDiv.innerHTML = html;
                explanationDiv.style.display = 'block';
            } catch (e) {
                explanationDiv.innerHTML = `<div class="error"><strong>Error:</strong> ${e.message}</div>`;
                explanationDiv.style.display = 'block';
            } finally {
                explainBtn.textContent = 'ðŸ§  Explain This Peptide';
                explainBtn.disabled = false;
            }
        }
    </script>
</body>
</html>'''

# Write the new version
with open('static/search.html', 'w', encoding='utf-8') as f:
    f.write(new_content)

print("âœ… search.html updated successfully!")
print("- Added cascading dropdowns for runs and peptides")
print("- Fixed API field names (neighbors instead of nearest_neighbors)")
print("- Added explain peptide functionality")


====================
FILE: .\importers.py
====================
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional
from models import Feature

def parse_tumor_csv(df: pd.DataFrame) -> List[Feature]:
    """
    Parses tumor proteomics CSVs with stats columns.
    Expected columns: Accession, Description, samples..., Fold Change, q-value, etc.
    """
    features = []
    
    # Identify sample columns (columns that are not stats or metadata)
    # This is a heuristic: exclude known non-sample columns
    exclude_cols = {
        "Accession", "Description", "Gene Symbol", "Entrez Gene ID", 
        "Fold Change", "Log2 Fold Change", "p-value", "q-value", 
        "Wilcoxon p-value", "t-test p-value", "Resampled p-value",
        "Significant", "Pi Score"
    }
    
    # Normalize columns for easier matching
    df_cols_map = {c.lower(): c for c in df.columns}
    
    # Find key columns
    acc_col = df_cols_map.get("accession")
    desc_col = df_cols_map.get("description")
    
    if not acc_col:
        # Fallback: try to find a column that looks like an ID
        for c in df.columns:
            if "accession" in c.lower() or "protein" in c.lower() or "id" in c.lower():
                acc_col = c
                break
    
    if not acc_col:
        raise ValueError("Could not identify Accession/ID column in tumor CSV.")

    # Identify stats columns
    stats_cols = []
    for c in df.columns:
        lower_c = c.lower()
        if "fold change" in lower_c or "p-value" in lower_c or "q-value" in lower_c or "score" in lower_c:
            stats_cols.append(c)
            
    # Identify sample columns (everything else)
    sample_cols = [c for c in df.columns if c not in exclude_cols and c not in stats_cols and c != acc_col and c != desc_col]
    
    for i, row in df.iterrows():
        accession = str(row[acc_col])
        description = str(row[desc_col]) if desc_col else ""
        
        # Calculate a representative intensity (e.g., max or mean of samples)
        # For the MVP, we'll just take the max to have something non-zero
        intensities = [float(row[c]) for c in sample_cols if pd.to_numeric(row[c], errors='coerce') >= 0]
        rep_intensity = max(intensities) if intensities else 0.0
        
        # Collect stats into metadata
        meta = {
            "description": description,
            "stats": {c: row[c] for c in stats_cols},
            "samples": {c: row[c] for c in sample_cols}
        }
        
        features.append(Feature(
            feature_id=f"TUMOR_{i}_{accession}",
            peptide_sequence=accession, # Using Accession as sequence for now
            intensity=rep_intensity,
            mz=0.0, # Not applicable
            rt_sec=None,
            adduct=None,
            polarity=None,
            metadata=meta or {}
        ))
        
    return features

def detect_format(df: pd.DataFrame) -> str:
    """
    Simple heuristic to detect the format of the uploaded CSV.
    """
    cols = set(df.columns)
    # Check for tumor format specific columns
    lower_cols = {c.lower() for c in cols}
    if "accession" in lower_cols and ("fold change" in lower_cols or "q-value" in lower_cols):
        return "tumor_csv"
        
    if "Sequence" in cols and "Intensity" in cols and "Modified sequence" in cols:
        return "maxquant"
    if "Precursor.Id" in cols and "Stripped.Sequence" in cols:
        return "diann"
    if "PEP.StrippedSequence" in cols:
        return "spectronaut"
    return "generic"

def parse_upload(df: pd.DataFrame, fmt: str = "auto") -> List[Feature]:
    if fmt == "auto":
        fmt = detect_format(df)
    
    if fmt == "tumor_csv":
        return parse_tumor_csv(df)
    elif fmt == "maxquant":
        return parse_maxquant(df)
    elif fmt == "diann":
        return parse_diann(df)
    elif fmt == "spectronaut":
        return parse_spectronaut(df)
    else:
        return parse_generic(df)

def parse_generic(df: pd.DataFrame) -> List[Feature]:
    """
    Parses a generic CSV with 'feature_id', 'peptide_sequence', 'intensity' columns.
    """
    features = []
    # Normalize column names to lowercase for easier matching
    df.columns = [c.lower() for c in df.columns]
    
    # Map common variations
    col_map = {
        "feature_id": ["feature_id", "id", "peptide_id"],
        "peptide_sequence": ["peptide_sequence", "sequence", "annotation_name", "seq"],
        "intensity": ["intensity", "area", "abundance"],
        "mz": ["mz", "m/z", "mass_to_charge"],
        "rt_sec": ["rt_sec", "rt", "retention_time"],
        "adduct": ["adduct", "charge_state"], # approximate
        "polarity": ["polarity"]
    }

    def get_col(variations):
        for v in variations:
            if v in df.columns:
                return v
        return None

    fid_col = get_col(col_map["feature_id"])
    seq_col = get_col(col_map["peptide_sequence"])
    int_col = get_col(col_map["intensity"])
    mz_col = get_col(col_map["mz"])
    rt_col = get_col(col_map["rt_sec"])

    if not (fid_col and seq_col and int_col):
        raise ValueError(f"Generic CSV missing required columns. Found: {list(df.columns)}")

    for i, row in df.iterrows():
        try:
            intensity_val = float(row[int_col]) if pd.notna(row[int_col]) else 0.0
        except (ValueError, TypeError):
            intensity_val = 0.0

        features.append(Feature(
            feature_id=str(row[fid_col]),
            peptide_sequence=str(row[seq_col]),
            intensity=intensity_val,
            mz=float(row[mz_col]) if mz_col and pd.notna(row[mz_col]) else 0.0,
            rt_sec=float(row[rt_col]) if rt_col and pd.notna(row[rt_col]) else None,
            adduct=None,
            polarity=None,
            annotation_score=None,
            metadata={}
        ))
    return features

def parse_maxquant(df: pd.DataFrame) -> List[Feature]:
    """
    Parses MaxQuant peptides.txt format.
    """
    features = []
    # MaxQuant usually has 'Sequence', 'Intensity', 'id'
    for i, row in df.iterrows():
        try:
            intensity_val = float(row.get("Intensity", 0.0))
        except (ValueError, TypeError):
            intensity_val = 0.0
            
        features.append(Feature(
            feature_id=str(row.get("id", f"MQ_{i}")),
            peptide_sequence=str(row.get("Sequence", "")),
            intensity=intensity_val,
            mz=float(row.get("Mass", 0.0)), # Mass is not m/z but close enough for MVP placeholder
            rt_sec=float(row.get("Retention time", 0.0)) * 60 if "Retention time" in df.columns else None,
            adduct=str(row.get("Charge", "")),
            polarity=None,
            metadata={}
        ))
    return features

def parse_diann(df: pd.DataFrame) -> List[Feature]:
    """
    Parses DIA-NN report.tsv format.
    """
    features = []
    for i, row in df.iterrows():
        try:
            intensity_val = float(row.get("Precursor.Quantity", 0.0))
        except (ValueError, TypeError):
            intensity_val = 0.0

        features.append(Feature(
            feature_id=str(row.get("Precursor.Id", f"DIA_{i}")),
            peptide_sequence=str(row.get("Stripped.Sequence", "")),
            intensity=intensity_val,
            mz=float(row.get("Precursor.Mz", 0.0)),
            rt_sec=float(row.get("RT", 0.0)) * 60,
            adduct=str(row.get("Precursor.Charge", "")),
            polarity=None,
            metadata={}
        ))
    return features

def parse_spectronaut(df: pd.DataFrame) -> List[Feature]:
    """
    Parses Spectronaut export format.
    """
    features = []
    for i, row in df.iterrows():
        try:
            intensity_val = float(row.get("PEP.Quantity", 0.0))
        except (ValueError, TypeError):
            intensity_val = 0.0

        features.append(Feature(
            feature_id=f"SPEC_{i}", # Spectronaut exports might vary, using index for now
            peptide_sequence=str(row.get("PEP.StrippedSequence", "")),
            intensity=intensity_val,
            mz=0.0,
            rt_sec=float(row.get("PEP.RT", 0.0)) * 60,
            adduct=None,
            polarity=None,
            metadata={}
        ))
    return features




====================
FILE: .\ingest_real_data.py
====================
import pandas as pd
import os
import db
import importers
from embeddings import peptide_to_vector, EMBEDDING_DIM

DATA_DIR = "data"
FILENAME = "Melanoma vs. MPNST.csv"
FILEPATH = os.path.join(DATA_DIR, FILENAME)
RUN_ID = "RUN_MELANOMA_VS_MPNST"

def ingest_real_data():
    print(f"--- Ingesting {FILENAME} ---")
    
    # 1. Read CSV
    try:
        df = pd.read_csv(FILEPATH)
        print(f"Loaded CSV with {len(df)} rows.")
    except Exception as e:
        print(f"Error reading CSV: {e}")
        return

    # 2. Parse Features
    # We force "tumor_csv" format as we know the source
    try:
        features = importers.parse_tumor_csv(df)
        print(f"Parsed {len(features)} features.")
    except Exception as e:
        print(f"Error parsing features: {e}")
        return

    # 3. Insert into DB
    con = db.get_db_connection(DATA_DIR)
    
    # Check if run exists, delete if so to refresh
    existing_run = db.get_run(con, RUN_ID)
    if existing_run:
        print(f"Run {RUN_ID} exists. Cleaning up old data...")
        con.execute("DELETE FROM features WHERE run_id=?", (RUN_ID,))
        con.execute("DELETE FROM embeddings WHERE run_id=?", (RUN_ID,))
        con.execute("DELETE FROM runs WHERE run_id=?", (RUN_ID,))
        con.commit()
        
    # Insert Run
    meta_dict = {"original_filename": FILENAME, "description": "Real data from Simplifi"}
    db.insert_run(con, RUN_ID, meta_dict)
    
    # Insert Features
    print("Inserting features into DB...")
    for feat in features:
        db.insert_feature(con, RUN_ID, feat)
    con.commit()
    
    # 4. Embed Peptides (for search/clustering)
    print("Generating embeddings...")
    count = 0
    for feat in features:
        vec = peptide_to_vector(feat.peptide_sequence)
        if vec is not None and vec.shape[0] == EMBEDDING_DIM:
            db.insert_embedding(con, RUN_ID, feat.feature_id, "unknown", "unknown", vec)
            count += 1
            
    con.commit()
    print(f"Embedded {count} peptides.")
    
    con.close()
    print(f"--- Ingestion Complete. Run ID: {RUN_ID} ---")

if __name__ == "__main__":
    ingest_real_data()


====================
FILE: .\list_models.py
====================
"""
List available Gemini models
"""
import os
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)

print("Available Gemini models:")
for m in genai.list_models():
    if 'generateContent' in m.supported_generation_methods:
        print(f"  - {m.name}")


====================
FILE: .\models.py
====================
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Any, Tuple

# -------------------- Data Models --------------------

class HealthResponse(BaseModel):
    ok: bool
    schema: str

class Spectrum(BaseModel):
    mz_array: List[float]
    intensity_array: List[float]

class Feature(BaseModel):
    # This model is now used for Peptides. `peptide_sequence` will hold the sequence.
    # The `alias` is used to map to the 'annotation_name' column in the DB for backward compatibility.
    model_config = ConfigDict(populate_by_name=True)

    feature_id: str
    mz: float
    rt_sec: Optional[float] = None
    intensity: float
    adduct: Optional[str] = None
    polarity: Optional[str] = None
    peptide_sequence: Optional[str] = Field(None, alias="annotation_name") # Maps to annotation_name in DB
    annotation_score: Optional[float] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)

class Run(BaseModel):
    run_id: str
    user_id: Optional[str] = None
    instrument: Optional[str] = None
    method: Optional[str] = None
    polarity: Optional[str] = None
    schema_version: str
    meta: Dict[str, Any] = {}
    features: Optional[List[Feature]] = None # Optional for when fetching run metadata without all features

class QueryPeptide(BaseModel):
    run_id: str
    feature_id: str
    peptide_sequence: Optional[str] = Field(None, alias="annotation_name")
    intensity: Optional[float] = None

class SimilarPeptide(BaseModel):
    run_id: str
    feature_id: str
    peptide_sequence: Optional[str] = Field(None, alias="annotation_name")
    similarity: float
    intensity: Optional[float] = None

class SimilarPeptidesResponse(BaseModel):
    query: QueryPeptide
    neighbors: List[SimilarPeptide]

====================
FILE: .\prepare_cachexia_dataset.py
====================


====================
FILE: .\prepare_ibd_dataset.py
====================
"""
A utility script to prepare a public metabolomics dataset (Human Cachexia) from
MetaboAnalyst for ingestion into the Metabo-MVP application.

This script will:
1. Define the source URL for the raw data.
2. Load the raw data, which is in a "wide" format (samples in columns).
3. Transform the data into a "long" feature list for a single sample.
4. Parse combined peak names (e.g., "mz_rt") into separate columns.
5. Save the cleaned data to a new CSV file, ready for our application.
"""

import pandas as pd
import urllib.request
import os

# --- Configuration ---

# Get the project's root directory (where this script is located)
APP_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(APP_DIR, "data")

# Ensure the data directory exists
os.makedirs(DATA_DIR, exist_ok=True)

# Source URL for the MetaboAnalyst Human Cachexia dataset (this can be unstable)
SOURCE_URL = "https://rest.xialab.ca/api/download/metaboanalyst/human_cachexia.csv"
LOCAL_RAW_PATH = os.path.join(DATA_DIR, "human_cachexia.csv")

# Path to save the final, cleaned CSV file
OUTPUT_PATH = os.path.join(DATA_DIR, "prepared_metaboanalyst_cachexia.csv")


def main():
    """Main function to run the data preparation pipeline."""
    print("Starting dataset preparation...")

    # --- Robust Data Loading ---
    # 1. Check if the raw data file already exists locally.
    if not os.path.exists(LOCAL_RAW_PATH):
        print(f"Raw data not found locally. Attempting to download from {SOURCE_URL}")
        try:
            # 2. If not, try to download it.
            urllib.request.urlretrieve(SOURCE_URL, LOCAL_RAW_PATH)
            print(f"âœ… Download successful. Saved to {LOCAL_RAW_PATH}")
        except Exception as e:
            # 3. If download fails, give the user clear instructions.
            print(f"\nâŒ ERROR: Could not download the data file: {e}")
            print("\n--- MANUAL ACTION REQUIRED ---")
            print(f"1. Open this URL in your browser: {SOURCE_URL}")
            print("2. Save the file as 'human_cachexia.csv'")
            print(f"3. Place the file inside this directory: {DATA_DIR}")
            print("4. Run this script again.")
            return # Stop execution

    # Load the raw data, treating the first column as the index (peak names)
    df = pd.read_csv(LOCAL_RAW_PATH)

    print(f"Raw data loaded. Shape: {df.shape}")

    # We will transform the data for the first sample (first row) into a "long" feature list.
    first_sample_row = df.iloc[0]
    sample_id = first_sample_row.iloc[0]
    print(f"Extracting feature list for the first sample: '{sample_id}'")

    # The first two columns are metadata ('Patient ID', 'Muscle loss'). Features start from the 3rd column.
    feature_data = first_sample_row.iloc[2:]

    # Create a new DataFrame from this series
    final_df = pd.DataFrame({
        'feature_id': feature_data.index,
        'intensity': feature_data.values
    })

    # This dataset does not contain m/z or rt, so we will create placeholder values.
    final_df['mz'] = final_df['feature_id'].apply(lambda x: 100 + (hash(x) % 90000) / 100.0)
    final_df['rt_sec'] = 0.0 # No retention time provided

    print(f"Saving cleaned data with {len(final_df)} rows to {OUTPUT_PATH}")
    final_df.to_csv(OUTPUT_PATH, index=False)

    print("âœ… Dataset preparation complete!")

if __name__ == "__main__":
    # Call the main function to execute the script's logic
    main()


====================
FILE: .\prepare_peptide_dataset.py
====================


====================
FILE: .\search.py
====================
import faiss
import numpy as np
import json
import os
import sqlite3
from typing import List, Tuple
from fastapi import HTTPException

import db
import embeddings
import models

# --- Configuration ---
FAISS_INDEX_FILENAME = "peptides.faiss"
FAISS_IDS_FILENAME = "peptides_ids.json"

def get_faiss_index_path(data_dir: str) -> str:
    return os.path.join(data_dir, FAISS_INDEX_FILENAME)

def get_faiss_ids_path(data_dir: str) -> str:
    return os.path.join(data_dir, FAISS_IDS_FILENAME)

def rebuild_faiss_index(con: sqlite3.Connection, data_dir: str):
    """
    Queries all embeddings from the DB, builds a FAISS index, and saves it.
    This is slow and should be run as a background task in a real app.
    """
    print("Rebuilding FAISS index...")
    faiss_index_path = get_faiss_index_path(data_dir)
    faiss_ids_path = get_faiss_ids_path(data_dir)

    rows = db.get_all_embeddings_data(con)

    if not rows:
        print("No embeddings found to build index.")
        # Ensure any old index files are removed if no embeddings exist
        if os.path.exists(faiss_index_path): os.remove(faiss_index_path)
        if os.path.exists(faiss_ids_path): os.remove(faiss_ids_path)
        return 0

    ids = [(row[0], row[1]) for row in rows] # (run_id, feature_id)
    vectors = np.array([json.loads(row[2]) for row in rows], dtype=np.float32)

    d = vectors.shape[1]  # vector dimension
    index = faiss.IndexFlatL2(d)  # Using L2 distance
    faiss.normalize_L2(vectors) # Normalize vectors to use L2 as cosine similarity
    index.add(vectors)

    faiss.write_index(index, faiss_index_path)
    with open(faiss_ids_path, "w") as f:
        json.dump(ids, f)
    print(f"FAISS index rebuilt with {index.ntotal} vectors.")
    return index.ntotal

def search_similar_peptides(con: sqlite3.Connection, data_dir: str, run_id: str, feature_id: str, k: int = 5) -> models.SimilarPeptidesResponse:
    """Finds peptides with similar biophysical properties using vector similarity."""
    faiss_index_path = get_faiss_index_path(data_dir)
    faiss_ids_path = get_faiss_ids_path(data_dir)

    if not os.path.exists(faiss_index_path) or not os.path.exists(faiss_ids_path):
        raise HTTPException(404, "FAISS index not found. Please upload data and ensure embeddings are generated.")

    index = faiss.read_index(faiss_index_path)
    with open(faiss_ids_path, "r") as f:
        ids_map = json.load(f)

    query_vector_list = db.get_embedding(con, run_id, feature_id)
    if not query_vector_list:
        raise HTTPException(404, f"Embedding for feature '{feature_id}' in run '{run_id}' not found (did you embed it?).")
    query_vector = np.array(query_vector_list, dtype=np.float32).reshape(1, -1)
    faiss.normalize_L2(query_vector)

    query_feat_props = db.get_feature_properties(con, run_id, feature_id)
    if not query_feat_props:
        raise HTTPException(404, f"Original feature '{feature_id}' in run '{run_id}' not found in DB.")

    distances, indices = index.search(query_vector, k)

    out = []
    for i, idx in enumerate(indices[0]):
        if idx == -1: continue
        neighbor_run_id, neighbor_feature_id = ids_map[idx]
        dist = distances[0][i]
        similarity = 1.0 - (dist**2) / 2.0 # Convert L2 distance back to cosine similarity

        feat_row = db.get_feature_properties(con, neighbor_run_id, neighbor_feature_id)
        out.append(models.SimilarPeptide(
            run_id=neighbor_run_id,
            feature_id=neighbor_feature_id,
            peptide_sequence=feat_row[0] if feat_row else None,
            similarity=float(similarity),
            intensity=feat_row[1] if feat_row else None,
        ))

    query_peptide = models.QueryPeptide(
        run_id=run_id,
        feature_id=feature_id,
        peptide_sequence=query_feat_props[0],
        intensity=query_feat_props[1]
    )

    return models.SimilarPeptidesResponse(query=query_peptide, neighbors=out)

====================
FILE: .\summarizer.py
====================
import os
from typing import Dict, Any, List, Optional

import google.generativeai as genai

import db
import models

# --- Gemini API configuration ---

# Prefer GEMINI_API_KEY but fall back to GOOGLE_API_KEY for compatibility.
_API_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")

if _API_KEY:
    genai.configure(api_key=_API_KEY)
else:
    # Keep the existing behavior of warning at import time.
    print("Warning: GEMINI_API_KEY/GOOGLE_API_KEY not found in environment variables!")


def _get_gemini_model() -> Optional[genai.GenerativeModel]:
    """
    Return a configured Gemini model instance, or None if no API key is set.

    This helper centralizes model configuration so all call sites behave
    consistently. It does not raise; higher-level functions decide what
    to do when the model is unavailable.
    """
    if not _API_KEY:
        return None
    # You can change the model name in one place if needed.
    return genai.GenerativeModel("gemini-2.5-flash")


def generate_summary(run_id: str, con=None) -> Dict[str, Any]:
    """
    Generate a natural-language summary for a given run.

    Behavior:
    - If no API key is configured, returns {"error": "...", "run_id": run_id}.
    - If there are no features for the run, returns an "error" dict.
    - Otherwise, delegates to either _generate_tumor_summary or
      _generate_peptide_summary depending on the presence of "stats" metadata.

    Parameters
    ----------
    run_id : str
        The identifier of the run to summarize.
    con : sqlite3.Connection or None
        Optional open DB connection. If None, a new connection is created
        using db.get_db_connection("data").

    Returns
    -------
    Dict[str, Any]
        A summary dictionary. On error, this includes an "error" key.
    """
    model = _get_gemini_model()
    if model is None:
        return {
            "error": "Gemini API key not configured. Please set GEMINI_API_KEY or GOOGLE_API_KEY in your .env file.",
            "run_id": run_id,
        }

    if con is None:
        con = db.get_db_connection("data")

    # Fetch basic stats / features for the run
    features = db.get_features_for_run(con, run_id)
    if not features:
        return {"error": "No features found for this run.", "run_id": run_id}

    # Check if this is a tumor run with stats in metadata
    is_tumor_run = bool(
        features
        and features[0].metadata
        and "stats" in features[0].metadata
    )

    if is_tumor_run:
        return _generate_tumor_summary(run_id, features, model)
    else:
        return _generate_peptide_summary(run_id, features, model)


def _generate_tumor_summary(
    run_id: str,
    features: List[models.Feature],
    model: genai.GenerativeModel,
) -> Dict[str, Any]:
    """
    Generate a tumor-style differential expression summary using Gemini.

    Returns the same dictionary structure as the previous implementation:
    {
        "run_id": str,
        "type": "tumor_comparison",
        "num_proteins": int,
        "num_significant": int,
        "top_up": [...],
        "top_down": [...],
        "summary_text": str,
    }
    """
    num_proteins = len(features)

    # Extract stats
    sig_proteins: List[models.Feature] = []
    up_regulated: List[Any] = []
    down_regulated: List[Any] = []

    for f in features:
        stats = f.metadata.get("stats", {}) if f.metadata else {}

        # Try to find q-value
        q_val = None
        for k, v in stats.items():
            if "q-value" in k.lower():
                try:
                    q_val = float(v)
                    break
                except (ValueError, TypeError):
                    continue

        if q_val is None:
            # Fallback: look for generic p-value (excluding Wilcoxon / t-test labels)
            for k, v in stats.items():
                if (
                    "p-value" in k.lower()
                    and "wilcoxon" not in k.lower()
                    and "t-test" not in k.lower()
                ):
                    try:
                        q_val = float(v)
                        break
                    except (ValueError, TypeError):
                        continue

        # Try to find fold change (non-log2)
        fc = None
        for k, v in stats.items():
            if "fold change" in k.lower() and "log2" not in k.lower():
                try:
                    fc = float(v)
                    break
                except (ValueError, TypeError):
                    continue

        if q_val is not None and q_val < 0.05:
            sig_proteins.append(f)

        if fc is not None:
            if fc > 0:
                up_regulated.append((f, fc))
            elif fc < 0:
                down_regulated.append((f, fc))

    # Sort up/down-regulated lists
    up_regulated.sort(key=lambda x: x[1], reverse=True)
    down_regulated.sort(key=lambda x: x[1])  # Most negative first

    top_up = up_regulated[:5]
    top_down = down_regulated[:5]

    up_list = "\n".join(
        f"- {f.peptide_sequence}: FC={fc:.2f} ({(f.metadata or {}).get('description', '')})"
        for f, fc in top_up
    )
    down_list = "\n".join(
        f"- {f.peptide_sequence}: FC={fc:.2f} ({(f.metadata or {}).get('description', '')})"
        for f, fc in top_down
    )

    prompt = f"""You are an expert proteomics data analyst. Analyze this differential expression dataset.

Comparison: {run_id} (Inferred from filename/ID)
Total Proteins: {num_proteins}
Significant Proteins (q<0.05): {len(sig_proteins)}

Top Upregulated Proteins:
{up_list}

Top Downregulated Proteins:
{down_list}

Provide a concise scientific summary of these findings. Mention the specific proteins and their potential biological relevance if known.
"""

    try:
        response = model.generate_content(prompt)
        summary_text = response.text

        return {
            "run_id": run_id,
            "type": "tumor_comparison",
            "num_proteins": num_proteins,
            "num_significant": len(sig_proteins),
            "top_up": [
                {
                    "accession": f.peptide_sequence,
                    "fc": fc,
                    "desc": (f.metadata or {}).get("description", ""),
                }
                for f, fc in top_up
            ],
            "top_down": [
                {
                    "accession": f.peptide_sequence,
                    "fc": fc,
                    "desc": (f.metadata or {}).get("description", ""),
                }
                for f, fc in top_down
            ],
            "summary_text": summary_text,
        }
    except Exception as e:
        # Preserve existing behavior: return an error dict, not raise.
        return {
            "error": f"Gemini API Error in tumor summary: {str(e)}",
            "run_id": run_id,
        }


def _generate_peptide_summary(
    run_id: str,
    features: List[models.Feature],
    model: genai.GenerativeModel,
) -> Dict[str, Any]:
    """
    Generate a peptide-focused run summary using Gemini.

    Returns the same dictionary structure as the previous implementation:
    {
        "run_id": ...,
        "num_peptides": ...,
        "avg_intensity": ...,
        "min_intensity": ...,
        "max_intensity": ...,
        "avg_sequence_length": ...,
        "physico_chem": {...},
        "top_peptides": [...],
        "summary_text": ...,
        "llm_model": "gemini-2.5-flash",
    }
    """
    num_peptides = len(features)
    avg_intensity = (
        sum(f.intensity for f in features) / num_peptides if num_peptides > 0 else 0
    )

    # Sort by intensity to find "top" peptides
    sorted_features = sorted(features, key=lambda x: x.intensity, reverse=True)
    top_10 = sorted_features[:10]
    top_sequences = [f.peptide_sequence for f in top_10]
    top_intensities = [f.intensity for f in top_10]

    # Additional statistics
    min_intensity = min(f.intensity for f in features)
    max_intensity = max(f.intensity for f in features)

    # Sequence length distribution
    seq_lengths = [
        len(f.peptide_sequence) if f.peptide_sequence else 0 for f in features
    ]
    avg_seq_length = sum(seq_lengths) / len(seq_lengths) if seq_lengths else 0.0

    # --- Enhanced Metrics ---

    # 1. Charge Distribution (Adducts)
    adduct_counts: Dict[str, int] = {}
    for f in features:
        a = getattr(f, "adduct", None) or "Unknown"
        adduct_counts[a] = adduct_counts.get(a, 0) + 1

    # 2. Hydrophobicity (GRAVY score approximation)
    hydropathy = {
        "I": 4.5,
        "V": 4.2,
        "L": 3.8,
        "F": 2.8,
        "C": 2.5,
        "M": 1.9,
        "A": 1.8,
        "G": -0.4,
        "T": -0.7,
        "S": -0.8,
        "W": -0.9,
        "Y": -1.3,
        "P": -1.6,
        "H": -3.2,
        "E": -3.5,
        "Q": -3.5,
        "D": -3.5,
        "N": -3.5,
        "K": -3.9,
        "R": -4.5,
    }

    def calculate_gravy(seq: str) -> float:
        if not seq:
            return 0.0
        score = sum(hydropathy.get(aa.upper(), 0.0) for aa in seq)
        return score / len(seq)

    gravy_scores = [calculate_gravy(f.peptide_sequence) for f in features]
    avg_gravy = sum(gravy_scores) / len(gravy_scores) if gravy_scores else 0.0

    hydrophobic_count = sum(1 for s in gravy_scores if s > 0)
    hydrophilic_count = sum(1 for s in gravy_scores if s <= 0)

    # Build a scientific prompt for Gemini
    peptide_list = "\n".join(
        f"{i+1}. {seq} (Intensity: {int_val:,.0f})"
        for i, (seq, int_val) in enumerate(
            zip(top_sequences[:5], top_intensities[:5])
        )
    )

    adduct_str = ", ".join(f"{k}: {v}" for k, v in adduct_counts.items())

    prompt = f"""You are an expert proteomics data analyst. Analyze this peptide dataset and provide a concise scientific summary.

Dataset: Run ID "{run_id}"

Key Statistics:
- Total Peptides: {num_peptides}
- Intensity: Avg {avg_intensity:,.0f} (Range: {min_intensity:,.0f} - {max_intensity:,.0f})
- Sequence Length: Avg {avg_seq_length:.1f} AA

Physicochemical Properties:
- Hydrophobicity (GRAVY): Avg {avg_gravy:.2f}
- Hydrophobic Peptides: {hydrophobic_count}
- Hydrophilic Peptides: {hydrophilic_count}
- Charge States (Adducts): {adduct_str}

Top 5 Peptides by Abundance:
{peptide_list}

Please provide a 2-3 paragraph summary covering:
1. Overall dataset characteristics and quality.
2. Physicochemical profile (hydrophobicity, charge). What does this suggest about the sample preparation or column type?
3. Biological significance of the top peptides.
4. Recommendations for downstream analysis.

Keep the summary scientific but accessible.
"""

    try:
        response = model.generate_content(prompt)
        summary_text = response.text

        return {
            "run_id": run_id,
            "num_peptides": num_peptides,
            "avg_intensity": avg_intensity,
            "min_intensity": min_intensity,
            "max_intensity": max_intensity,
            "avg_sequence_length": avg_seq_length,
            "physico_chem": {
                "avg_gravy": avg_gravy,
                "hydrophobic_count": hydrophobic_count,
                "hydrophilic_count": hydrophilic_count,
                "adduct_counts": adduct_counts,
            },
            "top_peptides": [
                {
                    "sequence": seq,
                    "intensity": int_val,
                    "feature_id": top_10[i].feature_id,
                }
                for i, (seq, int_val) in enumerate(
                    zip(top_sequences[:10], top_intensities[:10])
                )
            ],
            "summary_text": summary_text,
            "llm_model": "gemini-2.5-flash",
        }
    except Exception as e:
        # Preserve existing behavior: return an error dict, not raise.
        return {
            "error": f"Failed to generate summary: {str(e)}",
            "run_id": run_id,
            "num_peptides": num_peptides,
            "avg_intensity": avg_intensity,
            "top_peptides": top_sequences[:5],
        }


====================
FILE: .\test_api_key.py
====================
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
print(f"API Key loaded: {api_key}")
print(f"Key length: {len(api_key) if api_key else 0}")


====================
FILE: .\test_embedding_export.py
====================
"""
Test script to verify peptide embeddings export functionality.
This script:
1. Authenticates as a user
2. Uploads a small test file
3. Waits for embedding to complete
4. Calls the export endpoint
5. Verifies the response structure
"""

import requests
import time
import json

BASE_URL = "http://127.0.0.1:8080"

def test_embedding_export():
    print("=" * 60)
    print("Testing Peptide Embeddings Export")
    print("=" * 60)
    
    # Step 1: Login (using existing test user)
    print("\n[1] Logging in...")
    login_data = {
        "username": "user_a@example.com",
        "password": "password123"
    }
    
    res = requests.post(f"{BASE_URL}/auth/jwt/login", data=login_data)
    if res.status_code != 200:
        print(f"   âŒ Login failed: {res.status_code}")
        print(f"   Response: {res.text}")
        print(f"   Note: Make sure to run verify_auth_flow.py first to create test users")
        return False
    
    token = res.json()["access_token"]
    headers = {"Authorization": f"Bearer {token}"}
    print(f"   âœ… Login successful")
    
    # Step 2: Upload a test file
    print("\n[2] Uploading test file...")
    
    # Create a minimal test CSV with correct column names for generic format
    test_csv = """feature_id,sequence,intensity
FEAT_001,PEPTIDE,1000.0
FEAT_002,TESTSEQ,2000.0
FEAT_003,SAMPLE,1500.0
"""
    
    files = {"file": ("test_peptides.csv", test_csv, "text/csv")}
    data = {
        "format": "generic",
        "run_id": "TEST_EXPORT_RUN",
        "instrument": "Test Instrument",
        "method": "Test Method"
    }
    
    res = requests.post(f"{BASE_URL}/upload", headers=headers, files=files, data=data)
    if res.status_code != 200:
        print(f"   âŒ Upload failed: {res.status_code}")
        print(f"   Response: {res.text}")
        return False
    
    upload_result = res.json()
    run_id = upload_result["run_id"]
    print(f"   âœ… Upload successful: {run_id}")
    print(f"   Rows ingested: {upload_result['rows_ingested']}")
    
    # Step 3: Wait for embedding to complete
    print("\n[3] Waiting for background embedding to complete...")
    max_wait = 30  # seconds
    wait_interval = 2
    elapsed = 0
    
    while elapsed < max_wait:
        time.sleep(wait_interval)
        elapsed += wait_interval
        
        # Check if embeddings are ready by calling the export endpoint
        res = requests.get(f"{BASE_URL}/export/embeddings/{run_id}", headers=headers)
        if res.status_code == 200:
            embeddings = res.json()
            if len(embeddings) > 0:
                print(f"   âœ… Embeddings ready after {elapsed}s")
                break
        
        print(f"   â³ Waiting... ({elapsed}s)")
    else:
        print(f"   âš ï¸  Timeout after {max_wait}s - embeddings may not be ready")
    
    # Step 4: Call export endpoint
    print("\n[4] Calling export endpoint...")
    res = requests.get(f"{BASE_URL}/export/embeddings/{run_id}", headers=headers)
    
    if res.status_code != 200:
        print(f"   âŒ Export failed: {res.status_code}")
        print(f"   Response: {res.text}")
        return False
    
    embeddings = res.json()
    print(f"   âœ… Export successful")
    print(f"   Number of embeddings: {len(embeddings)}")
    
    # Step 5: Verify response structure
    print("\n[5] Verifying response structure...")
    
    if not isinstance(embeddings, list):
        print(f"   âŒ Response is not a list")
        return False
    
    if len(embeddings) == 0:
        print(f"   âš ï¸  No embeddings returned (background task may still be running)")
        return True  # Not a failure, just not ready yet
    
    # Check first embedding structure
    first_emb = embeddings[0]
    required_fields = ["sequence", "intensity", "length", "charge", "hydrophobicity", "embedding"]
    
    for field in required_fields:
        if field not in first_emb:
            print(f"   âŒ Missing field: {field}")
            return False
    
    print(f"   âœ… All required fields present")
    
    # Display sample embedding
    print("\n[6] Sample embedding:")
    print(f"   Sequence: {first_emb['sequence']}")
    print(f"   Intensity: {first_emb['intensity']}")
    print(f"   Length: {first_emb['length']}")
    print(f"   Charge: {first_emb['charge']}")
    print(f"   Hydrophobicity: {first_emb['hydrophobicity']}")
    print(f"   Embedding vector length: {len(first_emb['embedding'])}")
    print(f"   First 5 values: {first_emb['embedding'][:5]}")
    
    print("\n" + "=" * 60)
    print("âœ… All tests passed!")
    print("=" * 60)
    return True

if __name__ == "__main__":
    success = test_embedding_export()
    exit(0 if success else 1)


====================
FILE: .\test_fingerprint.py
====================
import httpx
import os
import getpass

# --- Configuration ---
BASE_URL = "http://127.0.0.1:8080"
# ---

def login(client, email, password):
    """Logs in to the application and returns the auth token."""
    print("Attempting to log in...")
    login_data = {
        "username": email,
        "password": password,
    }
    try:
        r = client.post(f"{BASE_URL}/auth/jwt/login", data=login_data)
        r.raise_for_status()
        token = r.json()["access_token"]
        print("Login successful.")
        return token
    except httpx.HTTPStatusError as e:
        print(f"Login failed: {e.response.status_code} {e.response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred during login: {e}")
        return None

def get_first_run_id(client, token):
    """Fetches the list of runs and returns the ID of the first one."""
    print("Fetching user's runs...")
    headers = {"Authorization": f"Bearer {token}"}
    try:
        r = client.get(f"{BASE_URL}/runs", headers=headers)
        r.raise_for_status()
        runs = r.json()
        if not runs:
            print("No runs found for this user.")
            return None
        first_run_id = runs[0]["run_id"]
        print(f"Found run_id: {first_run_id}")
        return first_run_id
    except httpx.HTTPStatusError as e:
        print(f"Failed to get runs: {e.response.status_code} {e.response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred while fetching runs: {e}")
        return None

def get_fingerprint(client, token, run_id):
    """Fetches the semantic fingerprint for a given run_id."""
    print(f"\nFetching fingerprint for run_id: {run_id}...")
    headers = {"Authorization": f"Bearer {token}"}
    try:
        with client.stream("GET", f"{BASE_URL}/runs/{run_id}/fingerprint", headers=headers, timeout=30) as r:
            r.raise_for_status()
            print("--- Fingerprint Response ---")
            for chunk in r.iter_text():
                print(chunk, end="")
            print("\n----------------------------")
    except httpx.HTTPStatusError as e:
        print(f"Failed to get fingerprint: {e.response.status_code}")
        print("Response body:", e.response.text)
    except Exception as e:
        print(f"An unexpected error occurred: {e}")


def main():
    """Main function to run the test."""
    email = input("Enter your login email: ")
    password = getpass.getpass("Enter your password: ")
    
    with httpx.Client() as client:
        token = login(client, email, password)
        if not token:
            return

        run_id = get_first_run_id(client, token)
        if not run_id:
            return
            
        get_fingerprint(client, token, run_id)

if __name__ == "__main__":
    main()


====================
FILE: .\test_gemini.py
====================
"""
Quick test to verify Gemini API integration works correctly.
"""
import os
from dotenv import load_dotenv
import google.generativeai as genai

# Load environment variables
load_dotenv()

# Check if key exists
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("âŒ GOOGLE_API_KEY not found in environment!")
    exit(1)
else:
    print(f"âœ… API Key found: {api_key[:20]}...")

try:
    # Configure and test the API
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    
    # Simple test query
    print("\nðŸ§ª Testing Gemini API connection...")
    response = model.generate_content("Say 'Hello from Gemini!' in a scientific tone.")
    
    print(f"âœ… Gemini API works!")
    print(f"\nðŸ“ Response:\n{response.text}\n")
    
    print("ðŸŽ‰ All checks passed! Your Gemini integration is ready.")
    
except Exception as e:
    print(f"âŒ Error: {str(e)}")
    exit(1)


====================
FILE: .\test_gemini_api.py
====================
import google.generativeai as genai
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def test_api():
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEY not found in environment variables!")
        print("Please ensure your .env file contains: GOOGLE_API_KEY=your_key_here")
        return False
    
    print(f"âœ… API Key found (starts with: {api_key[:10]}...)")
    
    try:
        genai.configure(api_key=api_key)
        
        # Test with the updated model
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        response = model.generate_content("Say 'Hello, the API is working!' in one sentence.")
        
        print(f"âœ… Model: models/gemini-1.5-flash")
        print(f"âœ… Response: {response.text}")
        print("\nðŸŽ‰ Gemini API is configured correctly!")
        return True
        
    except Exception as e:
        print(f"âŒ API Error: {str(e)}")
        return False

if __name__ == "__main__":
    test_api()


====================
FILE: .\test_gemini_key.py
====================
from dotenv import load_dotenv
import os
import google.generativeai as genai

load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
print(f"Testing API Key: {api_key[:10]}...")

try:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    response = model.generate_content("Say hello")
    print(f"SUCCESS: API Key works! Response: {response.text[:50]}")
except Exception as e:
    print(f"FAILED: API Key error: {e}")


====================
FILE: .\test_login.py
====================
import requests

# Test login endpoint
url = "http://127.0.0.1:8080/auth/jwt/login"
data = {
    "username": "test@example.com",
    "password": "password123"
}

try:
    response = requests.post(url, data=data)
    print(f"Status Code: {response.status_code}")
    print(f"Response: {response.text}")
except Exception as e:
    print(f"Error: {e}")


====================
FILE: .\test_models.py
====================
import google.generativeai as genai

# Test the provided API key with different model names
api_key = "AIzaSyAJ6IpRR0eojz042OylU7mPSpy3SkHs7uI"

print("=" * 60)
print("ðŸ§ª Testing Different Model Names")
print("=" * 60)

genai.configure(api_key=api_key)

# Try different model name formats
model_names = [
    'gemini-1.5-flash',
    'gemini-1.5-pro',
    'gemini-pro',
    'gemini-2.0-flash-exp',
    'gemini-flash-latest',
]

for model_name in model_names:
    try:
        print(f"\nðŸ” Trying: {model_name}")
        model = genai.GenerativeModel(model_name)
        response = model.generate_content("Say 'Hello!' in one word.")
        
        print(f"   âœ… SUCCESS with {model_name}")
        print(f"   Response: {response.text}")
        print()
        print("=" * 60)
        print(f"ðŸŽ‰ WORKING MODEL FOUND: {model_name}")
        print("=" * 60)
        print(f"\nAdd to your .env file:")
        print(f"GOOGLE_API_KEY={api_key}")
        print()
        print(f"Working model: {model_name}")
        print("=" * 60)
        break
        
    except Exception as e:
        print(f"   âŒ Failed: {str(e)[:80]}...")
        continue
else:
    print("\nâŒ None of the models worked. Listing available models...")
    try:
        print("\nAvailable models:")
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"  - {m.name}")
    except Exception as e:
        print(f"Error listing models: {e}")


====================
FILE: .\test_provided_key.py
====================
import google.generativeai as genai

# Test the provided API key
api_key = "AIzaSyAJ6IpRR0eojz042OylU7mPSpy3SkHs7uI"

print("=" * 60)
print("ðŸ§ª Testing Provided API Key")
print("=" * 60)
print(f"API Key: {api_key[:20]}...")
print()

try:
    # Configure the API
    genai.configure(api_key=api_key)
    
    # Test with the correct model
    print("ðŸ“¡ Connecting to Gemini API...")
    model = genai.GenerativeModel('models/gemini-1.5-flash')
    
    # Simple test query
    print("ðŸ’¬ Sending test query...")
    response = model.generate_content("Say 'Hello! The API key is working perfectly!' in one sentence.")
    
    print()
    print("=" * 60)
    print("âœ… SUCCESS!")
    print("=" * 60)
    print(f"Response: {response.text}")
    print()
    print("ðŸŽ‰ The API key is valid and working!")
    print()
    print("ðŸ“ Next steps:")
    print("   1. Add this to your .env file:")
    print(f"      GOOGLE_API_KEY={api_key}")
    print("   2. Restart the server: uvicorn app:app --reload")
    print("   3. Test summarization in the app")
    print("=" * 60)
    
except Exception as e:
    print()
    print("=" * 60)
    print("âŒ ERROR")
    print("=" * 60)
    print(f"Error: {str(e)}")
    print()
    print("This could mean:")
    print("  - The API key is invalid or expired")
    print("  - The API key doesn't have access to Gemini models")
    print("  - Network connectivity issues")
    print("=" * 60)


====================
FILE: .\update_env.py
====================
"""
This script will help you update your .env file with the correct API key.
"""
import os

api_key = "AIzaSyAJ6IpRR0eojz042OylU7mPSpy3SkHs7uI"
env_file_path = ".env"

print("=" * 60)
print("ðŸ”§ .env File Update Helper")
print("=" * 60)
print()

# Read existing .env file if it exists
existing_content = []
if os.path.exists(env_file_path):
    print(f"âœ… Found existing .env file")
    with open(env_file_path, 'r') as f:
        existing_content = f.readlines()
else:
    print(f"ðŸ“ Creating new .env file")

# Remove old GEMINI_API_KEY and GOOGLE_API_KEY lines
new_content = []
removed_old = False
for line in existing_content:
    if line.strip().startswith('GEMINI_API_KEY=') or line.strip().startswith('GOOGLE_API_KEY='):
        removed_old = True
        continue
    new_content.append(line)

# Add the new GOOGLE_API_KEY
new_content.append(f'GOOGLE_API_KEY={api_key}\n')

# Write back to file
with open(env_file_path, 'w') as f:
    f.writelines(new_content)

print()
if removed_old:
    print("âœ… Removed old API key configuration")
print(f"âœ… Added: GOOGLE_API_KEY={api_key[:20]}...")
print()
print("=" * 60)
print("ðŸ“‹ Your .env file now contains:")
print("=" * 60)
with open(env_file_path, 'r') as f:
    print(f.read())
print("=" * 60)
print()
print("ðŸŽ‰ Configuration complete!")
print()
print("ðŸ“ Next steps:")
print("   1. Test the API: python test_gemini_api.py")
print("   2. Start server: uvicorn app:app --reload")
print("   3. Try summarization in the app!")
print()
print("=" * 60)


====================
FILE: .\upload_error.html
====================
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Immuno-Engine - Upload Error</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 2rem; }
  </style>
</head>
<body>
  <h3>Upload failed</h3>
  <p>An error occurred during the upload or processing:</p>
  <pre>{{ error_message }}</pre>
  <p><a href='/upload'>Back to Upload</a></p>
  <p>Or use the API docs: <a href="/docs">/docs</a></p>
</body>
</html>

====================
FILE: .\upload_form.html
====================
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Immuno-Engine - Upload Peptide Data</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 2rem; }
    form { display: block; max-width: 560px; padding: 1rem; border: 1px solid #ddd; border-radius: 8px; }
    label { display:block; margin-top: 1rem; font-weight: 600; }
    input, select, textarea { width: 100%; padding: .6rem; margin-top: .4rem; }
    button { margin-top: 1rem; padding: .6rem 1rem; cursor: pointer; }
    .tip { color:#555; font-size:.9rem; margin-bottom: 1rem; }
    .row { display: grid; grid-template-columns: 1fr 1fr; gap: 12px; }
  </style>
</head>
<body>
  <h1>Upload Peptide Table</h1>
  <p class="tip">Accepted files: CSV with columns: <code>feature_id, peptide_sequence, intensity</code>.<br/><code>peptide_sequence</code> should contain the amino acid sequence.</p>

  <form action="/upload" method="post" enctype="multipart/form-data">
    <label>Peptide table file (CSV)
      <input type="file" name="file" required />
    </label>

    <div class="row">
      <div>
        <label>Run ID (optional)
          <input type="text" name="run_id" placeholder="e.g., RUN_2025_11_03_A" />
        </label>
      </div>
      <div>
        <label>Instrument (optional)
          <input type="text" name="instrument" placeholder="e.g., Q Exactive" />
        </label>
      </div>
    </div>

    <div class="row">
      <div>
        <label>Method (optional)
          <input type="text" name="method" placeholder="e.g., HILIC or RP" />
        </label>
      </div>
      <div>
        <label>Polarity (optional)
          <select name="polarity">
            <option value="">(none)</option>
            <option value="POS">POS</option>
            <option value="NEG">NEG</option>
          </select>
        </label>
      </div>
    </div>

    <p class="tip">Tip: If youâ€™re unsure, leave fields blankâ€”defaults are okay.</p>
    <button type="submit">Upload & Ingest</button>
  </form>

  <p style="margin-top:2rem;">Or use the API docs: <a href="/docs">/docs</a></p>
</body>
</html>

====================
FILE: .\upload_success.html
====================
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Immuno-Engine - Upload Success</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 2rem; }
  </style>
</head>
<body>
  <h2>Upload complete</h2>
  <p>Run ID: <b>{{ run_id }}</b></p>
  <p>âœ… Rows ingested: <b>{{ rows_ingested }}</b></p>
  <p>
    The embedding and indexing process has been started in the background.
    It may take a moment for the index to be fully rebuilt, especially for large files.
  </p>
  <p>
    Next steps:
    <ul>
      {{ search_link_html | safe }}
      <li><a href="/docs#/default/similar_peptide_search__run_id___feature_id__get" target="_blank">Go to API docs for custom search</a></li>
    </ul>
  </p>
  <p><a href="/upload">Upload another file</a></p>
</body>
</html>

====================
FILE: .\verify_access_control.py
====================
import requests
import sys

BASE_URL = "http://127.0.0.1:8000"

def test_access_control():
    print("ðŸ”’ Starting Access Control Verification...")

    # --- Setup Users ---
    def get_token(email, password):
        # Register
        requests.post(f"{BASE_URL}/auth/register", json={"email": email, "password": password})
        # Login
        res = requests.post(f"{BASE_URL}/auth/jwt/login", data={"username": email, "password": password})
        if res.status_code != 200:
            print(f"âŒ Login failed for {email}")
            sys.exit(1)
        return res.json()["access_token"]

    print("\n1. Setting up users...")
    token_a = get_token("user_secure_a@example.com", "password123")
    token_b = get_token("user_secure_b@example.com", "password123")
    print("   âœ… Users A and B logged in")

    # --- User A Uploads Data ---
    print("\n2. User A uploading data...")
    headers_a = {"Authorization": f"Bearer {token_a}"}
    files = {"file": ("test_sec.csv", "feature_id,peptide_sequence,intensity\nPEP_SEC_1,PEPTIDE,1000", "text/csv")}
    run_id = "RUN_SECURE_A"
    res = requests.post(f"{BASE_URL}/upload", headers=headers_a, files=files, data={"run_id": run_id})
    if res.status_code != 200:
        print(f"âŒ Upload failed: {res.text}")
        sys.exit(1)
    print(f"   âœ… Uploaded {run_id}")

    # --- User B Attacks ---
    headers_b = {"Authorization": f"Bearer {token_b}"}
    
    print("\n3. User B attempting to access User A's run details...")
    res = requests.get(f"{BASE_URL}/runs/{run_id}", headers=headers_b)
    if res.status_code in [403, 404]:
        print(f"   âœ… Blocked: {res.status_code} (Expected)")
    else:
        print(f"   âŒ FAIL: User B accessed run details! Status: {res.status_code}")

    print("\n4. User B attempting to generate summary for User A's run...")
    res = requests.post(f"{BASE_URL}/summary/run/{run_id}", headers=headers_b)
    if res.status_code in [403, 404]:
        print(f"   âœ… Blocked: {res.status_code} (Expected)")
    else:
        print(f"   âŒ FAIL: User B triggered summary! Status: {res.status_code}")

    print("\n5. User B attempting to compare User A's run...")
    # User B compares A's run with A's run (or any run)
    res = requests.get(f"{BASE_URL}/compare/{run_id}/{run_id}", headers=headers_b)
    if res.status_code in [403, 404]:
        print(f"   âœ… Blocked: {res.status_code} (Expected)")
    else:
        print(f"   âŒ FAIL: User B accessed comparison! Status: {res.status_code}")

    # --- User A Access (Should work) ---
    print("\n6. User A accessing their own run...")
    res = requests.get(f"{BASE_URL}/runs/{run_id}", headers=headers_a)
    if res.status_code == 200:
        print("   âœ… User A accessed run details")
    else:
        print(f"   âŒ FAIL: User A blocked from own run! Status: {res.status_code}")

if __name__ == "__main__":
    test_access_control()


====================
FILE: .\verify_auth_flow.py
====================
import requests
import json
import os

BASE_URL = "http://127.0.0.1:8080"

def test_auth_flow():
    print("ðŸš€ Starting Auth Flow Verification...")

    # 1. Register User A
    print("\n1. Registering User A (user_a@example.com)...")
    user_a = {"email": "user_a@example.com", "password": "password123", "is_active": True, "is_superuser": False, "is_verified": False}
    res = requests.post(f"{BASE_URL}/auth/register", json=user_a)
    if res.status_code == 400 and "REGISTER_USER_ALREADY_EXISTS" in res.text:
        print("   User A already exists (skipping registration)")
    elif res.status_code != 201:
        print(f"   âŒ Registration failed: {res.text}")
        return
    else:
        print("   âœ… User A registered")

    # 2. Login User A
    print("\n2. Logging in User A...")
    res = requests.post(f"{BASE_URL}/auth/jwt/login", data={"username": user_a["email"], "password": user_a["password"]})
    if res.status_code != 200:
        print(f"   âŒ Login failed: {res.text}")
        return
    token_a = res.json()["access_token"]
    print(f"   âœ… Login successful. Token: {token_a[:10]}...")

    # 3. Upload File as User A
    print("\n3. Uploading file as User A...")
    headers_a = {"Authorization": f"Bearer {token_a}"}
    files = {"file": ("test_a.csv", "feature_id,peptide_sequence,intensity\nPEPTIDE_A,PEPTIDE,1000", "text/csv")}
    res = requests.post(f"{BASE_URL}/upload", headers=headers_a, files=files, data={"run_id": "RUN_USER_A"})
    if res.status_code != 200:
        print(f"   âŒ Upload failed: {res.text}")
        return
    print("   âœ… Upload successful")

    # 4. List Runs for User A
    print("\n4. Listing runs for User A...")
    res = requests.get(f"{BASE_URL}/runs", headers=headers_a)
    runs = res.json()
    run_ids = [r["run_id"] for r in runs]
    print(f"   Runs found: {run_ids}")
    if "RUN_USER_A" in run_ids:
        print("   âœ… User A sees their run")
    else:
        print("   âŒ User A DOES NOT see their run")

    # 5. Register User B
    print("\n5. Registering User B (user_b@example.com)...")
    user_b = {"email": "user_b@example.com", "password": "password123", "is_active": True, "is_superuser": False, "is_verified": False}
    res = requests.post(f"{BASE_URL}/auth/register", json=user_b)
    if res.status_code == 400 and "REGISTER_USER_ALREADY_EXISTS" in res.text:
        print("   User B already exists")
    elif res.status_code != 201:
        print(f"   âŒ Registration failed: {res.text}")
        return
    else:
        print("   âœ… User B registered")

    # 6. Login User B
    print("\n6. Logging in User B...")
    res = requests.post(f"{BASE_URL}/auth/jwt/login", data={"username": user_b["email"], "password": user_b["password"]})
    token_b = res.json()["access_token"]
    print(f"   âœ… Login successful")

    # 7. List Runs for User B (Should NOT see User A's run)
    print("\n7. Listing runs for User B...")
    headers_b = {"Authorization": f"Bearer {token_b}"}
    res = requests.get(f"{BASE_URL}/runs", headers=headers_b)
    runs_b = res.json()
    run_ids_b = [r["run_id"] for r in runs_b]
    print(f"   Runs found: {run_ids_b}")
    if "RUN_USER_A" in run_ids_b:
        print("   âŒ SECURITY FAIL: User B can see User A's run!")
    else:
        print("   âœ… SECURITY PASS: User B cannot see User A's run")

if __name__ == "__main__":
    test_auth_flow()


====================
FILE: .\verify_dashboard.py
====================
import sys
from fastapi.testclient import TestClient
from app import app

client = TestClient(app)

def test_dashboard_endpoint():
    print("Testing dashboard endpoint...")
    
    # 1. List runs to get a valid run_id
    response = client.get("/runs")
    if response.status_code != 200:
        print(f"Failed to list runs: {response.status_code}")
        return
        
    runs = response.json()
    if not runs:
        print("No runs found. Please upload data first (or run verify_tumor_flow.py to seed data).")
        return
        
    run_id = runs[0]['run_id']
    print(f"Using Run ID: {run_id}")
    
    # 2. Fetch dashboard data
    response = client.get(f"/dashboard-data/{run_id}")
    if response.status_code == 200:
        data = response.json()
        print(f"Success! Retrieved {len(data['data'])} data points.")
        if data['data']:
            print("Sample data point:")
            print(data['data'][0])
            
            # Verify properties exist
            props = data['data'][0]['properties']
            if 'hydrophobicity' in props and 'molecular_weight' in props:
                print("[PASS] Biophysical properties present.")
            else:
                print("[FAIL] Biophysical properties missing.")
    else:
        print(f"Failed to get dashboard data: {response.status_code}")
        print(response.text)

if __name__ == "__main__":
    test_dashboard_endpoint()


====================
FILE: .\verify_summary.py
====================
import os
import sys
import json
from unittest.mock import MagicMock, patch
from fastapi.testclient import TestClient

# Mock google.generativeai before importing app
# This allows us to test the integration without a real API key or network call
mock_genai = MagicMock()
sys.modules["google.generativeai"] = mock_genai

# Now import app
from app import app

client = TestClient(app)

def test_summarization_flow():
    print("1. Uploading test data...")
    # Create a dummy CSV content
    csv_content = "Sequence,Intensity,Modified sequence\nPEPTIDE,100000,PEPTIDE\nANOTHER,50000,ANOTHER"
    files = {"file": ("test.csv", csv_content, "text/csv")}
    
    response = client.post("/upload", files=files, data={"format": "maxquant", "run_id": "TEST_RUN_001"})
    
    if response.status_code != 200:
        print(f"âŒ Upload failed: {response.status_code}")
        print(response.text)
        return
    
    print("âœ… Upload successful.")
    
    print("2. Testing Summarization Endpoint...")
    
    # Mock the generate_content response
    mock_model = MagicMock()
    mock_response = MagicMock()
    mock_response.text = "This is a mock scientific summary of the peptide data."
    mock_model.generate_content.return_value = mock_response
    
    # Patch the GenerativeModel constructor
    with patch("google.generativeai.GenerativeModel", return_value=mock_model):
        # We need to set a dummy API key in env if not present, 
        # because summarizer.py checks for it.
        if "GOOGLE_API_KEY" not in os.environ:
            os.environ["GOOGLE_API_KEY"] = "dummy_key"
            
        # Force reload of summarizer module to pick up the env var if needed? 
        # Actually, summarizer.py reads env at module level. 
        # If it was already imported by app, it might have seen None.
        # Let's patch the module-level variable if needed, but patching os.environ before import is best.
        # Since app is already imported, let's check summarizer.GOOGLE_API_KEY
        import summarizer
        summarizer.GOOGLE_API_KEY = "dummy_key" # Force it for the test
        
        response = client.post("/summary/run/TEST_RUN_001")
        
        if response.status_code == 200:
            data = response.json()
            print("âœ… Summarization request successful.")
            print(f"   Summary: {data.get('summary_text')}")
            
            if data.get("summary_text") == "This is a mock scientific summary of the peptide data.":
                print("âœ… Mock response verified.")
            else:
                print("âš ï¸ Unexpected response content.")
                
            if data.get("num_peptides") == 2:
                print("âœ… Correct number of peptides analyzed.")
            else:
                print(f"âš ï¸ Expected 2 peptides, got {data.get('num_peptides')}")
                
        else:
            print(f"âŒ Summarization failed: {response.status_code}")
            print(response.text)

if __name__ == "__main__":
    test_summarization_flow()


====================
FILE: .\verify_tumor_flow.py
====================
import os
import sys
from unittest.mock import MagicMock, patch
from fastapi.testclient import TestClient

# Mock google.generativeai
mock_genai = MagicMock()
sys.modules["google.generativeai"] = mock_genai

from app import app

client = TestClient(app)

def test_tumor_workflow():
    print("1. Uploading Tumor CSV...")
    # Create dummy tumor CSV
    csv_content = """Accession,Description,Melanoma-1,Melanoma-2,Fold Change,q-value
P12345,Protein A,100,110,2.5,0.01
P67890,Protein B,50,60,-1.5,0.04
P54321,Protein C,200,210,0.1,0.5
"""
    files = {"file": ("tumor_test.csv", csv_content, "text/csv")}
    response = client.post("/upload", files=files, data={"format": "auto", "run_id": "TUMOR_RUN_001"})
    
    if response.status_code != 200:
        print(f"[FAIL] Upload failed: {response.status_code}")
        print(response.text)
        return
    print("[PASS] Upload successful.")
    
    print("2. Checking /runs endpoint...")
    response = client.get("/runs")
    if response.status_code == 200:
        runs = response.json()
        found = False
        for r in runs:
            if r["run_id"] == "TUMOR_RUN_001":
                found = True
                print(f"[PASS] Found run in list. Features: {r['n_features']}")
                if r['n_features'] == 3:
                    print("[PASS] Feature count correct.")
                else:
                    print(f"[WARN] Expected 3 features, got {r['n_features']}")
                break
        if not found:
            print("[FAIL] Run not found in /runs list.")
    else:
        print(f"[FAIL] /runs failed: {response.status_code}")

    print("3. Checking Run Details...")
    response = client.get("/runs/TUMOR_RUN_001")
    if response.status_code == 200:
        details = response.json()
        print("[PASS] Run details fetched.")
        if details["stats"]["n_features"] == 3:
            print("[PASS] Stats correct.")
    else:
        print(f"[FAIL] /runs/ID failed: {response.status_code}")

    print("4. Testing Tumor Summary...")
    # Mock Gemini response
    mock_model = MagicMock()
    mock_response = MagicMock()
    mock_response.text = "Tumor summary generated."
    mock_model.generate_content.return_value = mock_response
    
    with patch("google.generativeai.GenerativeModel", return_value=mock_model):
        # Patch API key check
        import summarizer
        summarizer.GOOGLE_API_KEY = "dummy"
        
        response = client.post("/summary/run/TUMOR_RUN_001")
        if response.status_code == 200:
            data = response.json()
            print("[PASS] Summary generated.")
            if data.get("type") == "tumor_comparison":
                print("[PASS] Correctly identified as tumor comparison.")
            else:
                print(f"[WARN] Expected type 'tumor_comparison', got {data.get('type')}")
                
            if data.get("num_significant") == 2:
                print("[PASS] Correct significant count (2).")
            else:
                print(f"[WARN] Expected 2 significant, got {data.get('num_significant')}")
        else:
            print(f"[FAIL] Summary failed: {response.status_code}")
            print(response.text)

if __name__ == "__main__":
    test_tumor_workflow()


====================
FILE: .\modules\embedder.py
====================


====================
FILE: .\modules\tokenizer.py
====================


====================
FILE: .\omicstoken_repo\app.py
====================
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi import Request
from pydantic import BaseModel, Field
import uvicorn
import os
import shutil
import pandas as pd
from typing import List, Optional
import logging

import embeddings
from embeddings import peptide_to_vector, EMBEDDING_DIM
import db
import search
import models
import importers
import summarizer

# --- Configuration ---
DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

app = FastAPI(title="Immuno-Peptidomics MVP")

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# CORS (Optional, good for dev)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/", include_in_schema=False)
async def root():
    return RedirectResponse(url="/docs", status_code=307)

@app.post("/peptide/embed/{run_id}")
def embed(run_id: str):
    """Vectorize each peptide in a run and persist the vectors."""
    con = db.get_db_connection(DATA_DIR)
    
    # Verify run exists
    run = db.get_run(con, run_id)
    if not run:
        con.close()
        raise HTTPException(404, "run_id not found")

    features = db.get_features_for_run(con, run_id)
    
    count = 0
    for feat in features:
        # The core of our new engine: converting sequence to vector
        vec = peptide_to_vector(feat.peptide_sequence)

        # Skip if vectorization failed
        if vec is None or vec.shape[0] != EMBEDDING_DIM:
            print(f"Skipping embedding for feature {feat.feature_id} due to invalid sequence or vector.")
            continue

        db.insert_embedding(con, run_id, feat.feature_id, run.method or "", run.polarity or "", vec)
        count += 1

    con.commit()
    # After committing, rebuild the global search index
    search.rebuild_faiss_index(con, DATA_DIR)

    con.close()
    return {"run_id": run_id, "peptides_embedded": count}

@app.get("/upload", response_class=HTMLResponse, include_in_schema=False)
def upload_page():
    return """
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Immuno-Engine - Upload</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 2rem; }
    form { display: block; max-width: 560px; padding: 1rem; border: 1px solid #ddd; border-radius: 8px; }
    label { display:block; margin-top: 1rem; font-weight: 600; }
    input, select, textarea { width: 100%; padding: .6rem; margin-top: .4rem; }
    button { margin-top: 1rem; padding: .6rem 1rem; cursor: pointer; }
    .tip { color:#555; font-size:.9rem; margin-bottom: 1rem; }
    .row { display: grid; grid-template-columns: 1fr 1fr; gap: 12px; }
  </style>
</head>
  <h1>Upload Peptide Table</h1>
  <p class="tip">Accepted files: CSV/TSV from MaxQuant, DIA-NN, Spectronaut, or Generic.</p>

  <form action="/upload" method="post" enctype="multipart/form-data">
    <label>Peptide table file
      <input type="file" name="file" required />
    </label>

    <div class="row">
      <div>
        <label>Format
          <select name="format">
            <option value="auto">Auto-detect</option>
            <option value="maxquant">MaxQuant (peptides.txt)</option>
            <option value="diann">DIA-NN (report.tsv)</option>
            <option value="spectronaut">Spectronaut</option>
            <option value="generic">Generic CSV</option>
          </select>
        </label>
      </div>
      <div>
        <label>Run ID (optional)
          <input type="text" name="run_id" placeholder="e.g., RUN_2025_11_03_A" />
        </label>
      </div>
    </div>

    <div class="row">
      <div>
        <label>Instrument (optional)
          <input type="text" name="instrument" placeholder="e.g., Q Exactive" />
        </label>
      </div>
      <div>
        <label>Method (optional)
          <input type="text" name="method" placeholder="e.g., HILIC or RP" />
        </label>
      </div>
    </div>

    <button type="submit">Upload & Ingest</button>
  </form>

  <p style="margin-top:2rem;">
    Or use the API docs: <a href="/docs">/docs</a>
  </p>
</body>
</html>
    """

@app.post("/upload", response_class=HTMLResponse, include_in_schema=False)
async def upload_handler(request: Request, background_tasks: BackgroundTasks,
                         file: UploadFile = File(...),
                         run_id: str = Form(""),
                         instrument: str = Form(""),
                         method: str = Form(""),
                         format: str = Form("auto")):
    """
    Handles file uploads, detects format, ingests data, and triggers embedding.
    """
    # --- Ingest Logic ---
    name = file.filename or "upload.csv"
    sep = "\t" if name.endswith(".tsv") or name.endswith(".txt") else ","
    await file.seek(0)
    
    try:
        df = pd.read_csv(file.file, sep=sep)
    except Exception as e:
        raise HTTPException(400, f"Failed to parse CSV: {e}")

    # Use the importers module to parse the dataframe
    try:
        features = importers.parse_upload(df, fmt=format)
    except Exception as e:
        raise HTTPException(400, f"Import failed: {e}")

    # Build meta dict
    meta_dict = {
        "run_id": run_id.strip() or None,
        "instrument": instrument.strip() or None,
        "method": method.strip() or None,
        "original_filename": name
    }
    run_id_final = meta_dict.get("run_id") or f"RUN_{pd.Timestamp.utcnow().strftime('%Y%m%d_%H%M%S')}"

    # Store in SQLite
    con = db.get_db_connection(DATA_DIR)
    db.insert_run(con, run_id_final, meta_dict)

    for feat in features:
        db.insert_feature(con, run_id_final, feat)
        
    con.commit()
    con.close()
    rows_ingested = len(features)

    # --- Background Tasks ---
    def _background_work(run_id_to_process: str):
        # 1. Embed
        embed_result = embed(run_id=run_id_to_process)
        print(f"Background: Embedded {embed_result['peptides_embedded']} peptides.")
        # 2. Summarize (Pre-compute? Or just let user request it later? For now, just print)
        print(f"Background: Ready for summarization.")

    background_tasks.add_task(_background_work, run_id_final)

    # --- Success Response ---
    first_feature_id = features[0].feature_id if features else None
    search_link_html = ""
    if first_feature_id:
        search_url = f"/peptide/search/{run_id_final}/{first_feature_id}"
        search_link_html = f'<li><a href="{search_url}" target="_blank">Test search for first peptide: "{first_feature_id}"</a></li>'

    return HTMLResponse(f"""
        <h2>Upload complete</h2>
        <p>Run ID: <b>{run_id_final}</b></p>
        <p>âœ… Ingested <b>{rows_ingested}</b> peptides using format <b>{format}</b>.</p>
        <p>Embedding running in background...</p>
        <p>
          Next steps:
          <ul>
            {search_link_html}
            <li>
                <form action="/summary/run/{run_id_final}" method="post" target="_blank" style="display:inline;">
                    <button type="submit" style="background:none; border:none; text-decoration:underline; color:blue; cursor:pointer; padding:0;">
                        Generate Summary for this Run
                    </button>
                </form>
            </li>
            <li><a href="/docs" target="_blank">API Docs</a></li>
          </ul>
        </p>
        <p><a href="/upload">Upload another file</a></p>
    """, status_code=200)

@app.get("/peptide/search/{run_id}/{feature_id}")
def similar(run_id: str, feature_id: str, k: int = 5):
    """Find peptides with similar biophysical properties."""
    con = db.get_db_connection(DATA_DIR)
    try:
        return search.search_similar_peptides(con, DATA_DIR, run_id, feature_id, k)
    except HTTPException as e:
        raise e
    finally:
        con.close()

@app.post("/summary/run/{run_id}")
def get_run_summary(run_id: str):
    """
    Generates a text summary of the run using the Summarization Engine.
    """
    con = db.get_db_connection(DATA_DIR)
    try:
        summary = summarizer.generate_summary(run_id, con)
        return summary
    finally:
        con.close()

@app.get("/runs")
def list_runs():
    """List all runs with summary statistics."""
    con = db.get_db_connection(DATA_DIR)
    try:
        return db.get_run_summaries(con)
    finally:
        con.close()

@app.get("/runs/{run_id}")
def get_run_details(run_id: str):
    """Get detailed information about a specific run."""
    con = db.get_db_connection(DATA_DIR)
    try:
        run = db.get_run(con, run_id)
        if not run:
            raise HTTPException(404, "Run not found")
            
        # Get counts
        cur = con.cursor()
        cur.execute("SELECT COUNT(*) FROM features WHERE run_id=?", (run_id,))
        n_features = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM embeddings WHERE run_id=?", (run_id,))
        n_embeddings = cur.fetchone()[0]
        
        # Check for first feature for search link
        cur.execute("SELECT feature_id FROM features WHERE run_id=? LIMIT 1", (run_id,))
        row = cur.fetchone()
        first_feature_id = row[0] if row else None
        
        return {
            "run": run,
            "stats": {
                "n_features": n_features,
                "n_embeddings": n_embeddings
            },
            "links": {
                "summary": f"/summary/run/{run_id}",
                "search_example": f"/peptide/search/{run_id}/{first_feature_id}" if first_feature_id else None
            }
        }
    finally:
        con.close()

@app.get("/compare/{run_id_1}/{run_id_2}")
def compare_runs(run_id_1: str, run_id_2: str):
    """
    Compares two runs to find shared and unique peptides.
    """
    con = db.get_db_connection(DATA_DIR)
    try:
        # Fetch features for both runs
        features_1 = db.get_features_for_run(con, run_id_1)
        features_2 = db.get_features_for_run(con, run_id_2)
        
        if not features_1:
            raise HTTPException(404, f"Run {run_id_1} not found or empty")
        if not features_2:
            raise HTTPException(404, f"Run {run_id_2} not found or empty")
            
        # Extract sequences
        seqs_1 = set(f.peptide_sequence for f in features_1)
        seqs_2 = set(f.peptide_sequence for f in features_2)
        
        # Calculate intersections and differences
        shared = seqs_1.intersection(seqs_2)
        unique_1 = seqs_1 - seqs_2
        unique_2 = seqs_2 - seqs_1
        
        return {
            "run_1": run_id_1,
            "run_2": run_id_2,
            "stats": {
                "total_run_1": len(seqs_1),
                "total_run_2": len(seqs_2),
                "shared_count": len(shared),
                "unique_run_1_count": len(unique_1),
                "unique_run_2_count": len(unique_2),
                "jaccard_index": len(shared) / len(seqs_1.union(seqs_2)) if seqs_1 or seqs_2 else 0
            },
            "shared_peptides": list(shared)[:100], # Limit for display
            "unique_run_1": list(unique_1)[:100],
            "unique_run_2": list(unique_2)[:100]
        }
    finally:
        con.close()


====================
FILE: .\omicstoken_repo\db.py
====================
import sqlite3
import os
import json
from typing import List, Dict, Any, Optional, Tuple

import models

# --- Configuration ---
SCHEMA_VERSION = "immuno-0.1.0"

def get_db_path(data_dir: str) -> str:
    return os.path.join(data_dir, "immuno.sqlite")

def get_db_connection(data_dir: str) -> sqlite3.Connection:
    """Establishes a connection to the SQLite database and ensures tables exist."""
    db_path = get_db_path(data_dir)
    con = sqlite3.connect(db_path)
    con.execute("PRAGMA foreign_keys = ON") # Enable foreign key constraints
    _create_tables(con)
    return con

def _create_tables(con: sqlite3.Connection):
    """Creates database tables if they do not already exist."""
    con.execute("""CREATE TABLE IF NOT EXISTS runs(
        run_id TEXT PRIMARY KEY,
        instrument TEXT,
        method TEXT,
        polarity TEXT,
        schema_version TEXT,
        meta_json TEXT
    )""")
    
    con.execute("""CREATE TABLE IF NOT EXISTS features(
        run_id TEXT,
        feature_id TEXT,
        mz REAL,
        rt_sec REAL,
        intensity REAL,
        adduct TEXT,
        polarity TEXT,
        annotation_name TEXT, -- Stores peptide sequence
        annotation_score REAL,
        meta_json TEXT,
        PRIMARY KEY(run_id, feature_id),
        FOREIGN KEY(run_id) REFERENCES runs(run_id) ON DELETE CASCADE
    )""")
    
    # Migration: Attempt to add meta_json column if it doesn't exist
    try:
        con.execute("ALTER TABLE features ADD COLUMN meta_json TEXT")
    except sqlite3.OperationalError:
        pass # Column likely already exists

    con.execute("""CREATE TABLE IF NOT EXISTS embeddings(
        run_id TEXT,
        feature_id TEXT,
        method TEXT,
        polarity TEXT,
        vec_json TEXT,
        PRIMARY KEY(run_id, feature_id),
        FOREIGN KEY(run_id, feature_id) REFERENCES features(run_id, feature_id) ON DELETE CASCADE
    )""")
    con.commit()

# --- Helper functions for DB operations ---

def insert_run(con: sqlite3.Connection, run_id: str, meta_dict: Dict[str, Any]):
    """Inserts or replaces a run's metadata into the database."""
    con.execute(
        "INSERT OR REPLACE INTO runs(run_id, instrument, method, polarity, schema_version, meta_json) VALUES(?,?,?,?,?,?)",
        (run_id, meta_dict.get("instrument"), meta_dict.get("method"), meta_dict.get("polarity"), SCHEMA_VERSION, json.dumps(meta_dict)),
    )

def insert_feature(con: sqlite3.Connection, run_id: str, feature_data: models.Feature):
    """Inserts or replaces a feature (peptide) into the database."""
    con.execute(
        """INSERT OR REPLACE INTO features(run_id, feature_id, mz, rt_sec, intensity, adduct, polarity, annotation_name, annotation_score, meta_json)
           VALUES(?,?,?,?,?,?,?,?,?,?)""",
        (
            run_id,
            feature_data.feature_id,
            feature_data.mz,
            feature_data.rt_sec,
            feature_data.intensity,
            feature_data.adduct,
            feature_data.polarity,
            feature_data.peptide_sequence, # Map peptide_sequence to annotation_name DB column
            feature_data.annotation_score,
            json.dumps(feature_data.metadata)
        ),
    )

def insert_embedding(con: sqlite3.Connection, run_id: str, feature_id: str, method: str, polarity: str, vector: List[float]):
    """Inserts or replaces a peptide embedding into the database."""
    con.execute(
        """INSERT OR REPLACE INTO embeddings(run_id, feature_id, method, polarity, vec_json)
           VALUES(?,?,?,?,?)""",
        (run_id, feature_id, method, polarity, json.dumps(vector.tolist())),
    )

def get_run(con: sqlite3.Connection, run_id: str) -> Optional[models.Run]:
    """Retrieves a run's metadata."""
    cur = con.cursor()
    cur.execute("SELECT run_id, instrument, method, polarity, schema_version, meta_json FROM runs WHERE run_id=?", (run_id,))
    row = cur.fetchone()
    if row:
        return models.Run(run_id=row[0], instrument=row[1], method=row[2], polarity=row[3], schema_version=row[4], meta=json.loads(row[5]))
    return None

def get_features_for_run(con: sqlite3.Connection, run_id: str) -> List[models.Feature]:
    """Retrieves all features (peptides) for a given run."""
    cur = con.cursor()
    cur.execute("SELECT feature_id, mz, rt_sec, intensity, adduct, polarity, annotation_name, annotation_score, meta_json FROM features WHERE run_id=?", (run_id,))
    results = []
    for row in cur.fetchall():
        meta = json.loads(row[8]) if row[8] else {}
        results.append(models.Feature(
            feature_id=row[0], 
            mz=row[1], 
            rt_sec=row[2], 
            intensity=row[3], 
            adduct=row[4], 
            polarity=row[5], 
            peptide_sequence=row[6], 
            annotation_score=row[7],
            metadata=meta
        ))
    return results

def get_embedding(con: sqlite3.Connection, run_id: str, feature_id: str) -> Optional[List[float]]:
    """Retrieves a specific peptide embedding."""
    cur = con.cursor()
    cur.execute("SELECT vec_json FROM embeddings WHERE run_id=? AND feature_id=?", (run_id, feature_id))
    row = cur.fetchone()
    return json.loads(row[0]) if row else None

def get_feature_properties(con: sqlite3.Connection, run_id: str, feature_id: str) -> Optional[Tuple[str, float]]:
    """Retrieves the peptide sequence and intensity for a given feature."""
    cur = con.cursor()
    cur.execute("SELECT annotation_name, intensity FROM features WHERE run_id=? AND feature_id=? LIMIT 1", (run_id, feature_id))
    row = cur.fetchone()
    return (row[0], row[1]) if row else None

def get_all_embeddings_data(con: sqlite3.Connection) -> List[Tuple[str, str, str]]:
    """Retrieves all embedding data (run_id, feature_id, vec_json) from the database."""
    cur = con.cursor()
    cur.execute("SELECT run_id, feature_id, vec_json FROM embeddings")
    return cur.fetchall()

def get_run_summaries(con: sqlite3.Connection) -> List[Dict[str, Any]]:
    """Retrieves a summary of all runs with feature and embedding counts."""
    cur = con.cursor()
    cur.execute("""
        SELECT r.run_id, r.instrument, r.method, r.polarity, r.meta_json,
               COUNT(DISTINCT f.feature_id) as n_features,
               COUNT(DISTINCT e.feature_id) as n_embeddings
        FROM runs r
        LEFT JOIN features f ON r.run_id = f.run_id
        LEFT JOIN embeddings e ON r.run_id = e.run_id AND f.feature_id = e.feature_id
        GROUP BY r.run_id
    """)
    results = []
    for row in cur.fetchall():
        meta = json.loads(row[4]) if row[4] else {}
        results.append({
            "run_id": row[0],
            "instrument": row[1],
            "method": row[2],
            "polarity": row[3],
            "original_filename": meta.get("original_filename"),
            "n_features": row[5],
            "n_embeddings": row[6]
        })
    return results

====================
FILE: .\omicstoken_repo\embeddings.py
====================
import numpy as np

# --- Configuration ---
# Dimension of the peptide embedding vector.
EMBEDDING_DIM = 16

_AMINO_ALPHABET = "ACDEFGHIKLMNPQRSTVWY"
_AMINO_INDEX = {aa: i for i, aa in enumerate(_AMINO_ALPHABET)}


def _sequence_to_basic_features(sequence: str) -> np.ndarray:
    """
    Very simple, fast, *local* embedder that does NOT require external libraries.

    It turns a peptide into a small numeric vector:
      - length
      - mean position in alphabet
      - fraction of charged residues (D, E, K, R, H)
      - fraction of hydrophobic residues (A, V, I, L, M, F, Y, W)
      - plus a small fixed-length bag-of-amino-acids representation
    """
    if not sequence or not isinstance(sequence, str):
        return np.zeros((EMBEDDING_DIM,), dtype=np.float32)

    seq = sequence.strip().upper()
    if not seq:
        return np.zeros((EMBEDDING_DIM,), dtype=np.float32)

    length = len(seq)

    charged = set("DEKRH")
    hydrophobic = set("AVILMFWY")

    charged_count = sum(1 for aa in seq if aa in charged)
    hydrophobic_count = sum(1 for aa in seq if aa in hydrophobic)

    charged_frac = charged_count / length
    hydrophobic_frac = hydrophobic_count / length

    indices = [_AMINO_INDEX.get(aa, 0) for aa in seq]
    mean_idx = float(sum(indices)) / length

    bag_dim = EMBEDDING_DIM - 4  # we already used 4 slots above
    bag = np.zeros((bag_dim,), dtype=np.float32)

    for aa in seq:
        idx = _AMINO_INDEX.get(aa)
        if idx is not None and idx < bag_dim:
            bag[idx] += 1.0

    if bag.sum() > 0:
        bag = bag / bag.sum()

    vec = np.concatenate(
        [
            np.array(
                [length, mean_idx, charged_frac, hydrophobic_frac],
                dtype=np.float32,
            ),
            bag.astype(np.float32),
        ]
    )

    if vec.shape[0] != EMBEDDING_DIM:
        vec = np.resize(vec, (EMBEDDING_DIM,)).astype(np.float32)

    return vec


def peptide_to_vector(sequence: str) -> np.ndarray:
    """
    Public function used by the rest of the app.

    Later, I can replace this implementation with a real ProtTrans-based embedder,
    but for now it's a lightweight, dependency-free embedding that always returns
    an EMBEDDING_DIM-dimensional vector.
    """
    return _sequence_to_basic_features(sequence)

====================
FILE: .\omicstoken_repo\importers.py
====================
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional
from models import Feature

def parse_tumor_csv(df: pd.DataFrame) -> List[Feature]:
    """
    Parses tumor proteomics CSVs with stats columns.
    Expected columns: Accession, Description, samples..., Fold Change, q-value, etc.
    """
    features = []
    
    # Identify sample columns (columns that are not stats or metadata)
    # This is a heuristic: exclude known non-sample columns
    exclude_cols = {
        "Accession", "Description", "Gene Symbol", "Entrez Gene ID", 
        "Fold Change", "Log2 Fold Change", "p-value", "q-value", 
        "Wilcoxon p-value", "t-test p-value", "Resampled p-value",
        "Significant", "Pi Score"
    }
    
    # Normalize columns for easier matching
    df_cols_map = {c.lower(): c for c in df.columns}
    
    # Find key columns
    acc_col = df_cols_map.get("accession")
    desc_col = df_cols_map.get("description")
    
    if not acc_col:
        # Fallback: try to find a column that looks like an ID
        for c in df.columns:
            if "accession" in c.lower() or "protein" in c.lower() or "id" in c.lower():
                acc_col = c
                break
    
    if not acc_col:
        raise ValueError("Could not identify Accession/ID column in tumor CSV.")

    # Identify stats columns
    stats_cols = []
    for c in df.columns:
        lower_c = c.lower()
        if "fold change" in lower_c or "p-value" in lower_c or "q-value" in lower_c or "score" in lower_c:
            stats_cols.append(c)
            
    # Identify sample columns (everything else)
    sample_cols = [c for c in df.columns if c not in exclude_cols and c not in stats_cols and c != acc_col and c != desc_col]
    
    for i, row in df.iterrows():
        accession = str(row[acc_col])
        description = str(row[desc_col]) if desc_col else ""
        
        # Calculate a representative intensity (e.g., max or mean of samples)
        # For the MVP, we'll just take the max to have something non-zero
        intensities = [float(row[c]) for c in sample_cols if pd.to_numeric(row[c], errors='coerce') >= 0]
        rep_intensity = max(intensities) if intensities else 0.0
        
        # Collect stats into metadata
        meta = {
            "description": description,
            "stats": {c: row[c] for c in stats_cols},
            "samples": {c: row[c] for c in sample_cols}
        }
        
        features.append(Feature(
            feature_id=f"TUMOR_{i}_{accession}",
            peptide_sequence=accession, # Using Accession as sequence for now
            intensity=rep_intensity,
            mz=0.0, # Not applicable
            rt_sec=None,
            adduct=None,
            polarity=None,
            metadata=meta
        ))
        
    return features

def detect_format(df: pd.DataFrame) -> str:
    """
    Simple heuristic to detect the format of the uploaded CSV.
    """
    cols = set(df.columns)
    # Check for tumor format specific columns
    lower_cols = {c.lower() for c in cols}
    if "accession" in lower_cols and ("fold change" in lower_cols or "q-value" in lower_cols):
        return "tumor_csv"
        
    if "Sequence" in cols and "Intensity" in cols and "Modified sequence" in cols:
        return "maxquant"
    if "Precursor.Id" in cols and "Stripped.Sequence" in cols:
        return "diann"
    if "PEP.StrippedSequence" in cols:
        return "spectronaut"
    return "generic"

def parse_upload(df: pd.DataFrame, fmt: str = "auto") -> List[Feature]:
    if fmt == "auto":
        fmt = detect_format(df)
    
    if fmt == "tumor_csv":
        return parse_tumor_csv(df)
    elif fmt == "maxquant":
        return parse_maxquant(df)
    elif fmt == "diann":
        return parse_diann(df)
    elif fmt == "spectronaut":
        return parse_spectronaut(df)
    else:
        return parse_generic(df)

def parse_generic(df: pd.DataFrame) -> List[Feature]:
    """
    Parses a generic CSV with 'feature_id', 'peptide_sequence', 'intensity' columns.
    """
    features = []
    # Normalize column names to lowercase for easier matching
    df.columns = [c.lower() for c in df.columns]
    
    # Map common variations
    col_map = {
        "feature_id": ["feature_id", "id", "peptide_id"],
        "peptide_sequence": ["peptide_sequence", "sequence", "annotation_name", "seq"],
        "intensity": ["intensity", "area", "abundance"],
        "mz": ["mz", "m/z", "mass_to_charge"],
        "rt_sec": ["rt_sec", "rt", "retention_time"],
        "adduct": ["adduct", "charge_state"], # approximate
        "polarity": ["polarity"]
    }

    def get_col(variations):
        for v in variations:
            if v in df.columns:
                return v
        return None

    fid_col = get_col(col_map["feature_id"])
    seq_col = get_col(col_map["peptide_sequence"])
    int_col = get_col(col_map["intensity"])
    mz_col = get_col(col_map["mz"])
    rt_col = get_col(col_map["rt_sec"])

    if not (fid_col and seq_col and int_col):
        raise ValueError(f"Generic CSV missing required columns. Found: {list(df.columns)}")

    for i, row in df.iterrows():
        features.append(Feature(
            feature_id=str(row[fid_col]),
            peptide_sequence=str(row[seq_col]),
            intensity=float(row[int_col]),
            mz=float(row[mz_col]) if mz_col and pd.notna(row[mz_col]) else 0.0,
            rt_sec=float(row[rt_col]) if rt_col and pd.notna(row[rt_col]) else None,
            adduct=None,
            polarity=None,
            annotation_score=None
        ))
    return features

def parse_maxquant(df: pd.DataFrame) -> List[Feature]:
    """
    Parses MaxQuant peptides.txt format.
    """
    features = []
    # MaxQuant usually has 'Sequence', 'Intensity', 'id'
    for i, row in df.iterrows():
        features.append(Feature(
            feature_id=str(row.get("id", f"MQ_{i}")),
            peptide_sequence=str(row.get("Sequence", "")),
            intensity=float(row.get("Intensity", 0.0)),
            mz=float(row.get("Mass", 0.0)), # Mass is not m/z but close enough for MVP placeholder
            rt_sec=float(row.get("Retention time", 0.0)) * 60 if "Retention time" in df.columns else None,
            adduct=str(row.get("Charge", "")),
            polarity=None
        ))
    return features

def parse_diann(df: pd.DataFrame) -> List[Feature]:
    """
    Parses DIA-NN report.tsv format.
    """
    features = []
    for i, row in df.iterrows():
        features.append(Feature(
            feature_id=str(row.get("Precursor.Id", f"DIA_{i}")),
            peptide_sequence=str(row.get("Stripped.Sequence", "")),
            intensity=float(row.get("Precursor.Quantity", 0.0)),
            mz=float(row.get("Precursor.Mz", 0.0)),
            rt_sec=float(row.get("RT", 0.0)) * 60,
            adduct=str(row.get("Precursor.Charge", "")),
            polarity=None
        ))
    return features

def parse_spectronaut(df: pd.DataFrame) -> List[Feature]:
    """
    Parses Spectronaut export format.
    """
    features = []
    for i, row in df.iterrows():
        features.append(Feature(
            feature_id=f"SPEC_{i}", # Spectronaut exports might vary, using index for now
            peptide_sequence=str(row.get("PEP.StrippedSequence", "")),
            intensity=float(row.get("PEP.Quantity", 0.0)),
            mz=0.0,
            rt_sec=float(row.get("PEP.RT", 0.0)) * 60,
            adduct=None,
            polarity=None
        ))
    return features




====================
FILE: .\omicstoken_repo\list_models.py
====================
"""
List available Gemini models
"""
import os
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=api_key)

print("Available Gemini models:")
for m in genai.list_models():
    if 'generateContent' in m.supported_generation_methods:
        print(f"  - {m.name}")


====================
FILE: .\omicstoken_repo\models.py
====================
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Any, Tuple

# -------------------- Data Models --------------------

class HealthResponse(BaseModel):
    ok: bool
    schema: str

class Spectrum(BaseModel):
    mz_array: List[float]
    intensity_array: List[float]

class Feature(BaseModel):
    # This model is now used for Peptides. `peptide_sequence` will hold the sequence.
    # The `alias` is used to map to the 'annotation_name' column in the DB for backward compatibility.
    model_config = ConfigDict(populate_by_name=True)

    feature_id: str
    mz: float
    rt_sec: Optional[float] = None
    intensity: float
    adduct: Optional[str] = None
    polarity: Optional[str] = None
    peptide_sequence: Optional[str] = Field(None, alias="annotation_name") # Maps to annotation_name in DB
    annotation_score: Optional[float] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)

class Run(BaseModel):
    run_id: str
    instrument: Optional[str] = None
    method: Optional[str] = None
    polarity: Optional[str] = None
    schema_version: str
    meta: Dict[str, Any] = {}
    features: Optional[List[Feature]] = None # Optional for when fetching run metadata without all features

class QueryPeptide(BaseModel):
    run_id: str
    feature_id: str
    peptide_sequence: Optional[str] = Field(None, alias="annotation_name")
    intensity: Optional[float] = None

class SimilarPeptide(BaseModel):
    run_id: str
    feature_id: str
    peptide_sequence: Optional[str] = Field(None, alias="annotation_name")
    similarity: float
    intensity: Optional[float] = None

class SimilarPeptidesResponse(BaseModel):
    query: QueryPeptide
    neighbors: List[SimilarPeptide]

====================
FILE: .\omicstoken_repo\prepare_cachexia_dataset.py
====================


====================
FILE: .\omicstoken_repo\prepare_ibd_dataset.py
====================
"""
A utility script to prepare a public metabolomics dataset (Human Cachexia) from
MetaboAnalyst for ingestion into the Metabo-MVP application.

This script will:
1. Define the source URL for the raw data.
2. Load the raw data, which is in a "wide" format (samples in columns).
3. Transform the data into a "long" feature list for a single sample.
4. Parse combined peak names (e.g., "mz_rt") into separate columns.
5. Save the cleaned data to a new CSV file, ready for our application.
"""

import pandas as pd
import urllib.request
import os

# --- Configuration ---

# Get the project's root directory (where this script is located)
APP_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(APP_DIR, "data")

# Ensure the data directory exists
os.makedirs(DATA_DIR, exist_ok=True)

# Source URL for the MetaboAnalyst Human Cachexia dataset (this can be unstable)
SOURCE_URL = "https://rest.xialab.ca/api/download/metaboanalyst/human_cachexia.csv"
LOCAL_RAW_PATH = os.path.join(DATA_DIR, "human_cachexia.csv")

# Path to save the final, cleaned CSV file
OUTPUT_PATH = os.path.join(DATA_DIR, "prepared_metaboanalyst_cachexia.csv")


def main():
    """Main function to run the data preparation pipeline."""
    print("Starting dataset preparation...")

    # --- Robust Data Loading ---
    # 1. Check if the raw data file already exists locally.
    if not os.path.exists(LOCAL_RAW_PATH):
        print(f"Raw data not found locally. Attempting to download from {SOURCE_URL}")
        try:
            # 2. If not, try to download it.
            urllib.request.urlretrieve(SOURCE_URL, LOCAL_RAW_PATH)
            print(f"âœ… Download successful. Saved to {LOCAL_RAW_PATH}")
        except Exception as e:
            # 3. If download fails, give the user clear instructions.
            print(f"\nâŒ ERROR: Could not download the data file: {e}")
            print("\n--- MANUAL ACTION REQUIRED ---")
            print(f"1. Open this URL in your browser: {SOURCE_URL}")
            print("2. Save the file as 'human_cachexia.csv'")
            print(f"3. Place the file inside this directory: {DATA_DIR}")
            print("4. Run this script again.")
            return # Stop execution

    # Load the raw data, treating the first column as the index (peak names)
    df = pd.read_csv(LOCAL_RAW_PATH)

    print(f"Raw data loaded. Shape: {df.shape}")

    # We will transform the data for the first sample (first row) into a "long" feature list.
    first_sample_row = df.iloc[0]
    sample_id = first_sample_row.iloc[0]
    print(f"Extracting feature list for the first sample: '{sample_id}'")

    # The first two columns are metadata ('Patient ID', 'Muscle loss'). Features start from the 3rd column.
    feature_data = first_sample_row.iloc[2:]

    # Create a new DataFrame from this series
    final_df = pd.DataFrame({
        'feature_id': feature_data.index,
        'intensity': feature_data.values
    })

    # This dataset does not contain m/z or rt, so we will create placeholder values.
    final_df['mz'] = final_df['feature_id'].apply(lambda x: 100 + (hash(x) % 90000) / 100.0)
    final_df['rt_sec'] = 0.0 # No retention time provided

    print(f"Saving cleaned data with {len(final_df)} rows to {OUTPUT_PATH}")
    final_df.to_csv(OUTPUT_PATH, index=False)

    print("âœ… Dataset preparation complete!")

if __name__ == "__main__":
    # Call the main function to execute the script's logic
    main()


====================
FILE: .\omicstoken_repo\prepare_peptide_dataset.py
====================


====================
FILE: .\omicstoken_repo\search.py
====================
import faiss
import numpy as np
import json
import os
import sqlite3
from typing import List, Tuple
from fastapi import HTTPException

import db
import embeddings
import models

# --- Configuration ---
FAISS_INDEX_FILENAME = "peptides.faiss"
FAISS_IDS_FILENAME = "peptides_ids.json"

def get_faiss_index_path(data_dir: str) -> str:
    return os.path.join(data_dir, FAISS_INDEX_FILENAME)

def get_faiss_ids_path(data_dir: str) -> str:
    return os.path.join(data_dir, FAISS_IDS_FILENAME)

def rebuild_faiss_index(con: sqlite3.Connection, data_dir: str):
    """
    Queries all embeddings from the DB, builds a FAISS index, and saves it.
    This is slow and should be run as a background task in a real app.
    """
    print("Rebuilding FAISS index...")
    faiss_index_path = get_faiss_index_path(data_dir)
    faiss_ids_path = get_faiss_ids_path(data_dir)

    rows = db.get_all_embeddings_data(con)

    if not rows:
        print("No embeddings found to build index.")
        # Ensure any old index files are removed if no embeddings exist
        if os.path.exists(faiss_index_path): os.remove(faiss_index_path)
        if os.path.exists(faiss_ids_path): os.remove(faiss_ids_path)
        return 0

    ids = [(row[0], row[1]) for row in rows] # (run_id, feature_id)
    vectors = np.array([json.loads(row[2]) for row in rows], dtype=np.float32)

    d = vectors.shape[1]  # vector dimension
    index = faiss.IndexFlatL2(d)  # Using L2 distance
    faiss.normalize_L2(vectors) # Normalize vectors to use L2 as cosine similarity
    index.add(vectors)

    faiss.write_index(index, faiss_index_path)
    with open(faiss_ids_path, "w") as f:
        json.dump(ids, f)
    print(f"FAISS index rebuilt with {index.ntotal} vectors.")
    return index.ntotal

def search_similar_peptides(con: sqlite3.Connection, data_dir: str, run_id: str, feature_id: str, k: int = 5) -> models.SimilarPeptidesResponse:
    """Finds peptides with similar biophysical properties using vector similarity."""
    faiss_index_path = get_faiss_index_path(data_dir)
    faiss_ids_path = get_faiss_ids_path(data_dir)

    if not os.path.exists(faiss_index_path) or not os.path.exists(faiss_ids_path):
        raise HTTPException(404, "FAISS index not found. Please upload data and ensure embeddings are generated.")

    index = faiss.read_index(faiss_index_path)
    with open(faiss_ids_path, "r") as f:
        ids_map = json.load(f)

    query_vector_list = db.get_embedding(con, run_id, feature_id)
    if not query_vector_list:
        raise HTTPException(404, f"Embedding for feature '{feature_id}' in run '{run_id}' not found (did you embed it?).")
    query_vector = np.array(query_vector_list, dtype=np.float32).reshape(1, -1)
    faiss.normalize_L2(query_vector)

    query_feat_props = db.get_feature_properties(con, run_id, feature_id)
    if not query_feat_props:
        raise HTTPException(404, f"Original feature '{feature_id}' in run '{run_id}' not found in DB.")

    distances, indices = index.search(query_vector, k)

    out = []
    for i, idx in enumerate(indices[0]):
        if idx == -1: continue
        neighbor_run_id, neighbor_feature_id = ids_map[idx]
        dist = distances[0][i]
        similarity = 1.0 - (dist**2) / 2.0 # Convert L2 distance back to cosine similarity

        feat_row = db.get_feature_properties(con, neighbor_run_id, neighbor_feature_id)
        out.append(models.SimilarPeptide(
            run_id=neighbor_run_id,
            feature_id=neighbor_feature_id,
            peptide_sequence=feat_row[0] if feat_row else None,
            similarity=float(similarity),
            intensity=feat_row[1] if feat_row else None,
        ))

    query_peptide = models.QueryPeptide(
        run_id=run_id,
        feature_id=feature_id,
        peptide_sequence=query_feat_props[0],
        intensity=query_feat_props[1]
    )

    return models.SimilarPeptidesResponse(query=query_peptide, neighbors=out)

====================
FILE: .\omicstoken_repo\summarizer.py
====================
import os
import google.generativeai as genai
from typing import Dict, Any, List
import db
import models

# Configure Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    print("Warning: GEMINI_API_KEY not found in environment variables!")

def generate_summary(run_id: str, con=None) -> Dict[str, Any]:
    """
    Generates a summary for a given run using Gemini API.
    Provides scientific insights about peptide composition and patterns.
    """
    # Check if API key is configured
    if not GEMINI_API_KEY:
        return {
            "error": "GEMINI_API_KEY not configured. Please set it in your .env file.",
            "run_id": run_id
        }
    
    if con is None:
        con = db.get_db_connection(db.get_db_path("data"))
    
    # Fetch basic stats
    features = db.get_features_for_run(con, run_id)
    if not features:
        return {"error": "No features found for this run.", "run_id": run_id}
    
    # Check if this is a tumor run with stats
    is_tumor_run = False
    if features and features[0].metadata and "stats" in features[0].metadata:
        is_tumor_run = True
        
    if is_tumor_run:
        return _generate_tumor_summary(run_id, features)
    else:
        return _generate_peptide_summary(run_id, features)

def _generate_tumor_summary(run_id: str, features: List[models.Feature]) -> Dict[str, Any]:
    num_proteins = len(features)
    
    # Extract stats
    sig_proteins = []
    up_regulated = []
    down_regulated = []
    
    for f in features:
        stats = f.metadata.get("stats", {})
        # Try to find q-value or p-value
        q_val = None
        for k, v in stats.items():
            if "q-value" in k.lower():
                q_val = float(v)
                break
        if q_val is None:
             for k, v in stats.items():
                if "p-value" in k.lower() and "wilcoxon" not in k.lower() and "t-test" not in k.lower():
                    q_val = float(v) # Fallback to p-value
                    break
        
        # Try to find fold change
        fc = None
        for k, v in stats.items():
            if "fold change" in k.lower() and "log2" not in k.lower():
                fc = float(v)
                break
        
        if q_val is not None and q_val < 0.05:
            sig_proteins.append(f)
            
        if fc is not None:
            if fc > 0:
                up_regulated.append((f, fc))
            elif fc < 0:
                down_regulated.append((f, fc))
                
    # Sort up/down
    up_regulated.sort(key=lambda x: x[1], reverse=True)
    down_regulated.sort(key=lambda x: x[1]) # Most negative first
    
    top_up = up_regulated[:5]
    top_down = down_regulated[:5]
    
    # Build prompt
    up_list = "\n".join([f"- {f.peptide_sequence}: FC={fc:.2f} ({f.metadata.get('description', '')})" for f, fc in top_up])
    down_list = "\n".join([f"- {f.peptide_sequence}: FC={fc:.2f} ({f.metadata.get('description', '')})" for f, fc in top_down])
    
    prompt = f"""You are an expert proteomics data analyst. Analyze this differential expression dataset.
    
    Comparison: {run_id} (Inferred from filename/ID)
    Total Proteins: {num_proteins}
    Significant Proteins (q<0.05): {len(sig_proteins)}
    
    Top Upregulated Proteins:
    {up_list}
    
    Top Downregulated Proteins:
    {down_list}
    
    Provide a concise scientific summary of these findings. Mention the specific proteins and their potential biological relevance if known.
    """
    
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        summary_text = response.text
        
        return {
            "run_id": run_id,
            "type": "tumor_comparison",
            "num_proteins": num_proteins,
            "num_significant": len(sig_proteins),
            "top_up": [{"accession": f.peptide_sequence, "fc": fc, "desc": f.metadata.get("description")} for f, fc in top_up],
            "top_down": [{"accession": f.peptide_sequence, "fc": fc, "desc": f.metadata.get("description")} for f, fc in top_down],
            "summary_text": summary_text
        }
    except Exception as e:
        return {"error": f"Gemini API Error: {str(e)}", "run_id": run_id}

def _generate_peptide_summary(run_id: str, features: List[models.Feature]) -> Dict[str, Any]:
    num_peptides = len(features)
    avg_intensity = sum(f.intensity for f in features) / num_peptides if num_peptides > 0 else 0
    
    # Sort by intensity to find "top" peptides
    sorted_features = sorted(features, key=lambda x: x.intensity, reverse=True)
    top_10 = sorted_features[:10]
    top_sequences = [f.peptide_sequence for f in top_10]
    top_intensities = [f.intensity for f in top_10]
    
    # Calculate additional statistics
    min_intensity = min(f.intensity for f in features)
    max_intensity = max(f.intensity for f in features)
    
    # Get sequence length distribution
    seq_lengths = [len(f.peptide_sequence) if f.peptide_sequence else 0 for f in features]
    avg_seq_length = sum(seq_lengths) / len(seq_lengths) if seq_lengths else 0
    
    # --- Enhanced Metrics ---
    # 1. Charge Distribution (Adducts)
    adduct_counts = {}
    for f in features:
        a = f.adduct if f.adduct else "Unknown"
        adduct_counts[a] = adduct_counts.get(a, 0) + 1
    
    # 2. Hydrophobicity (GRAVY score approximation)
    # Kyte-Doolittle scale
    hydropathy = {
        'I': 4.5, 'V': 4.2, 'L': 3.8, 'F': 2.8, 'C': 2.5, 'M': 1.9, 'A': 1.8,
        'G': -0.4, 'T': -0.7, 'S': -0.8, 'W': -0.9, 'Y': -1.3, 'P': -1.6,
        'H': -3.2, 'E': -3.5, 'Q': -3.5, 'D': -3.5, 'N': -3.5, 'K': -3.9, 'R': -4.5
    }
    
    def calculate_gravy(seq):
        if not seq: return 0
        score = sum(hydropathy.get(aa.upper(), 0) for aa in seq)
        return score / len(seq)

    gravy_scores = [calculate_gravy(f.peptide_sequence) for f in features]
    avg_gravy = sum(gravy_scores) / len(gravy_scores) if gravy_scores else 0
    
    # Binning GRAVY scores
    hydrophobic_count = sum(1 for s in gravy_scores if s > 0)
    hydrophilic_count = sum(1 for s in gravy_scores if s <= 0)

    # 3. Clustering (FAISS K-Means)
    # We need embeddings for this. 
    # Since we don't have easy access to embeddings here without querying DB again, 
    # we will skip actual K-Means for this MVP step to avoid circular imports/complexity,
    # OR we can generate them on the fly since we have the code.
    # Let's do a simple sequence-based clustering (e.g. by length or start AA) for the prompt
    # to keep it fast and dependency-free in this module.
    # Actually, let's just report the hydrophobicity clusters.
    
    # Build a scientific prompt for Gemini
    peptide_list = "\n".join([
        f"{i+1}. {seq} (Intensity: {int_val:,.0f})" 
        for i, (seq, int_val) in enumerate(zip(top_sequences[:5], top_intensities[:5]))
    ])
    
    adduct_str = ", ".join([f"{k}: {v}" for k, v in adduct_counts.items()])
    
    prompt = f"""You are an expert proteomics data analyst. Analyze this peptide dataset and provide a concise scientific summary.

Dataset: Run ID "{run_id}"

Key Statistics:
- Total Peptides: {num_peptides}
- Intensity: Avg {avg_intensity:,.0f} (Range: {min_intensity:,.0f} - {max_intensity:,.0f})
- Sequence Length: Avg {avg_seq_length:.1f} AA

Physicochemical Properties:
- Hydrophobicity (GRAVY): Avg {avg_gravy:.2f}
- Hydrophobic Peptides: {hydrophobic_count}
- Hydrophilic Peptides: {hydrophilic_count}
- Charge States (Adducts): {adduct_str}

Top 5 Peptides by Abundance:
{peptide_list}

Please provide a 2-3 paragraph summary covering:
1. Overall dataset characteristics and quality.
2. Physicochemical profile (hydrophobicity, charge). What does this suggest about the sample preparation or column type?
3. Biological significance of the top peptides.
4. Recommendations for downstream analysis.

Keep the summary scientific but accessible.
"""

    try:
        # Initialize Gemini model
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # Generate content
        response = model.generate_content(prompt)
        summary_text = response.text
        
        return {
            "run_id": run_id,
            "num_peptides": num_peptides,
            "avg_intensity": avg_intensity,
            "min_intensity": min_intensity,
            "max_intensity": max_intensity,
            "avg_sequence_length": avg_seq_length,
            "physico_chem": {
                "avg_gravy": avg_gravy,
                "hydrophobic_count": hydrophobic_count,
                "hydrophilic_count": hydrophilic_count,
                "adduct_counts": adduct_counts
            },
            "top_peptides": [
                {
                    "sequence": seq,
                    "intensity": int_val,
                    "feature_id": top_10[i].feature_id
                }
                for i, (seq, int_val) in enumerate(zip(top_sequences[:10], top_intensities[:10]))
            ],
            "summary_text": summary_text,
            "llm_model": "gemini-2.5-flash"
        }
    
    except Exception as e:
        return {
            "error": f"Failed to generate summary: {str(e)}",
            "run_id": run_id,
            "num_peptides": num_peptides,
            "avg_intensity": avg_intensity,
            "top_peptides": top_sequences[:5]
        }


====================
FILE: .\omicstoken_repo\test_gemini.py
====================
"""
Quick test to verify Gemini API integration works correctly.
"""
import os
from dotenv import load_dotenv
import google.generativeai as genai

# Load environment variables
load_dotenv()

# Check if key exists
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("âŒ GEMINI_API_KEY not found in environment!")
    exit(1)
else:
    print(f"âœ… API Key found: {api_key[:20]}...")

try:
    # Configure and test the API
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    # Simple test query
    print("\nðŸ§ª Testing Gemini API connection...")
    response = model.generate_content("Say 'Hello from Gemini!' in a scientific tone.")
    
    print(f"âœ… Gemini API works!")
    print(f"\nðŸ“ Response:\n{response.text}\n")
    
    print("ðŸŽ‰ All checks passed! Your Gemini integration is ready.")
    
except Exception as e:
    print(f"âŒ Error: {str(e)}")
    exit(1)


====================
FILE: .\omicstoken_repo\upload_error.html
====================
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Immuno-Engine - Upload Error</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 2rem; }
  </style>
</head>
<body>
  <h3>Upload failed</h3>
  <p>An error occurred during the upload or processing:</p>
  <pre>{{ error_message }}</pre>
  <p><a href='/upload'>Back to Upload</a></p>
  <p>Or use the API docs: <a href="/docs">/docs</a></p>
</body>
</html>

====================
FILE: .\omicstoken_repo\upload_form.html
====================
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Immuno-Engine - Upload Peptide Data</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 2rem; }
    form { display: block; max-width: 560px; padding: 1rem; border: 1px solid #ddd; border-radius: 8px; }
    label { display:block; margin-top: 1rem; font-weight: 600; }
    input, select, textarea { width: 100%; padding: .6rem; margin-top: .4rem; }
    button { margin-top: 1rem; padding: .6rem 1rem; cursor: pointer; }
    .tip { color:#555; font-size:.9rem; margin-bottom: 1rem; }
    .row { display: grid; grid-template-columns: 1fr 1fr; gap: 12px; }
  </style>
</head>
<body>
  <h1>Upload Peptide Table</h1>
  <p class="tip">Accepted files: CSV with columns: <code>feature_id, peptide_sequence, intensity</code>.<br/><code>peptide_sequence</code> should contain the amino acid sequence.</p>

  <form action="/upload" method="post" enctype="multipart/form-data">
    <label>Peptide table file (CSV)
      <input type="file" name="file" required />
    </label>

    <div class="row">
      <div>
        <label>Run ID (optional)
          <input type="text" name="run_id" placeholder="e.g., RUN_2025_11_03_A" />
        </label>
      </div>
      <div>
        <label>Instrument (optional)
          <input type="text" name="instrument" placeholder="e.g., Q Exactive" />
        </label>
      </div>
    </div>

    <div class="row">
      <div>
        <label>Method (optional)
          <input type="text" name="method" placeholder="e.g., HILIC or RP" />
        </label>
      </div>
      <div>
        <label>Polarity (optional)
          <select name="polarity">
            <option value="">(none)</option>
            <option value="POS">POS</option>
            <option value="NEG">NEG</option>
          </select>
        </label>
      </div>
    </div>

    <p class="tip">Tip: If youâ€™re unsure, leave fields blankâ€”defaults are okay.</p>
    <button type="submit">Upload & Ingest</button>
  </form>

  <p style="margin-top:2rem;">Or use the API docs: <a href="/docs">/docs</a></p>
</body>
</html>

====================
FILE: .\omicstoken_repo\upload_success.html
====================
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Immuno-Engine - Upload Success</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 2rem; }
  </style>
</head>
<body>
  <h2>Upload complete</h2>
  <p>Run ID: <b>{{ run_id }}</b></p>
  <p>âœ… Rows ingested: <b>{{ rows_ingested }}</b></p>
  <p>
    The embedding and indexing process has been started in the background.
    It may take a moment for the index to be fully rebuilt, especially for large files.
  </p>
  <p>
    Next steps:
    <ul>
      {{ search_link_html | safe }}
      <li><a href="/docs#/default/similar_peptide_search__run_id___feature_id__get" target="_blank">Go to API docs for custom search</a></li>
    </ul>
  </p>
  <p><a href="/upload">Upload another file</a></p>
</body>
</html>

====================
FILE: .\omicstoken_repo\verify_summary.py
====================
import os
import sys
import json
from unittest.mock import MagicMock, patch
from fastapi.testclient import TestClient

# Mock google.generativeai before importing app
# This allows us to test the integration without a real API key or network call
mock_genai = MagicMock()
sys.modules["google.generativeai"] = mock_genai

# Now import app
from app import app

client = TestClient(app)

def test_summarization_flow():
    print("1. Uploading test data...")
    # Create a dummy CSV content
    csv_content = "Sequence,Intensity,Modified sequence\nPEPTIDE,100000,PEPTIDE\nANOTHER,50000,ANOTHER"
    files = {"file": ("test.csv", csv_content, "text/csv")}
    
    response = client.post("/upload", files=files, data={"format": "maxquant", "run_id": "TEST_RUN_001"})
    
    if response.status_code != 200:
        print(f"âŒ Upload failed: {response.status_code}")
        print(response.text)
        return
    
    print("âœ… Upload successful.")
    
    print("2. Testing Summarization Endpoint...")
    
    # Mock the generate_content response
    mock_model = MagicMock()
    mock_response = MagicMock()
    mock_response.text = "This is a mock scientific summary of the peptide data."
    mock_model.generate_content.return_value = mock_response
    
    # Patch the GenerativeModel constructor
    with patch("google.generativeai.GenerativeModel", return_value=mock_model):
        # We need to set a dummy API key in env if not present, 
        # because summarizer.py checks for it.
        if "GEMINI_API_KEY" not in os.environ:
            os.environ["GEMINI_API_KEY"] = "dummy_key"
            
        # Force reload of summarizer module to pick up the env var if needed? 
        # Actually, summarizer.py reads env at module level. 
        # If it was already imported by app, it might have seen None.
        # Let's patch the module-level variable if needed, but patching os.environ before import is best.
        # Since app is already imported, let's check summarizer.GEMINI_API_KEY
        import summarizer
        summarizer.GEMINI_API_KEY = "dummy_key" # Force it for the test
        
        response = client.post("/summary/run/TEST_RUN_001")
        
        if response.status_code == 200:
            data = response.json()
            print("âœ… Summarization request successful.")
            print(f"   Summary: {data.get('summary_text')}")
            
            if data.get("summary_text") == "This is a mock scientific summary of the peptide data.":
                print("âœ… Mock response verified.")
            else:
                print("âš ï¸ Unexpected response content.")
                
            if data.get("num_peptides") == 2:
                print("âœ… Correct number of peptides analyzed.")
            else:
                print(f"âš ï¸ Expected 2 peptides, got {data.get('num_peptides')}")
                
        else:
            print(f"âŒ Summarization failed: {response.status_code}")
            print(response.text)

if __name__ == "__main__":
    test_summarization_flow()


====================
FILE: .\omicstoken_repo\verify_tumor_flow.py
====================
import os
import sys
from unittest.mock import MagicMock, patch
from fastapi.testclient import TestClient

# Mock google.generativeai
mock_genai = MagicMock()
sys.modules["google.generativeai"] = mock_genai

from app import app

client = TestClient(app)

def test_tumor_workflow():
    print("1. Uploading Tumor CSV...")
    # Create dummy tumor CSV
    csv_content = """Accession,Description,Melanoma-1,Melanoma-2,Fold Change,q-value
P12345,Protein A,100,110,2.5,0.01
P67890,Protein B,50,60,-1.5,0.04
P54321,Protein C,200,210,0.1,0.5
"""
    files = {"file": ("tumor_test.csv", csv_content, "text/csv")}
    response = client.post("/upload", files=files, data={"format": "auto", "run_id": "TUMOR_RUN_001"})
    
    if response.status_code != 200:
        print(f"[FAIL] Upload failed: {response.status_code}")
        print(response.text)
        return
    print("[PASS] Upload successful.")
    
    print("2. Checking /runs endpoint...")
    response = client.get("/runs")
    if response.status_code == 200:
        runs = response.json()
        found = False
        for r in runs:
            if r["run_id"] == "TUMOR_RUN_001":
                found = True
                print(f"[PASS] Found run in list. Features: {r['n_features']}")
                if r['n_features'] == 3:
                    print("[PASS] Feature count correct.")
                else:
                    print(f"[WARN] Expected 3 features, got {r['n_features']}")
                break
        if not found:
            print("[FAIL] Run not found in /runs list.")
    else:
        print(f"[FAIL] /runs failed: {response.status_code}")

    print("3. Checking Run Details...")
    response = client.get("/runs/TUMOR_RUN_001")
    if response.status_code == 200:
        details = response.json()
        print("[PASS] Run details fetched.")
        if details["stats"]["n_features"] == 3:
            print("[PASS] Stats correct.")
    else:
        print(f"[FAIL] /runs/ID failed: {response.status_code}")

    print("4. Testing Tumor Summary...")
    # Mock Gemini response
    mock_model = MagicMock()
    mock_response = MagicMock()
    mock_response.text = "Tumor summary generated."
    mock_model.generate_content.return_value = mock_response
    
    with patch("google.generativeai.GenerativeModel", return_value=mock_model):
        # Patch API key check
        import summarizer
        summarizer.GEMINI_API_KEY = "dummy"
        
        response = client.post("/summary/run/TUMOR_RUN_001")
        if response.status_code == 200:
            data = response.json()
            print("[PASS] Summary generated.")
            if data.get("type") == "tumor_comparison":
                print("[PASS] Correctly identified as tumor comparison.")
            else:
                print(f"[WARN] Expected type 'tumor_comparison', got {data.get('type')}")
                
            if data.get("num_significant") == 2:
                print("[PASS] Correct significant count (2).")
            else:
                print(f"[WARN] Expected 2 significant, got {data.get('num_significant')}")
        else:
            print(f"[FAIL] Summary failed: {response.status_code}")
            print(response.text)

if __name__ == "__main__":
    test_tumor_workflow()


====================
FILE: .\omicstoken_repo\scripts\prepare_ibd_dataset.py
====================


====================
FILE: .\omicstoken_repo\static\search.html
====================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Peptide Search Explorer</title>
    <style>
        body { font-family: sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        .form-group { margin-bottom: 15px; }
        label { display: block; margin-bottom: 5px; font-weight: bold; }
        input { width: 100%; padding: 8px; box-sizing: border-box; }
        button { padding: 10px 20px; background-color: #007bff; color: white; border: none; cursor: pointer; }
        button:hover { background-color: #0056b3; }
        #results { margin-top: 20px; }
        table { width: 100%; border-collapse: collapse; margin-top: 10px; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        .error { color: red; }
    </style>
</head>
<body>
    <h1>Peptide Search Explorer</h1>
    
    <div class="form-group">
        <label for="runId">Run ID:</label>
        <input type="text" id="runId" placeholder="e.g., TUMOR_RUN_001">
    </div>
    
    <div class="form-group">
        <label for="featureId">Feature ID (Peptide ID):</label>
        <input type="text" id="featureId" placeholder="e.g., TUMOR_0_P12345">
    </div>
    
    <button onclick="search()">Search Similar Peptides</button>
    
    <div id="results"></div>

    <script>
        async function search() {
            const runId = document.getElementById('runId').value;
            const featureId = document.getElementById('featureId').value;
            const resultsDiv = document.getElementById('results');
            
            if (!runId || !featureId) {
                resultsDiv.innerHTML = '<p class="error">Please enter both Run ID and Feature ID.</p>';
                return;
            }
            
            resultsDiv.innerHTML = '<p>Searching...</p>';
            
            try {
                const response = await fetch(`/peptide/search/${runId}/${featureId}`);
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.detail || 'Search failed');
                }
                
                const data = await response.json();
                displayResults(data);
            } catch (e) {
                resultsDiv.innerHTML = `<p class="error">Error: ${e.message}</p>`;
            }
        }
        
        function displayResults(data) {
            const resultsDiv = document.getElementById('results');
            let html = `<h3>Results for ${data.query_feature_id}</h3>`;
            
            if (data.nearest_neighbors.length === 0) {
                html += '<p>No similar peptides found.</p>';
            } else {
                html += `
                    <table>
                        <thead>
                            <tr>
                                <th>Feature ID</th>
                                <th>Sequence</th>
                                <th>Distance</th>
                            </tr>
                        </thead>
                        <tbody>
                `;
                
                data.nearest_neighbors.forEach(item => {
                    html += `
                        <tr>
                            <td>${item.feature_id}</td>
                            <td>${item.peptide_sequence || 'N/A'}</td>
                            <td>${item.distance.toFixed(4)}</td>
                        </tr>
                    `;
                });
                
                html += '</tbody></table>';
            }
            
            resultsDiv.innerHTML = html;
        }
    </script>
</body>
</html>


====================
FILE: .\scripts\prepare_ibd_dataset.py
====================


====================
FILE: .\static\compare.html
====================
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Compare Runs - Immuno-Engine</title>
    <style>
        body {
            font-family: system-ui, sans-serif;
            margin: 2rem;
            background: #f8f9fa;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        .card {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin-bottom: 1.5rem;
        }

        h1 {
            margin-bottom: 0.5rem;
        }

        .back-link {
            display: inline-block;
            margin-bottom: 1rem;
            color: #0066cc;
            text-decoration: none;
        }

        .back-link:hover {
            text-decoration: underline;
        }

        .compare-form {
            display: grid;
            grid-template-columns: 1fr 1fr auto;
            gap: 1rem;
            align-items: flex-end;
        }

        .form-group label {
            display: block;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }

        select {
            width: 100%;
            padding: 0.6rem;
            border: 1px solid #ddd;
            border-radius: 4px;
        }

        .btn {
            padding: 0.6rem 1.5rem;
            background: #0066cc;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }

        .btn:hover {
            background: #0052a3;
        }

        .btn:disabled {
            background: #ccc;
            cursor: not-allowed;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin-top: 1rem;
        }

        .stat-item {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 4px;
            text-align: center;
        }

        .stat-label {
            color: #666;
            font-size: 0.9rem;
        }

        .stat-value {
            font-size: 1.8rem;
            font-weight: 600;
            color: #0066cc;
            margin-top: 0.5rem;
        }

        .peptide-grid {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 1.5rem;
            margin-top: 1rem;
        }

        .peptide-section {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 4px;
        }

        .peptide-section h3 {
            margin-top: 0;
            color: #333;
            font-size: 1.1rem;
        }

        .peptide-list {
            max-height: 400px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 0.9rem;
        }

        .peptide-item {
            padding: 0.5rem;
            margin-bottom: 0.3rem;
            background: white;
            border-radius: 3px;
            cursor: pointer;
            transition: background 0.2s;
        }

        .peptide-item:hover {
            background: #e8f4ff;
        }

        .shared {
            border-left: 4px solid #28a745;
        }

        .unique1 {
            border-left: 4px solid #007bff;
        }

        .unique2 {
            border-left: 4px solid #ffc107;
        }

        .empty-state {
            text-align: center;
            padding: 2rem;
            color: #999;
            font-family: system-ui, sans-serif;
        }

        .truncation-note {
            font-size: 0.85rem;
            color: #666;
            margin-top: 0.5rem;
            font-family: system-ui, sans-serif;
        }

        .error-message {
            background: #f8d7da;
            color: #721c24;
            padding: 1rem;
            border-radius: 4px;
            border-left: 4px solid #dc3545;
        }

        .warning-message {
            background: #fff3cd;
            color: #856404;
            padding: 1rem;
            border-radius: 4px;
            border-left: 4px solid #ffc107;
            margin-bottom: 1rem;
        }

        .loading-spinner {
            display: inline-block;
            width: 16px;
            height: 16px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #0066cc;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-left: 0.5rem;
        }

        @keyframes spin {
            0% {
                transform: rotate(0deg);
            }

            100% {
                transform: rotate(360deg);
            }
        }

        .run-label {
            font-family: monospace;
            font-weight: 600;
            color: #0066cc;
        }
    </style>
</head>

<body>
    <div class="container">
        <a href="/static/runs.html" class="back-link">â† Back to Runs</a>

        <div class="card">
            <h1>Compare Runs</h1>
            <p>Select two runs to compare their peptide composition</p>

            <div class="compare-form">
                <div class="form-group">
                    <label for="run1Select">Run 1</label>
                    <select id="run1Select" disabled>
                        <option>Loading runs...</option>
                    </select>
                </div>
                <div class="form-group">
                    <label for="run2Select">Run 2</label>
                    <select id="run2Select" disabled>
                        <option>Loading runs...</option>
                    </select>
                </div>
                <button id="compareBtn" class="btn" onclick="compareRuns()" disabled>
                    Compare
                </button>
            </div>

            <div id="errorContainer" style="margin-top:1rem;"></div>
        </div>

        <div id="results" style="display:none;">
            <div id="warningContainer"></div>

            <div class="card">
                <h2>Comparison Statistics</h2>
                <div class="stats-grid">
                    <div class="stat-item">
                        <div class="stat-label">Run 1 Peptides</div>
                        <div class="stat-value" id="run1Total">-</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-label">Run 2 Peptides</div>
                        <div class="stat-value" id="run2Total">-</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-label">Shared Peptides</div>
                        <div class="stat-value" id="sharedCount" style="color:#28a745;">-</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-label">Jaccard Index</div>
                        <div class="stat-value" id="jaccardIndex">-</div>
                    </div>
                </div>
            </div>

            <div class="card">
                <h2>Peptide Sets</h2>
                <div class="peptide-grid">
                    <div class="peptide-section">
                        <h3 id="unique1Header">ðŸ”µ Unique to Run 1 (<span id="unique1Count">0</span>)</h3>
                        <div class="peptide-list" id="unique1List"></div>
                        <div class="truncation-note" id="unique1Note" style="display:none;">
                            Showing first 100 peptides
                        </div>
                    </div>
                    <div class="peptide-section">
                        <h3 id="sharedHeader">ðŸŸ¢ Shared (<span id="sharedCount2">0</span>)</h3>
                        <div class="peptide-list" id="sharedList"></div>
                        <div class="truncation-note" id="sharedNote" style="display:none;">
                            Showing first 100 peptides
                        </div>
                    </div>
                    <div class="peptide-section">
                        <h3 id="unique2Header">ðŸŸ¡ Unique to Run 2 (<span id="unique2Count">0</span>)</h3>
                        <div class="peptide-list" id="unique2List"></div>
                        <div class="truncation-note" id="unique2Note" style="display:none;">
                            Showing first 100 peptides
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        const token = localStorage.getItem('token');
        if (!token) {
            window.location.href = '/static/login.html';
        }

        let runs = [];
        let currentRun1Id = null;
        let currentRun2Id = null;

        loadRuns();

        async function loadRuns() {
            try {
                const res = await fetch('/runs', {
                    headers: { 'Authorization': 'Bearer ' + token }
                });

                if (!res.ok) {
                    if (res.status === 401) {
                        window.location.href = '/static/login.html';
                        return;
                    }
                    throw new Error(`API Error: ${res.status}`);
                }

                runs = await res.json();
                populateSelects();
            } catch (e) {
                showError(`Error loading runs: ${e.message}`);
            }
        }

        function populateSelects() {
            const run1Select = document.getElementById('run1Select');
            const run2Select = document.getElementById('run2Select');
            const compareBtn = document.getElementById('compareBtn');

            if (runs.length < 2) {
                run1Select.innerHTML = '<option>Need at least 2 runs to compare</option>';
                run2Select.innerHTML = '<option>Need at least 2 runs to compare</option>';
                return;
            }

            const options = runs.map(r =>
                `<option value="${r.run_id}">${r.run_id} (${r.n_features} features)</option>`
            ).join('');

            run1Select.innerHTML = options;
            run2Select.innerHTML = options;

            // Pre-select different runs
            if (runs.length >= 2) {
                run2Select.selectedIndex = 1;
            }

            run1Select.disabled = false;
            run2Select.disabled = false;
            compareBtn.disabled = false;
        }

        function showError(message) {
            const container = document.getElementById('errorContainer');
            container.innerHTML = `<div class="error-message">${message}</div>`;
        }

        function clearError() {
            document.getElementById('errorContainer').innerHTML = '';
        }

        function showWarning(message) {
            const container = document.getElementById('warningContainer');
            container.innerHTML = `<div class="warning-message">${message}</div>`;
        }

        function clearWarning() {
            document.getElementById('warningContainer').innerHTML = '';
        }

        function getRunLabel(runId) {
            const run = runs.find(r => r.run_id === runId);
            if (!run) return runId;

            // Return a short, readable label
            return runId;
        }

        async function compareRuns() {
            const run1 = document.getElementById('run1Select').value;
            const run2 = document.getElementById('run2Select').value;

            currentRun1Id = run1;
            currentRun2Id = run2;

            clearError();
            clearWarning();

            if (!run1 || !run2) return;

            // Edge case: Same run selected
            if (run1 === run2) {
                showError('Please select two different runs to compare.');
                return;
            }

            const compareBtn = document.getElementById('compareBtn');
            compareBtn.innerHTML = 'Comparing<span class="loading-spinner"></span>';
            compareBtn.disabled = true;

            try {
                const res = await fetch(`/compare/${run1}/${run2}`, {
                    headers: { 'Authorization': 'Bearer ' + token }
                });

                if (!res.ok) {
                    if (res.status === 404) {
                        throw new Error('One or both runs not found. They may be empty or unavailable.');
                    } else if (res.status === 401) {
                        window.location.href = '/static/login.html';
                        return;
                    } else {
                        throw new Error(`Server error (${res.status}). Please try again.`);
                    }
                }

                const data = await res.json();
                displayResults(data);
            } catch (e) {
                showError(`Could not compare these runs. ${e.message}`);
            } finally {
                compareBtn.innerHTML = 'Compare';
                compareBtn.disabled = false;
            }
        }

        function displayResults(data) {
            document.getElementById('results').style.display = 'block';

            // Update headers with run labels
            const run1Label = getRunLabel(currentRun1Id);
            const run2Label = getRunLabel(currentRun2Id);

            document.getElementById('unique1Header').innerHTML =
                `ðŸ”µ Unique to <span class="run-label">${run1Label}</span> (<span id="unique1Count">${data.stats.unique_run_1_count}</span>)`;
            document.getElementById('sharedHeader').innerHTML =
                `ðŸŸ¢ Shared (<span id="sharedCount2">${data.stats.shared_count}</span>)`;
            document.getElementById('unique2Header').innerHTML =
                `ðŸŸ¡ Unique to <span class="run-label">${run2Label}</span> (<span id="unique2Count">${data.stats.unique_run_2_count}</span>)`;

            // Check for edge case: Jaccard = 1 (same run or identical peptides)
            if (data.stats.jaccard_index === 1.0) {
                showWarning('âš ï¸ These runs appear to be identical (Jaccard index = 1.0)');
            }

            // Check for edge case: No shared peptides
            if (data.stats.shared_count === 0) {
                showWarning('âš ï¸ These runs have no shared peptides (Jaccard index = 0.0)');
            }

            // Stats
            document.getElementById('run1Total').textContent = data.stats.total_run_1;
            document.getElementById('run2Total').textContent = data.stats.total_run_2;
            document.getElementById('sharedCount').textContent = data.stats.shared_count;

            // Handle Jaccard index (protect against NaN or null)
            const jaccardValue = data.stats.jaccard_index;
            document.getElementById('jaccardIndex').textContent =
                (jaccardValue !== null && !isNaN(jaccardValue)) ? jaccardValue.toFixed(3) : '0.000';

            // Peptide lists with click handlers
            displayPeptideList('unique1List', data.unique_run_1, 'unique1', 'No unique peptides', currentRun1Id);
            displayPeptideList('sharedList', data.shared_peptides, 'shared', 'No shared peptides', currentRun1Id);
            displayPeptideList('unique2List', data.unique_run_2, 'unique2', 'No unique peptides', currentRun2Id);

            // Show truncation notes if lists are at max length (100)
            document.getElementById('unique1Note').style.display =
                data.unique_run_1.length >= 100 ? 'block' : 'none';
            document.getElementById('sharedNote').style.display =
                data.shared_peptides.length >= 100 ? 'block' : 'none';
            document.getElementById('unique2Note').style.display =
                data.unique_run_2.length >= 100 ? 'block' : 'none';
        }

        function displayPeptideList(elementId, peptides, className, emptyMessage, runId) {
            const container = document.getElementById(elementId);

            if (!peptides || peptides.length === 0) {
                container.innerHTML = `<div class="empty-state">${emptyMessage}</div>`;
                return;
            }

            container.innerHTML = peptides
                .map(p => `<div class="peptide-item ${className}" onclick="searchPeptide('${runId}', '${p}')" title="Click to search for similar peptides">${p}</div>`)
                .join('');
        }

        function searchPeptide(runId, peptideSeq) {
            // Navigate to search page with this peptide pre-selected
            // The search page would need to support a peptide query parameter
            window.location.href = `/static/search.html?run_id=${runId}&peptide=${encodeURIComponent(peptideSeq)}`;
        }
    </script>
</body>

</html>

====================
FILE: .\static\dashboard.html
====================
<!DOCTYPE html>
<html lang="en" class="dark">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Proteomics Scientific Workbench</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=JetBrains+Mono:wght@400;700&display=swap"
        rel="stylesheet">
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                        mono: ['JetBrains Mono', 'monospace'],
                    },
                    colors: {
                        slate: {
                            850: '#151f32',
                            900: '#0f172a',
                            950: '#020617',
                        }
                    }
                }
            }
        }
    </script>
    <style>
        /* Custom Scrollbar for scientific feel */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: #0f172a;
        }

        ::-webkit-scrollbar-thumb {
            background: #334155;
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: #475569;
        }
    </style>
</head>

<body class="bg-slate-950 text-slate-200 h-screen flex overflow-hidden font-sans">

    <!-- Sidebar: Peptide List -->
    <aside class="w-80 bg-slate-900 border-r border-slate-800 flex flex-col">
        <div class="p-4 border-b border-slate-800">
            <h1 class="text-lg font-semibold text-emerald-400 tracking-tight">ANTIGRAVITY<span
                    class="text-slate-500 text-xs ml-2">WORKBENCH</span></h1>
            <div class="mt-4">
                <input type="text" id="runIdInput" placeholder="Run ID (e.g. TUMOR_RUN_001)"
                    class="w-full bg-slate-950 border border-slate-700 rounded px-3 py-1.5 text-sm focus:outline-none focus:border-emerald-500 transition-colors font-mono">
                <button onclick="loadRealData()"
                    class="mt-2 w-full bg-emerald-600 hover:bg-emerald-500 text-white text-xs font-bold py-1.5 rounded transition-colors">
                    LOAD RUN
                </button>
                <button onclick="simulateDataLoad()"
                    class="mt-2 w-full bg-slate-800 hover:bg-slate-700 text-slate-400 text-xs font-bold py-1.5 rounded transition-colors">
                    SIMULATE DATA
                </button>
            </div>
        </div>

        <div class="flex-1 overflow-y-auto p-2" id="peptideList">
            <!-- Peptide items injected here -->
            <div class="text-center text-slate-600 text-sm mt-10 italic">Load data to view peptides</div>
        </div>

        <div class="p-3 border-t border-slate-800 text-xs text-slate-500 flex justify-between">
            <span>Items: <span id="itemCount">0</span></span>
            <span>v0.4.0-beta</span>
        </div>
    </aside>

    <!-- Main Content -->
    <main class="flex-1 flex flex-col h-full">

        <!-- Top Pane: Visualization (60%) -->
        <div class="h-[60%] border-b border-slate-800 relative p-4">
            <div
                class="absolute top-4 left-4 z-10 bg-slate-900/80 backdrop-blur px-3 py-1 rounded border border-slate-700 text-xs font-mono text-emerald-400">
                FIGURE 1: HYDROPHOBICITY vs. MW
            </div>
            <div id="scatterPlot" class="w-full h-full"></div>
        </div>

        <!-- Bottom Pane: Detail View (40%) -->
        <div class="h-[40%] bg-slate-900 p-6 overflow-y-auto">
            <div id="detailView" class="hidden h-full flex flex-col">
                <div class="flex justify-between items-start mb-4">
                    <div>
                        <h2 class="text-2xl font-mono font-bold text-white mb-1" id="detailSeq">PEPTIDE_SEQUENCE</h2>
                        <div class="flex gap-2 text-xs">
                            <span class="bg-slate-800 px-2 py-0.5 rounded text-slate-400 border border-slate-700">ID:
                                <span id="detailId" class="text-slate-200">---</span></span>
                            <span
                                class="bg-slate-800 px-2 py-0.5 rounded text-slate-400 border border-slate-700">Charge:
                                <span id="detailCharge" class="text-emerald-400 font-bold">---</span></span>
                        </div>
                    </div>
                    <div class="text-right">
                        <div class="text-sm text-slate-400">Intensity</div>
                        <div class="text-xl font-mono text-emerald-400" id="detailIntensity">---</div>
                    </div>
                </div>

                <div class="grid grid-cols-3 gap-4 mt-2">
                    <div class="bg-slate-950 p-4 rounded border border-slate-800">
                        <div class="text-xs text-slate-500 uppercase tracking-wider mb-1">Hydrophobicity</div>
                        <div class="text-2xl font-mono text-white" id="detailHydro">---</div>
                        <div class="w-full bg-slate-900 h-1 mt-2 rounded-full overflow-hidden">
                            <div id="barHydro" class="bg-blue-500 h-full" style="width: 0%"></div>
                        </div>
                    </div>
                    <div class="bg-slate-950 p-4 rounded border border-slate-800">
                        <div class="text-xs text-slate-500 uppercase tracking-wider mb-1">Molecular Weight</div>
                        <div class="text-2xl font-mono text-white" id="detailMW">---</div>
                        <div class="text-xs text-slate-600 mt-1">Daltons</div>
                    </div>
                    <div class="bg-slate-950 p-4 rounded border border-slate-800">
                        <div class="text-xs text-slate-500 uppercase tracking-wider mb-1">Length</div>
                        <div class="text-2xl font-mono text-white" id="detailLen">---</div>
                        <div class="text-xs text-slate-600 mt-1">Amino Acids</div>
                    </div>
                </div>

                <div class="mt-6 pt-4 border-t border-slate-800">
                    <h3 class="text-sm font-semibold text-slate-400 mb-2">Analysis Tools</h3>
                    <div class="flex gap-3">
                        <button
                            class="px-3 py-1.5 bg-slate-800 hover:bg-slate-700 border border-slate-700 rounded text-xs text-slate-300 transition-colors">
                            Find Similar (BLAST-like)
                        </button>
                        <button
                            class="px-3 py-1.5 bg-slate-800 hover:bg-slate-700 border border-slate-700 rounded text-xs text-slate-300 transition-colors">
                            Predict Binding
                        </button>
                        <button
                            class="px-3 py-1.5 bg-slate-800 hover:bg-slate-700 border border-slate-700 rounded text-xs text-slate-300 transition-colors">
                            Export FASTA
                        </button>
                    </div>
                </div>
            </div>

            <!-- Empty State -->
            <div id="emptyState" class="h-full flex items-center justify-center text-slate-600 flex-col">
                <svg class="w-12 h-12 mb-3 opacity-20" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                        d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z">
                    </path>
                </svg>
                <p>Select a data point to view biophysical details</p>
            </div>
        </div>
    </main>

    <script>
        // --- State ---
        let currentData = [];

        // --- Simulation ---
        function simulateDataLoad() {
            const peptides = [];
            const aas = 'ACDEFGHIKLMNPQRSTVWY';

            for (let i = 0; i < 200; i++) {
                // Generate random sequence
                const len = 7 + Math.floor(Math.random() * 15);
                let seq = '';
                for (let j = 0; j < len; j++) seq += aas[Math.floor(Math.random() * aas.length)];

                // Mock properties
                const hydro = (Math.random() * 6) - 3; // -3 to +3
                const mw = len * 110 + (Math.random() * 50);
                const intensity = Math.pow(10, 4 + Math.random() * 5); // 10^4 to 10^9

                peptides.push({
                    feature_id: `SIM_${i}`,
                    sequence: seq,
                    intensity: intensity,
                    properties: {
                        hydrophobicity: parseFloat(hydro.toFixed(2)),
                        molecular_weight: Math.floor(mw),
                        charge: Math.floor(Math.random() * 5) - 2,
                        length: len
                    }
                });
            }

            renderDashboard(peptides);
        }

        // --- Real Data Load ---
        async function loadRealData() {
            const runId = document.getElementById('runIdInput').value.trim();
            if (!runId) {
                alert("Please enter a Run ID");
                return;
            }

            try {
                const btn = document.querySelector('button[onclick="loadRealData()"]');
                const originalText = btn.innerText;
                btn.innerText = "LOADING...";
                btn.disabled = true;

                const res = await fetch(`/dashboard-data/${runId}`);
                if (!res.ok) throw new Error("Failed to fetch data");

                const json = await res.json();
                renderDashboard(json.data);

                btn.innerText = originalText;
                btn.disabled = false;
            } catch (e) {
                alert("Error loading data: " + e.message);
                document.querySelector('button[onclick="loadRealData()"]').innerText = "LOAD RUN";
                document.querySelector('button[onclick="loadRealData()"]').disabled = false;
            }
        }

        // --- Rendering ---
        function renderDashboard(data) {
            currentData = data;
            document.getElementById('itemCount').innerText = data.length;

            renderList(data);

            // Check if we have stats for Volcano Plot
            const hasStats = data.some(d => d.stats && d.stats.fold_change !== undefined);

            if (hasStats) {
                renderVolcano(data);
                // Update title
                document.querySelector('.absolute.top-4.left-4').innerText = "FIGURE 1: VOLCANO PLOT (Differential Expression)";
            } else {
                renderScatter(data);
                document.querySelector('.absolute.top-4.left-4').innerText = "FIGURE 1: HYDROPHOBICITY vs. MW";
            }
        }

        function renderList(data) {
            const list = document.getElementById('peptideList');
            list.innerHTML = '';

            data.forEach((p, idx) => {
                const div = document.createElement('div');
                div.className = "p-2 border-b border-slate-800 hover:bg-slate-800 cursor-pointer transition-colors group";
                div.onclick = () => selectPeptide(idx);

                // Color code significant items if stats exist
                let sigClass = "";
                if (p.stats && p.stats.q_value < 0.05 && Math.abs(p.stats.fold_change) > 1) {
                    sigClass = "border-l-2 border-emerald-500 pl-1.5";
                }

                div.innerHTML = `
                    <div class="${sigClass}">
                        <div class="flex justify-between items-baseline">
                            <span class="font-mono text-xs text-emerald-400 font-bold truncate w-32">${p.sequence}</span>
                            <span class="text-[10px] text-slate-500">${p.intensity.toExponential(1)}</span>
                        </div>
                        <div class="flex justify-between mt-1 text-[10px] text-slate-600 group-hover:text-slate-400">
                            <span>MW: ${p.properties.molecular_weight}</span>
                            <span>Hyd: ${p.properties.hydrophobicity}</span>
                        </div>
                    </div>
                `;
                list.appendChild(div);
            });
        }

        function renderScatter(data) {
            const trace = {
                x: data.map(p => p.properties.molecular_weight),
                y: data.map(p => p.properties.hydrophobicity),
                mode: 'markers',
                type: 'scatter',
                text: data.map(p => p.sequence),
                marker: {
                    size: 8,
                    color: data.map(p => Math.log10(p.intensity)),
                    colorscale: 'Viridis',
                    opacity: 0.8,
                    line: { color: '#0f172a', width: 1 }
                },
                hoverinfo: 'text'
            };

            const layout = {
                paper_bgcolor: 'rgba(0,0,0,0)',
                plot_bgcolor: 'rgba(0,0,0,0)',
                margin: { t: 20, r: 20, b: 40, l: 50 },
                xaxis: { title: 'Molecular Weight (Da)', color: '#94a3b8', gridcolor: '#1e293b' },
                yaxis: { title: 'Hydrophobicity (GRAVY)', color: '#94a3b8', gridcolor: '#1e293b' },
                hovermode: 'closest'
            };
            Plotly.newPlot('scatterPlot', [trace], layout, { responsive: true, displayModeBar: false });

            document.getElementById('scatterPlot').on('plotly_click', function (data) {
                selectPeptide(data.points[0].pointIndex);
            });
        }

        function renderVolcano(data) {
            // Filter out invalid data points
            const validData = data.filter(d => d.stats && d.stats.fold_change !== null && d.stats.q_value !== null);

            // Create colors based on significance
            const colors = validData.map(d => {
                if (d.stats.q_value < 0.05) {
                    return d.stats.fold_change > 0 ? '#ef4444' : '#3b82f6'; // Red for Up, Blue for Down
                }
                return '#475569'; // Grey for non-significant
            });

            const trace = {
                x: validData.map(d => d.stats.fold_change),
                y: validData.map(d => -Math.log10(d.stats.q_value)),
                mode: 'markers',
                type: 'scatter',
                text: validData.map(d => d.sequence),
                marker: {
                    size: 6,
                    color: colors,
                    opacity: 0.8,
                    line: { color: '#0f172a', width: 0.5 }
                },
                hoverinfo: 'text'
            };

            const layout = {
                paper_bgcolor: 'rgba(0,0,0,0)',
                plot_bgcolor: 'rgba(0,0,0,0)',
                margin: { t: 20, r: 20, b: 40, l: 50 },
                xaxis: { title: 'Log2 Fold Change', color: '#94a3b8', gridcolor: '#1e293b', zerolinecolor: '#cbd5e1' },
                yaxis: { title: '-Log10 q-value', color: '#94a3b8', gridcolor: '#1e293b' },
                hovermode: 'closest',
                shapes: [
                    // Significance thresholds
                    { type: 'line', x0: -10, x1: 10, y0: -Math.log10(0.05), y1: -Math.log10(0.05), line: { color: '#94a3b8', width: 1, dash: 'dash' } }
                ]
            };

            Plotly.newPlot('scatterPlot', [trace], layout, { responsive: true, displayModeBar: false });

            document.getElementById('scatterPlot').on('plotly_click', function (evtData) {
                // Map back to original data index
                const pt = evtData.points[0];
                // Since we filtered, we need to find the object in the original array
                const selectedObj = validData[pt.pointIndex];
                const originalIndex = currentData.indexOf(selectedObj);
                selectPeptide(originalIndex);
            });
        }

        function selectPeptide(index) {
            const p = currentData[index];
            if (!p) return;

            // Show Detail View
            document.getElementById('emptyState').classList.add('hidden');
            document.getElementById('detailView').classList.remove('hidden');

            // Populate Data
            document.getElementById('detailSeq').innerText = p.sequence;
            document.getElementById('detailId').innerText = p.feature_id;
            document.getElementById('detailCharge').innerText = p.properties.charge > 0 ? `+${p.properties.charge}` : p.properties.charge;
            document.getElementById('detailIntensity').innerText = p.intensity.toExponential(2);

            document.getElementById('detailHydro').innerText = p.properties.hydrophobicity;
            document.getElementById('detailMW').innerText = p.properties.molecular_weight;
            document.getElementById('detailLen').innerText = p.properties.length;

            // Visual bar for hydrophobicity (-4.5 to 4.5 scale approx)
            const hydroPct = ((p.properties.hydrophobicity + 4.5) / 9) * 100;
            const bar = document.getElementById('barHydro');
            bar.style.width = `${Math.max(0, Math.min(100, hydroPct))}%`;
            // Color shift
            if (p.properties.hydrophobicity > 0) {
                bar.className = "h-full bg-rose-500"; // Hydrophobic
            } else {
                bar.className = "h-full bg-blue-500"; // Hydrophilic
            }

            // Show Stats if available
            if (p.stats && p.stats.fold_change !== undefined) {
                const fcText = `FC: ${p.stats.fold_change.toFixed(2)}`;
                const qText = `q: ${p.stats.q_value?.toExponential(2)}`;
                document.getElementById('detailId').innerText = `${p.feature_id} | ${fcText} | ${qText}`;
            }
        }
    </script>
</body>

</html>

====================
FILE: .\static\fingerprint.html
====================
<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Fingerprint</title>
    <link rel="stylesheet" href="/static/style.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <style>
        .grid-2 {
            display: grid;
            grid-template-columns: 1fr 2fr;
            gap: 2rem;
            align-items: start;
        }
        .chart-container {
            position: relative;
            height: 60vh;
            width: 100%;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Semantic Fingerprint</h1>
            <h2 id="runIdHeader" class="text-muted" style="margin-top: -0.5rem;"></h2>
        </div>

        <p id="loading" class="text-center text-muted" style="padding: 2rem;">Loading fingerprint...</p>

        <div id="fingerprintContent" class="hidden">
            <div class="grid-2">
                <div>
                    <h3>Cluster Analysis</h3>
                    <p class="text-sm text-muted" id="totalPeptides"></p>
                    <table id="clusterTable" class="table" style="margin-top: 1rem;">
                        <thead>
                            <tr>
                                <th>Cluster ID</th>
                                <th>Size</th>
                                <th>Avg. Length</th>
                                <th>Avg. Hydrophobicity</th>
                                <th>Avg. Intensity</th>
                            </tr>
                        </thead>
                        <tbody>
                            <!-- Rows will be inserted here -->
                        </tbody>
                    </table>
                </div>
                <div style="min-width: 0;">
                    <h3>Embedding 2D Projection (PCA)</h3>
                    <div class="chart-container">
                        <canvas id="fingerprintChart"></canvas>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Chart.js color scheme for clusters
        const CLUSTER_COLORS = [
            'rgba(54, 162, 235, 0.7)',
            'rgba(255, 99, 132, 0.7)',
            'rgba(75, 192, 192, 0.7)',
            'rgba(255, 206, 86, 0.7)',
            'rgba(153, 102, 255, 0.7)',
            'rgba(255, 159, 64, 0.7)'
        ];

        window.addEventListener('DOMContentLoaded', async () => {
            const token = localStorage.getItem('token');
            const urlParams = new URLSearchParams(window.location.search);
            const runId = urlParams.get('run_id');

            const loadingEl = document.getElementById('loading');
            const contentEl = document.getElementById('fingerprintContent');
            const runIdHeader = document.getElementById('runIdHeader');

            if (!runId) {
                loadingEl.innerHTML = '<span style="color: red;">Error: No run_id specified in URL.</span>';
                return;
            }
            
            runIdHeader.textContent = `Run ID: ${runId}`;

            if (!token) {
                loadingEl.innerHTML = 'You are not logged in. <a href="/static/login.html">Please log in</a>.';
                return;
            }

            try {
                const headers = { 'Authorization': 'Bearer ' + token };
                const response = await fetch(`/runs/${runId}/fingerprint`, { headers });

                if (response.status === 401) {
                    loadingEl.innerHTML = 'Your session has expired. <a href="/static/login.html">Please log in again</a>.';
                    return;
                }
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || `Failed to load fingerprint (status: ${response.status})`);
                }

                const data = await response.json();
                
                loadingEl.classList.add('hidden');
                contentEl.classList.remove('hidden');

                // Populate total peptides count
                document.getElementById('totalPeptides').textContent = `${data.total_peptides} total peptides in run.`;

                // Populate cluster table
                const tableBody = document.getElementById('clusterTable').querySelector('tbody');
                data.clusters.forEach(cluster => {
                    const row = tableBody.insertRow();
                    row.innerHTML = `
                        <td><span class="color-dot" style="background-color: ${CLUSTER_COLORS[cluster.id % CLUSTER_COLORS.length]}"></span>${cluster.id}</td>
                        <td>${cluster.size}</td>
                        <td>${cluster.mean_length}</td>
                        <td>${cluster.mean_hydrophobicity}</td>
                        <td>${cluster.mean_intensity.toExponential(2)}</td>
                    `;
                });

                // Create scatter plot
                const ctx = document.getElementById('fingerprintChart').getContext('2d');
                new Chart(ctx, {
                    type: 'scatter',
                    data: {
                        datasets: data.clusters.map(cluster => ({
                            label: `Cluster ${cluster.id}`,
                            data: data.embedding_2d.filter(p => p.cluster_id === cluster.id).map(p => ({ x: p.x, y: p.y })),
                            backgroundColor: CLUSTER_COLORS[cluster.id % CLUSTER_COLORS.length],
                        }))
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        scales: {
                            x: {
                                title: { display: true, text: 'PCA Component 1' }
                            },
                            y: {
                                title: { display: true, text: 'PCA Component 2' }
                            }
                        },
                        plugins: {
                            legend: {
                                position: 'top',
                            },
                            tooltip: {
                                callbacks: {
                                    label: function(context) {
                                        return `Cluster ${context.dataset.label}: (PCA1: ${context.parsed.x.toFixed(2)}, PCA2: ${context.parsed.y.toFixed(2)})`;
                                    }
                                }
                            }
                        }
                    }
                });

            } catch (e) {
                loadingEl.innerHTML = `<span style="color: red;">Error: ${e.message}</span>`;
            }
        });
    </script>
</body>
</html>

====================
FILE: .\static\login.html
====================
<!DOCTYPE html>
<html>

<head>
    <title>Immuno-Engine - Login</title>
    <link rel="stylesheet" href="/static/style.css">
    <style>
        body {
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .login-card {
            width: 100%;
            max-width: 400px;
        }

        .brand {
            text-align: center;
            margin-bottom: 2rem;
        }

        .brand h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
        }

        .brand p {
            color: var(--text-secondary);
        }
    </style>
</head>

<body>
    <div class="card login-card">
        <div class="brand">
            <h1>Immuno-Engine</h1>
            <p>Next-Gen Proteomics Intelligence</p>
        </div>

        <div id="error"
            style="display:none; color: var(--danger-color); background: rgba(239, 68, 68, 0.1); padding: 0.75rem; border-radius: 6px; margin-bottom: 1rem; text-align: center;">
            Login failed
        </div>

        <form id="loginForm">
            <div style="margin-bottom: 1rem;">
                <label for="username">Email</label>
                <input type="email" id="username" placeholder="name@example.com" required value="test@example.com">
            </div>
            <div style="margin-bottom: 1.5rem;">
                <label for="password">Password</label>
                <input type="password" id="password" placeholder="â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢" required value="password123">
            </div>
            <button type="submit" class="btn btn-primary" style="width: 100%;">Sign In</button>
        </form>

        <div style="margin-top: 1.5rem; text-align: center; font-size: 0.9rem;">
            <span class="text-muted">New here?</span>
            <a href="#" onclick="register()">Create Account</a>
        </div>
    </div>

    <script>
        const API_URL = "http://127.0.0.1:8080";

        async function register() {
            const email = document.getElementById('username').value;
            const password = document.getElementById('password').value;
            const btn = document.querySelector('a[onclick="register()"]');
            const originalText = btn.innerText;
            btn.innerText = "Creating...";

            try {
                const res = await fetch(`${API_URL}/auth/register`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ email, password, is_active: true, is_superuser: false, is_verified: false })
                });
                if (res.ok) {
                    // Auto login after register
                    document.getElementById('loginForm').dispatchEvent(new Event('submit'));
                } else {
                    const data = await res.json();
                    if (res.status === 400 && JSON.stringify(data).includes("REGISTER_USER_ALREADY_EXISTS")) {
                        alert("User already exists. Please log in.");
                    } else {
                        alert("Registration failed: " + JSON.stringify(data));
                    }
                }
            } catch (e) {
                alert("Error: " + e);
            } finally {
                btn.innerText = originalText;
            }
        }

        document.getElementById('loginForm').addEventListener('submit', async (e) => {
            e.preventDefault();
            const username = document.getElementById('username').value;
            const password = document.getElementById('password').value;
            const btn = document.querySelector('button[type="submit"]');
            btn.innerText = "Authenticating...";
            btn.disabled = true;

            const formData = new URLSearchParams();
            formData.append('username', username);
            formData.append('password', password);

            try {
                const res = await fetch(`${API_URL}/auth/jwt/login`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                    body: formData
                });

                if (res.ok) {
                    const data = await res.json();
                    localStorage.setItem('token', data.access_token);
                    window.location.href = '/static/runs.html'; // Direct to runs page
                } else {
                    document.getElementById('error').style.display = 'block';
                    document.getElementById('error').innerText = "Invalid credentials";
                }
            } catch (e) {
                console.error(e);
                document.getElementById('error').style.display = 'block';
                document.getElementById('error').innerText = e.message;
            } finally {
                btn.innerText = "Sign In";
                btn.disabled = false;
            }
        });
    </script>
</body>

</html>

====================
FILE: .\static\runs.html
====================
<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Runs</title>
    <link rel="stylesheet" href="/static/style.css">
</head>
<body>
    <div class="container">
        <div class="header flex-between">
            <h1>My Runs</h1>
            <div>
                <a href="/static/upload.html" class="btn btn-primary">Upload New Data</a>
                <a href="/static/compare.html" class="btn btn-secondary">Compare Runs</a>
            </div>
        </div>

        <div id="runsList" class="grid" style="--grid-cols: 1; gap: 1rem;">
            <!-- Run cards will be inserted here -->
        </div>
        <p id="loading" class="text-center text-muted" style="padding: 2rem;">Loading runs...</p>
    </div>

    <script>
        window.addEventListener('DOMContentLoaded', async () => {
            const token = localStorage.getItem('token');
            const runsList = document.getElementById('runsList');
            const loadingEl = document.getElementById('loading');

            if (!token) {
                loadingEl.innerHTML = 'You are not logged in. <a href="/static/login.html">Please log in</a>.';
                return;
            }

            try {
                const headers = { 'Authorization': 'Bearer ' + token };
                const response = await fetch('/runs', { headers });

                if (response.status === 401) {
                    loadingEl.innerHTML = 'Your session has expired. <a href="/static/login.html">Please log in again</a>.';
                    return;
                }
                if (!response.ok) {
                    throw new Error(`Failed to load runs (status: ${response.status})`);
                }

                const runs = await response.json();

                if (runs.length === 0) {
                    loadingEl.textContent = 'No runs found. Try uploading some data!';
                } else {
                    loadingEl.remove();
                    runs.forEach(run => {
                        const card = document.createElement('div');
                        card.id = `run-card-${run.run_id}`; // Add an ID for easy removal
                        card.className = 'card';
                        card.innerHTML = `
                            <div class="flex-between">
                                <div>
                                    <h3 style="margin-bottom: 0.25rem;">${run.run_id}</h3>
                                    <p class="text-sm text-muted">${run.original_filename || 'No filename'}</p>
                                </div>
                                <div class="flex" style="gap: 0.5rem; align-items: center;">
                                    <div style="position: relative; display: flex; align-items: center;">
                                        <a href="/static/search.html?run_id=${run.run_id}" class="btn btn-secondary">Search</a>
                                        ${run.n_embeddings < run.n_features ?
                                            `<span class="tooltip" style="margin-left: 0.5rem; cursor: help;" title="Warning: Not all features have embeddings. Some searches may fail. (${run.n_embeddings}/${run.n_features})">âš ï¸</span>` : ''}
                                    </div>
                                    <a href="/static/simple_dashboard.html?run_id=${run.run_id}" class="btn btn-secondary">Dashboard</a>
                                    <a href="/static/summary.html?run_id=${run.run_id}" class="btn btn-secondary">Summary</a>
                                    ${run.n_embeddings < run.n_features ?
                                        `<button onclick="reEmbedRun('${run.run_id}')" class="btn btn-warning">Re-embed</button>` : ''
                                    }
                                    <a href="/static/fingerprint.html?run_id=${run.run_id}" class="btn btn-secondary">Fingerprint</a>
                                    <button onclick="deleteRun('${run.run_id}')" class="btn btn-danger">Delete</button>
                                </div>
                            </div>
                            <div class="flex text-sm text-muted" style="gap: 1.5rem; margin-top: 1rem; border-top: 1px solid var(--border-color); padding-top: 1rem;">
                                <span><strong>${run.n_features}</strong> features</span>
                                <span><strong>${run.n_embeddings}</strong> embeddings</span>
                                <span>Instrument: <strong>${run.instrument || 'N/A'}</strong></span>
                            </div>
                        `;
                        runsList.appendChild(card);
                    });
                }
            } catch (e) {
                loadingEl.innerHTML = `<span style="color: red;">Error: ${e.message}</span>`;
            }
        });

        async function reEmbedRun(runId) {
            const card = document.getElementById(`run-card-${runId}`);
            const button = card.querySelector('.btn-warning');
            const originalText = button.innerText;

            if (!confirm(`Are you sure you want to re-process embeddings for run "${runId}"?\nThis will generate any missing embeddings.`)) {
                return;
            }

            button.disabled = true;
            button.innerText = 'Embedding...';

            const token = localStorage.getItem('token');
            try {
                const response = await fetch(`/peptide/embed/${runId}`, {
                    method: 'POST',
                    headers: { 'Authorization': 'Bearer ' + token }
                });

                if (response.ok) {
                    alert(`Successfully started embedding for run "${runId}". The page will now reload to reflect the changes.`);
                    window.location.reload();
                } else {
                    const errorData = await response.json();
                    alert(`Failed to start embedding: ${errorData.detail || 'Unknown error'}`);
                    button.disabled = false;
                    button.innerText = originalText;
                }
            } catch (e) {
                alert(`An error occurred: ${e.message}`);
            }
        }

        async function deleteRun(runId) {
            if (!confirm(`Are you sure you want to delete run "${runId}"?\nThis action cannot be undone.`)) {
                return;
            }

            const token = localStorage.getItem('token');
            try {
                const response = await fetch(`/runs/${runId}`, {
                    method: 'DELETE',
                    headers: { 'Authorization': 'Bearer ' + token }
                });

                if (response.ok) {
                    // On success, remove the card from the UI
                    document.getElementById(`run-card-${runId}`).remove();
                } else {
                    const errorData = await response.json();
                    alert(`Failed to delete run: ${errorData.detail || 'Unknown error'}`);
                }
            } catch (e) {
                alert(`An error occurred: ${e.message}`);
            }
        }
    </script>
</body>
</html>

====================
FILE: .\static\search.html
====================
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Peptide Similarity Search | Immuno-Engine</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      margin: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: #020617;
      color: #e5e7eb;
    }
    header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 12px 20px;
      border-bottom: 1px solid #111827;
      background: #020617;
    }
    header h1 {
      font-size: 18px;
      margin: 0;
    }
    header .sub {
      font-size: 11px;
      opacity: 0.7;
    }
    header nav a {
      color: #9ca3af;
      text-decoration: none;
      font-size: 12px;
      margin-left: 12px;
    }
    header nav a:hover {
      color: #e5e7eb;
    }
    main {
      padding: 16px 20px 28px;
      display: grid;
      grid-template-columns: minmax(0, 1.25fr) minmax(0, 1.5fr);
      gap: 16px;
    }
    @media (max-width: 900px) {
      main {
        grid-template-columns: 1fr;
      }
    }
    .card {
      background: #020617;
      border-radius: 10px;
      border: 1px solid #1f2937;
      padding: 14px 16px 16px;
      box-shadow: 0 12px 30px rgba(0,0,0,0.5);
    }
    .card h2 {
      font-size: 16px;
      margin: 0 0 8px;
    }
    .card h3 {
      font-size: 14px;
      margin: 16px 0 6px;
    }
    .status {
      font-size: 12px;
      min-height: 16px;
      margin-top: 4px;
    }
    .status span.ok { color: #4ade80; }
    .status span.err { color: #f97316; }
    .status span.info { color: #60a5fa; }

    .badge {
      display: inline-flex;
      align-items: center;
      gap: 4px;
      padding: 2px 8px;
      font-size: 11px;
      border-radius: 999px;
      border: 1px solid #374151;
      background: #020617;
      margin-right: 6px;
    }
    .badge strong {
      font-weight: 600;
    }

    .peptide-table,
    .neighbors-box {
      border-radius: 8px;
      border: 1px solid #1f2937;
      margin-top: 6px;
      max-height: 260px;
      overflow-y: auto;
      font-size: 12px;
    }
    table {
      width: 100%;
      border-collapse: collapse;
    }
    th,
    td {
      padding: 4px 6px;
      border-bottom: 1px solid #111827;
      white-space: nowrap;
    }
    thead th {
      position: sticky;
      top: 0;
      background: #020617;
      z-index: 1;
      font-weight: 500;
    }
    tbody tr:hover {
      background: #0b1120;
      cursor: pointer;
    }

    .explanation {
      margin-top: 6px;
      border-radius: 8px;
      border: 1px solid #1f2937;
      padding: 8px 10px;
      font-size: 13px;
      line-height: 1.4;
      white-space: pre-wrap;
      background: #020617;
      max-height: 220px;
      overflow-y: auto;
    }

    .neighbors-item {
      display: flex;
      justify-content: space-between;
      gap: 8px;
      padding: 2px 6px;
      border-bottom: 1px dashed #111827;
    }
    .neighbors-item:last-child {
      border-bottom: none;
    }
    .neighbors-item span.seq {
      font-family: "JetBrains Mono", ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    }
    .neighbors-item span.small {
      font-size: 11px;
      opacity: 0.85;
    }

    code {
      font-family: "JetBrains Mono", ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 11px;
      background: #020617;
      padding: 1px 4px;
      border-radius: 4px;
    }
  </style>
</head>
<body>
  <header>
    <div>
      <h1>Peptide Similarity Search</h1>
      <div class="sub">
        Run-level nearest neighbors over FAISS embeddings
      </div>
    </div>
    <nav>
      <a href="/static/runs.html">My Runs</a>
      <a href="/static/upload.html">Upload</a>
      <a href="/docs" target="_blank">API Docs</a>
    </nav>
  </header>

  <main>
    <!-- LEFT: Peptide table -->
    <section class="card">
      <h2>1. Choose a peptide</h2>
      <div style="font-size:12px; margin-bottom:4px;">
        <span class="badge">
          <strong>Run:</strong> <span id="runLabel">â€“</span>
        </span>
        <span class="badge">
          <strong>Feature:</strong> <span id="featureLabel">none</span>
        </span>
      </div>
      <p style="margin:4px 0 6px; font-size:12px; opacity:0.8;">
        These are the top peptides from <code>/dashboard-data/{run_id}</code>. Click any row to search for neighbors.
      </p>
      <div class="peptide-table" id="peptideTable"></div>
      <div class="status" id="peptideStatus"></div>
    </section>

    <!-- RIGHT: Neighbors + explanation -->
    <section class="card">
      <h2>2. Neighbors & context</h2>
      <h3>Nearest neighbors in this run</h3>
      <div class="neighbors-box" id="neighborsBox">
        <div style="font-size:12px; opacity:0.7; padding:6px 8px;">
          Select a peptide on the left to find its nearest neighbors.
        </div>
      </div>

      <h3>Selected peptide explanation</h3>
      <div class="explanation" id="explanationBox">
        When you click a peptide, this will show the AI explanation from <code>/peptide/explain/{run_id}/{feature_id}</code>.
      </div>

      <div class="status" id="explainStatus"></div>
    </section>
  </main>

  <script>
    const API_URL = "http://127.0.0.1:8080";

    const runLabelEl = document.getElementById("runLabel");
    const featureLabelEl = document.getElementById("featureLabel");
    const peptideTableEl = document.getElementById("peptideTable");
    const peptideStatusEl = document.getElementById("peptideStatus");
    const neighborsBoxEl = document.getElementById("neighborsBox");
    const explanationBoxEl = document.getElementById("explanationBox");
    const explainStatusEl = document.getElementById("explainStatus");

    function setStatus(el, msg, type = "info") {
      if (!el) return;
      el.innerHTML = "";
      if (!msg) return;
      const span = document.createElement("span");
      span.className = type;
      span.textContent = msg;
      el.appendChild(span);
    }

    function getToken() {
      return window.localStorage.getItem("token") || "";
    }

    function authHeaders() {
      const token = getToken();
      const headers = {};
      if (token) headers["Authorization"] = "Bearer " + token;
      return headers;
    }

    function getRunIdFromQuery() {
      const params = new URLSearchParams(window.location.search);
      return params.get("run_id");
    }

    async function loadDashboardData(runId) {
      if (!runId) {
        setStatus(peptideStatusEl, "No run_id provided in query (?run_id=...).", "err");
        peptideTableEl.innerHTML = "";
        return;
      }

      const token = getToken();
      if (!token) {
        setStatus(peptideStatusEl, "You must log in first (via login.html).", "err");
        peptideTableEl.innerHTML = "";
        return;
      }

      setStatus(peptideStatusEl, "Loading peptidesâ€¦", "info");
      peptideTableEl.innerHTML = "";

      try {
        const res = await fetch(`${API_URL}/dashboard-data/${encodeURIComponent(runId)}`, {
          headers: {
            ...authHeaders(),
          },
        });
        const data = await res.json();
        if (!res.ok) {
          throw new Error(data.detail || JSON.stringify(data));
        }

        const items = data.data || [];
        if (!items.length) {
          peptideTableEl.innerHTML =
            "<div style='padding:6px 8px; font-size:12px; opacity:0.7;'>No peptides found for this run.</div>";
          setStatus(peptideStatusEl, "", "info");
          return;
        }

        const table = document.createElement("table");
        const thead = document.createElement("thead");
        thead.innerHTML =
          "<tr><th>Feature ID</th><th>Sequence</th><th>Intensity</th><th>Len</th><th>Charge</th><th>Hydro.</th></tr>";
        table.appendChild(thead);

        const tbody = document.createElement("tbody");

        items.forEach((row) => {
          const props = row.properties || {};
          const tr = document.createElement("tr");
          tr.innerHTML = `
            <td>${row.feature_id}</td>
            <td>${row.sequence}</td>
            <td>${row.intensity ?? ""}</td>
            <td>${props.length ?? ""}</td>
            <td>${props.charge ?? ""}</td>
            <td>${props.hydrophobicity ?? ""}</td>
          `;
          tr.addEventListener("click", () => {
            onSelectPeptide(runId, row.feature_id, row.sequence);
          });
          tbody.appendChild(tr);
        });

        table.appendChild(tbody);
        peptideTableEl.innerHTML = "";
        peptideTableEl.appendChild(table);
        setStatus(peptideStatusEl, "Click a row to search for neighbors.", "ok");
      } catch (err) {
        console.error(err);
        peptideTableEl.innerHTML = "";
        setStatus(peptideStatusEl, "Failed to load peptides: " + err.message, "err");
      }
    }

    async function onSelectPeptide(runId, featureId, sequence) {
      featureLabelEl.textContent = `${featureId} (${sequence})`;
      neighborsBoxEl.innerHTML =
        "<div style='font-size:12px; opacity:0.7; padding:6px 8px;'>Searching neighborsâ€¦</div>";
      explanationBoxEl.textContent = "Requesting explanationâ€¦";
      setStatus(explainStatusEl, "", "info");

      const token = getToken();
      if (!token) {
        setStatus(explainStatusEl, "You must log in first (via login.html).", "err");
        return;
      }

      try {
        // 1) Similarity search
        const searchRes = await fetch(
          `${API_URL}/peptide/search/${encodeURIComponent(runId)}/${encodeURIComponent(featureId)}?k=10`,
          {
            headers: {
              ...authHeaders(),
            },
          }
        );
        const searchData = await searchRes.json();
        if (!searchRes.ok) {
          throw new Error(searchData.detail || JSON.stringify(searchData));
        }

        const neighbors = searchData.neighbors || [];
        if (!neighbors.length) {
          neighborsBoxEl.innerHTML =
            "<div style='font-size:12px; opacity:0.7; padding:6px 8px;'>No neighbors found in this run.</div>";
        } else {
          const container = document.createElement("div");
          neighbors.forEach((n) => {
            const div = document.createElement("div");
            div.className = "neighbors-item";
            div.innerHTML = `
              <span class="seq">${n.peptide_sequence || ""}</span>
              <span class="small">sim=${(n.similarity ?? n.similarity_score ?? 0).toFixed(3)}</span>
              <span class="small">int=${n.intensity ?? ""}</span>
            `;
            container.appendChild(div);
          });
          neighborsBoxEl.innerHTML = "";
          neighborsBoxEl.appendChild(container);
        }

        // 2) Explanation
        try {
          const expRes = await fetch(
            `${API_URL}/peptide/explain/${encodeURIComponent(runId)}/${encodeURIComponent(featureId)}`,
            {
              headers: {
                ...authHeaders(),
              },
            }
          );
          const expData = await expRes.json();
          if (!expRes.ok) {
            throw new Error(expData.detail || JSON.stringify(expData));
          }
          explanationBoxEl.textContent =
            expData.explanation ||
            expData.summary_text ||
            JSON.stringify(expData, null, 2);
          setStatus(explainStatusEl, "", "info");
        } catch (expErr) {
          console.error(expErr);
          explanationBoxEl.textContent = "Failed to get explanation: " + expErr.message;
          setStatus(explainStatusEl, "Explanation failed.", "err");
        }
      } catch (err) {
        console.error(err);
        neighborsBoxEl.innerHTML =
          "<div style='font-size:12px; opacity:0.7; padding:6px 8px;'>No neighbors.</div>";
        explanationBoxEl.textContent = "Failed to search neighbors: " + err.message;
        setStatus(explainStatusEl, "Neighbor search failed.", "err");
      }
    }

    // --- Init ---
    (function init() {
      const runId = getRunIdFromQuery();
      runLabelEl.textContent = runId || "none";
      if (!runId) {
        setStatus(peptideStatusEl, "Add ?run_id=YOUR_RUN_ID to the URL.", "err");
        return;
      }
      loadDashboardData(runId);
    })();
  </script>
</body>
</html>

====================
FILE: .\static\search_backup.html
====================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Peptide Search Explorer</title>
    <style>
        body { font-family: sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        .form-group { margin-bottom: 15px; }
        label { display: block; margin-bottom: 5px; font-weight: bold; }
        input { width: 100%; padding: 8px; box-sizing: border-box; }
        button { padding: 10px 20px; background-color: #007bff; color: white; border: none; cursor: pointer; }
        button:hover { background-color: #0056b3; }
        #results { margin-top: 20px; }
        table { width: 100%; border-collapse: collapse; margin-top: 10px; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        .error { color: red; }
    </style>
</head>
<body>
    <h1>Peptide Search Explorer</h1>
    
    <div class="form-group">
        <label for="runId">Run ID:</label>
        <input type="text" id="runId" placeholder="e.g., TUMOR_RUN_001">
    </div>
    
    <div class="form-group">
        <label for="featureId">Feature ID (Peptide ID):</label>
        <input type="text" id="featureId" placeholder="e.g., TUMOR_0_P12345">
    </div>
    
    <button onclick="search()">Search Similar Peptides</button>
    
    <div id="results"></div>

    <script>
        async function search() {
            const runId = document.getElementById('runId').value;
            const featureId = document.getElementById('featureId').value;
            const resultsDiv = document.getElementById('results');
            
            if (!runId || !featureId) {
                resultsDiv.innerHTML = '<p class="error">Please enter both Run ID and Feature ID.</p>';
                return;
            }
            
            resultsDiv.innerHTML = '<p>Searching...</p>';
            
            try {
                const response = await fetch(`/peptide/search/${runId}/${featureId}`);
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.detail || 'Search failed');
                }
                
                const data = await response.json();
                displayResults(data);
            } catch (e) {
                resultsDiv.innerHTML = `<p class="error">Error: ${e.message}</p>`;
            }
        }
        
        function displayResults(data) {
            const resultsDiv = document.getElementById('results');
            let html = `<h3>Results for ${data.query_feature_id}</h3>`;
            
            if (data.nearest_neighbors.length === 0) {
                html += '<p>No similar peptides found.</p>';
            } else {
                html += `
                    <table>
                        <thead>
                            <tr>
                                <th>Feature ID</th>
                                <th>Sequence</th>
                                <th>Distance</th>
                            </tr>
                        </thead>
                        <tbody>
                `;
                
                data.nearest_neighbors.forEach(item => {
                    html += `
                        <tr>
                            <td>${item.feature_id}</td>
                            <td>${item.peptide_sequence || 'N/A'}</td>
                            <td>${item.distance.toFixed(4)}</td>
                        </tr>
                    `;
                });
                
                html += '</tbody></table>';
            }
            
            resultsDiv.innerHTML = html;
        }
    </script>
</body>
</html>


====================
FILE: .\static\simple_dashboard.html
====================
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Immuno-Engine Dashboard</title>
    <link rel="stylesheet" href="/static/style.css">
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
</head>

<body>
    <div class="container">
        <div class="header flex-between">
            <div>
                <h1>Run Dashboard</h1>
                <p id="runInfo" class="text-muted">Loading run data...</p>
            </div>
            <a href="/static/runs.html" class="btn btn-secondary">Back to Runs</a>
        </div>

        <div id="loading">Loading visualization data...</div>

        <div id="charts" style="display: none;">
            <div class="grid grid-2">
                <div class="card chart-container">
                    <!-- This div will contain the Plotly-generated SVG/canvas -->
                    <div id="scatterPlot"></div>
                </div>
                <div class="card chart-container">
                    <!-- This div will contain the Plotly-generated SVG/canvas -->
                    <div id="histPlot"></div>
                </div>
            </div>

            <div class="card">
                <h2>Top Peptides</h2>
                <div id="tableContainer"></div>
            </div>
        </div>
    </div>

    <script>
        const urlParams = new URLSearchParams(window.location.search);
        const runId = urlParams.get('run_id');
        const token = localStorage.getItem('token');

        if (!runId) {
            document.getElementById('runInfo').innerHTML = "Error: No run_id specified in URL.";
            document.getElementById('loading').style.display = 'none';
        } else if (!token) {
            window.location.href = '/static/login.html';
        } else {
            fetchData();
        }

        async function fetchData() {
            try {
                const res = await fetch(`/dashboard-data/${runId}`, {
                    headers: { 'Authorization': 'Bearer ' + token }
                });

                if (!res.ok) throw new Error(`API Error: ${res.status}`);

                const data = await res.json();
                renderDashboard(data);
            } catch (e) {
                document.getElementById('loading').innerHTML = `<span style="color:var(--danger-color)">Error loading data: ${e.message}</span>`;
            }
        }

        function renderDashboard(apiData) {
            document.getElementById('loading').style.display = 'none';
            document.getElementById('charts').style.display = 'block';
            document.getElementById('runInfo').innerHTML = `Run ID: <span style="color:var(--accent-color)">${apiData.run_id}</span> | Total Features: ${apiData.total_features}`;

            const features = apiData.data;

            // Plotly Dark Theme Config
            const plotConfig = {
                paper_bgcolor: 'rgba(0,0,0,0)',
                plot_bgcolor: 'rgba(0,0,0,0)',
                font: { color: '#94a3b8' },
                xaxis: { gridcolor: 'rgba(255,255,255,0.1)' },
                yaxis: { gridcolor: 'rgba(255,255,255,0.1)' }
            };

            // 1. Scatter Plot: Intensity vs Hydrophobicity
            const trace1 = {
                x: features.map(f => f.properties.hydrophobicity),
                y: features.map(f => f.intensity),
                mode: 'markers',
                type: 'scatter',
                text: features.map(f => f.sequence),
                marker: {
                    size: 8,
                    opacity: 0.7,
                    color: features.map(f => f.properties.length),
                    colorscale: 'Viridis',
                    showscale: true,
                    colorbar: { title: 'Length', titlefont: { color: '#94a3b8' }, tickfont: { color: '#94a3b8' } }
                }
            };

            const layout1 = {
                title: { text: 'Peptide Landscape', font: { color: '#f1f5f9', size: 18 } },
                xaxis: { title: 'Hydrophobicity (GRAVY)', ...plotConfig.xaxis },
                yaxis: { title: 'Intensity', type: 'log', ...plotConfig.yaxis },
                hovermode: 'closest',
                paper_bgcolor: plotConfig.paper_bgcolor,
                plot_bgcolor: plotConfig.plot_bgcolor,
                font: plotConfig.font,
                margin: { t: 40, r: 20, b: 40, l: 60 }
            };

            Plotly.newPlot('scatterPlot', [trace1], layout1, { responsive: true });

            // 2. Histogram: Length Distribution
            const trace2 = {
                x: features.map(f => f.properties.length),
                type: 'histogram',
                marker: { color: '#38bdf8', opacity: 0.8 }
            };

            const layout2 = {
                title: { text: 'Sequence Length Distribution', font: { color: '#f1f5f9', size: 18 } },
                xaxis: { title: 'Length (AA)', ...plotConfig.xaxis },
                yaxis: { title: 'Count', ...plotConfig.yaxis },
                paper_bgcolor: plotConfig.paper_bgcolor,
                plot_bgcolor: plotConfig.plot_bgcolor,
                font: plotConfig.font,
                margin: { t: 40, r: 20, b: 40, l: 60 }
            };

            Plotly.newPlot('histPlot', [trace2], layout2, { responsive: true });

            // 3. Simple Table
            const tableHtml = `
                <table>
                    <thead>
                        <tr>
                            <th>Sequence</th>
                            <th>Intensity</th>
                            <th>Length</th>
                            <th>Hydrophobicity</th>
                        </tr>
                    </thead>
                    <tbody>
                        ${features.slice(0, 10).map(f => `
                            <tr>
                                <td style="font-family:monospace; color: var(--accent-color);">${f.sequence}</td>
                                <td>${f.intensity.toExponential(2)}</td>
                                <td>${f.properties.length}</td>
                                <td>${f.properties.hydrophobicity}</td>
                            </tr>
                        `).join('')}
                    </tbody>
                </table>
                <p class="text-sm text-muted" style="margin-top:1rem;">Showing top 10 most intense peptides.</p>
            `;
            document.getElementById('tableContainer').innerHTML = tableHtml;
        }
    </script>
</body>

</html>

====================
FILE: .\static\style.css
====================
/* Modern Scientific Dark Theme */
:root {
    --bg-color: #0f172a;
    --card-bg: rgba(30, 41, 59, 0.7);
    --text-primary: #f1f5f9;
    --text-secondary: #94a3b8;
    --accent-color: #38bdf8;
    --accent-hover: #0ea5e9;
    --success-color: #22c55e;
    --danger-color: #ef4444;
    --border-color: rgba(148, 163, 184, 0.1);
    --glass-border: 1px solid rgba(255, 255, 255, 0.1);
    --shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
    --glow: 0 0 15px rgba(56, 189, 248, 0.3);
}

body {
    font-family: 'Inter', system-ui, -apple-system, sans-serif;
    background-color: var(--bg-color);
    background-image: 
        radial-gradient(at 0% 0%, rgba(56, 189, 248, 0.1) 0px, transparent 50%),
        radial-gradient(at 100% 0%, rgba(139, 92, 246, 0.1) 0px, transparent 50%);
    color: var(--text-primary);
    margin: 0;
    min-height: 100vh;
    line-height: 1.6;
}

/* Typography */
h1, h2, h3, h4, h5, h6 {
    color: var(--text-primary);
    font-weight: 700;
    letter-spacing: -0.025em;
    margin-top: 0;
}

h1 { font-size: 2.5rem; background: linear-gradient(to right, #38bdf8, #818cf8); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
h2 { font-size: 1.8rem; }

a { color: var(--accent-color); text-decoration: none; transition: all 0.2s; }
a:hover { color: var(--accent-hover); text-shadow: 0 0 8px rgba(56, 189, 248, 0.4); }

/* Layout */
.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 2rem;
}

/* Cards & Glassmorphism */
.card, .header, .runs-list, .form-container {
    background: var(--card-bg);
    backdrop-filter: blur(12px);
    -webkit-backdrop-filter: blur(12px);
    border: var(--glass-border);
    border-radius: 16px;
    padding: 2rem;
    box-shadow: var(--shadow);
    margin-bottom: 2rem;
}

/* Buttons */
.btn {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    padding: 0.75rem 1.5rem;
    border-radius: 8px;
    font-weight: 600;
    transition: all 0.2s;
    border: none;
    cursor: pointer;
    gap: 0.5rem;
}

.btn-primary {
    background: linear-gradient(135deg, #0ea5e9 0%, #3b82f6 100%);
    color: white;
    box-shadow: 0 4px 12px rgba(14, 165, 233, 0.3);
}

.btn-primary:hover {
    transform: translateY(-1px);
    box-shadow: 0 6px 16px rgba(14, 165, 233, 0.4);
}

.btn-secondary {
    background: rgba(255, 255, 255, 0.1);
    color: var(--text-primary);
    border: 1px solid rgba(255, 255, 255, 0.1);
}

.btn-secondary:hover {
    background: rgba(255, 255, 255, 0.15);
}

.btn-danger {
    background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
    color: white;
}

/* Forms */
input, select, textarea {
    width: 100%;
    padding: 0.75rem;
    background: rgba(15, 23, 42, 0.6);
    border: 1px solid rgba(148, 163, 184, 0.2);
    border-radius: 8px;
    color: white;
    font-family: inherit;
    transition: all 0.2s;
    box-sizing: border-box; /* Fix width issues */
}

input:focus, select:focus, textarea:focus {
    outline: none;
    border-color: var(--accent-color);
    box-shadow: 0 0 0 2px rgba(56, 189, 248, 0.2);
}

label {
    display: block;
    margin-bottom: 0.5rem;
    color: var(--text-secondary);
    font-weight: 500;
}

/* Tables */
table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 1rem;
}

th {
    text-align: left;
    padding: 1rem;
    color: var(--text-secondary);
    border-bottom: 1px solid rgba(255, 255, 255, 0.1);
    font-weight: 600;
}

td {
    padding: 1rem;
    border-bottom: 1px solid rgba(255, 255, 255, 0.05);
}

tr:hover td {
    background: rgba(255, 255, 255, 0.02);
}

/* Utilities */
.text-sm { font-size: 0.875rem; }
.text-muted { color: var(--text-secondary); }
.flex { display: flex; gap: 1rem; }
.flex-between { display: flex; justify-content: space-between; align-items: center; }
.grid { display: grid; gap: 1.5rem; }
.grid-2 { grid-template-columns: 1fr 1fr; }

/* Loading & Empty States */
#loading, .empty-state {
    text-align: center;
    padding: 3rem;
    color: var(--text-secondary);
}

/* Specific Components */
.run-item {
    border-bottom: 1px solid rgba(255, 255, 255, 0.1);
    padding: 1.5rem 0;
    transition: all 0.2s;
}

.run-item:last-child { border-bottom: none; }
.run-item:hover { background: rgba(255, 255, 255, 0.02); padding-left: 1rem; padding-right: 1rem; margin: 0 -1rem; border-radius: 8px; }

.run-title { font-size: 1.25rem; color: var(--text-primary); margin-bottom: 0.5rem; font-weight: 600; }
.run-meta { display: flex; gap: 1rem; flex-wrap: wrap; margin-bottom: 1rem; }
.meta-tag { background: rgba(56, 189, 248, 0.1); color: var(--accent-color); padding: 0.25rem 0.75rem; border-radius: 999px; font-size: 0.8rem; }

.run-actions { display: flex; gap: 0.75rem; flex-wrap: wrap; }
.action-link { 
    display: inline-flex; 
    align-items: center; 
    gap: 0.4rem;
    padding: 0.5rem 1rem; 
    background: rgba(255, 255, 255, 0.05); 
    border-radius: 6px; 
    color: var(--text-primary); 
    font-size: 0.9rem;
    border: 1px solid transparent;
}
.action-link:hover { background: rgba(255, 255, 255, 0.1); border-color: rgba(255, 255, 255, 0.1); color: white; }

/* Dashboard Specific */
.chart-container {
    background: rgba(15, 23, 42, 0.4);
    border-radius: 12px;
    padding: 1rem;
    border: 1px solid rgba(255, 255, 255, 0.05);
}


====================
FILE: .\static\summary.html
====================
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Run Summary - Immuno-Engine</title>
    <style>
        body {
            font-family: system-ui, sans-serif;
            margin: 2rem;
            background: #f8f9fa;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
        }

        .card {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin-bottom: 1.5rem;
        }

        h1 {
            margin-bottom: 0.5rem;
        }

        .back-link {
            display: inline-block;
            margin-bottom: 1rem;
            color: #0066cc;
            text-decoration: none;
        }

        .back-link:hover {
            text-decoration: underline;
        }

        #loading {
            text-align: center;
            padding: 2rem;
            color: #666;
        }

        .summary-text {
            line-height: 1.6;
            color: #333;
            white-space: pre-wrap;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin-top: 1rem;
        }

        .stat-item {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 4px;
        }

        .stat-label {
            color: #666;
            font-size: 0.9rem;
        }

        .stat-value {
            font-size: 1.5rem;
            font-weight: 600;
            color: #0066cc;
        }

        .top-peptides {
            margin-top: 1rem;
        }

        .peptide-item {
            background: #f8f9fa;
            padding: 0.8rem;
            margin-bottom: 0.5rem;
            border-radius: 4px;
            font-family: monospace;
        }

        .btn {
            padding: 0.6rem 1.2rem;
            background: #0066cc;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            margin-top: 1rem;
        }

        .btn:hover {
            background: #0052a3;
        }
    </style>
</head>

<body>
    <div class="container">
        <a href="/static/runs.html" class="back-link">â† Back to Runs</a>

        <div class="card">
            <h1>Run Summary</h1>
            <p id="runInfo">Loading summary...</p>
            <button id="regenerateBtn" onclick="regenerateSummary()" class="btn" style="display:none;">
                ðŸ”„ Regenerate Summary
            </button>
        </div>

        <div id="loading">Generating AI summary...</div>

        <div id="content" style="display:none;">
            <div class="card">
                <h2>Statistics</h2>
                <div class="stats-grid" id="statsGrid"></div>
            </div>

            <div class="card">
                <h2>AI-Generated Summary</h2>
                <div class="summary-text" id="summaryText"></div>
            </div>

            <div class="card" id="topPeptidesCard" style="display:none;">
                <h2>Top Peptides</h2>
                <div class="top-peptides" id="topPeptides"></div>
            </div>
        </div>
    </div>

    <script>
        const urlParams = new URLSearchParams(window.location.search);
        const runId = urlParams.get('run_id');
        const token = localStorage.getItem('token');

        if (!runId) {
            document.getElementById('runInfo').innerHTML = "Error: No run_id specified in URL.";
            document.getElementById('loading').style.display = 'none';
        } else if (!token) {
            window.location.href = '/static/login.html';
        } else {
            fetchSummary();
        }

        async function regenerateSummary() {
            if (!confirm('Regenerate AI summary? This will create a new summary.')) return;
            document.getElementById('loading').style.display = 'block';
            document.getElementById('content').style.display = 'none';
            await fetchSummary();
        }

        async function fetchSummary() {
            try {
                const res = await fetch(`/summary/run/${runId}`, {
                    method: 'POST',
                    headers: { 'Authorization': 'Bearer ' + token }
                });

                if (!res.ok) {
                    if (res.status === 401) {
                        window.location.href = '/static/login.html';
                        return;
                    }
                    throw new Error(`API Error: ${res.status}`);
                }

                const data = await res.json();
                displaySummary(data);
            } catch (e) {
                document.getElementById('loading').innerHTML =
                    `<span style="color:red">Error loading summary: ${e.message}</span>`;
            }
        }

        function displaySummary(data) {
            document.getElementById('loading').style.display = 'none';
            document.getElementById('content').style.display = 'block';
            document.getElementById('regenerateBtn').style.display = 'inline-block';
            document.getElementById('runInfo').innerHTML = `Run ID: <b>${data.run_id}</b>`;

            // Display stats
            const statsGrid = document.getElementById('statsGrid');
            const stats = [];

            if (data.num_peptides !== undefined) {
                stats.push({ label: 'Total Peptides', value: data.num_peptides.toLocaleString() });
            }
            if (data.num_proteins !== undefined) {
                stats.push({ label: 'Total Proteins', value: data.num_proteins.toLocaleString() });
            }
            if (data.num_significant !== undefined) {
                stats.push({ label: 'Significant (q<0.05)', value: data.num_significant.toLocaleString() });
            }
            if (data.avg_intensity !== undefined) {
                stats.push({ label: 'Avg Intensity', value: data.avg_intensity.toExponential(2) });
            }
            if (data.avg_sequence_length !== undefined) {
                stats.push({ label: 'Avg Length (AA)', value: data.avg_sequence_length.toFixed(1) });
            }

            statsGrid.innerHTML = stats.map(s => `
                <div class="stat-item">
                    <div class="stat-label">${s.label}</div>
                    <div class="stat-value">${s.value}</div>
                </div>
            `).join('');

            // Display summary text
            if (data.summary_text) {
                document.getElementById('summaryText').textContent = data.summary_text;
            } else if (data.error) {
                document.getElementById('summaryText').innerHTML =
                    `<span style="color:red">Error: ${data.error}</span>`;
            }

            // Display top peptides if available
            if (data.top_peptides && data.top_peptides.length > 0) {
                const topPeptidesCard = document.getElementById('topPeptidesCard');
                topPeptidesCard.style.display = 'block';

                document.getElementById('topPeptides').innerHTML = data.top_peptides
                    .slice(0, 5)
                    .map((p, i) => `
                        <div class="peptide-item">
                            ${i + 1}. ${p.sequence} 
                            <span style="color:#666; font-size:0.9rem;">
                                (Intensity: ${p.intensity ? p.intensity.toExponential(2) : 'N/A'})
                            </span>
                        </div>
                    `).join('');
            }
        }
    </script>
</body>

</html>

====================
FILE: .\static\upload.html
====================
<!DOCTYPE html>
<html>

<head>
    <title>Upload Run - Immuno-Engine</title>
    <link rel="stylesheet" href="/static/style.css">
</head>

<body>
    <div class="container">
        <div class="header flex-between">
            <h1>Upload Dataset</h1>
            <a href="/static/runs.html" class="btn btn-secondary">Back to Runs</a>
        </div>

        <div class="card" style="max-width: 800px; margin: 0 auto;">
            <form id="uploadForm">
                <div class="grid">
                    <div>
                        <label for="fileInput">Peptide Table File</label>
                        <input type="file" id="fileInput" name="file" required
                            style="padding: 1rem; border: 2px dashed var(--border-color); background: rgba(0,0,0,0.2); cursor: pointer;">
                        <p class="text-sm text-muted" style="margin-top: 0.5rem;">Accepted formats: MaxQuant
                            (peptides.txt), DIA-NN, Spectronaut, or Generic CSV.</p>
                    </div>

                    <div class="grid-2">
                        <div>
                            <label for="formatInput">Format</label>
                            <select id="formatInput" name="format">
                                <option value="auto">Auto-detect</option>
                                <option value="maxquant">MaxQuant (peptides.txt)</option>
                                <option value="diann">DIA-NN (report.tsv)</option>
                                <option value="spectronaut">Spectronaut</option>
                                <option value="generic">Generic CSV</option>
                            </select>
                        </div>
                        <div>
                            <label for="runIdInput">Run ID (Optional)</label>
                            <input type="text" id="runIdInput" name="run_id" placeholder="e.g., RUN_2025_11_03_A">
                        </div>
                    </div>

                    <div class="grid-2">
                        <div>
                            <label for="instrumentInput">Instrument (Optional)</label>
                            <input type="text" id="instrumentInput" name="instrument" placeholder="e.g., Q Exactive">
                        </div>
                        <div>
                            <label for="methodInput">Method (Optional)</label>
                            <input type="text" id="methodInput" name="method" placeholder="e.g., HILIC or RP">
                        </div>
                    </div>

                    <button type="submit" class="btn btn-primary"
                        style="width: 100%; justify-content: center; margin-top: 1rem;">
                        Upload & Ingest
                    </button>
                </div>
            </form>
        </div>

        <div id="status" class="card" style="display: none; max-width: 800px; margin: 2rem auto; text-align: center;">
            <!-- Success/Error content will go here -->
        </div>
    </div>

    <script>
        const token = localStorage.getItem('token');
        if (!token) window.location.href = '/static/login.html';

        document.getElementById('uploadForm').addEventListener('submit', async (e) => {
            e.preventDefault();
            const statusDiv = document.getElementById('status');
            const btn = document.querySelector('button[type="submit"]');

            statusDiv.style.display = 'block';
            statusDiv.innerHTML = '<div style="padding: 2rem;"><h3>Uploading & Ingesting...</h3><p class="text-muted">This may take a moment depending on file size.</p></div>';
            btn.disabled = true;
            btn.innerText = "Processing...";

            const formData = new FormData();
            formData.append('file', document.getElementById('fileInput').files[0]);
            formData.append('format', document.getElementById('formatInput').value);
            formData.append('run_id', document.getElementById('runIdInput').value);
            formData.append('instrument', document.getElementById('instrumentInput').value);
            formData.append('method', document.getElementById('methodInput').value);

            try {
                const res = await fetch('/upload', {
                    method: 'POST',
                    headers: {
                        'Authorization': 'Bearer ' + token
                    },
                    body: formData
                });

                if (res.ok) {
                    const data = await res.json();
                    statusDiv.innerHTML = `
                        <div style="padding: 1rem;">
                            <h2 style="color: var(--success-color)">âœ… Upload Complete</h2>
                            <p>Run ID: <strong>${data.run_id}</strong></p>
                            <p>Ingested <strong>${data.rows_ingested}</strong> peptides.</p>
                            <p class="text-muted">${data.message}</p>
                            
                            <div class="flex" style="justify-content: center; margin-top: 2rem; gap: 1rem; flex-wrap: wrap;">
                                <a href="/static/runs.html" class="btn btn-primary" style="background: var(--success-color); border: none;">Go to My Runs</a>
                                <a href="/static/simple_dashboard.html?run_id=${data.run_id}" class="btn btn-secondary">View Dashboard</a>
                                <a href="/static/summary.html?run_id=${data.run_id}" class="btn btn-secondary">Generate Summary</a>
                            </div>
                        </div>
                    `;
                    document.getElementById('uploadForm').reset();
                } else {
                    const err = await res.text();
                    statusDiv.innerHTML = `<h3 style="color: var(--danger-color)">Upload Failed</h3><p>${err}</p>`;
                }
            } catch (e) {
                statusDiv.innerHTML = `<h3 style="color: var(--danger-color)">Error</h3><p>${e.message}</p>`;
            } finally {
                btn.disabled = false;
                btn.innerText = "Upload & Ingest";
            }
        });
    </script>
</body>

</html>